{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c8e368d",
   "metadata": {},
   "source": [
    "# Hand-drawn shape detection using a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6273043",
   "metadata": {},
   "source": [
    "# Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7c64fe",
   "metadata": {},
   "source": [
    "In this notebook we train a neural network to catagorise my own hand drawn shapes labelling each image as either a circle, line or square. The ambitions for this project are two-fold, firstly, my ambition in studying deep learning was to use artificial intelligence to solve my own problems from my own datasets. Secondly, as a rule of thumb, neural networks typically need 1000 examples of each category to successfully train a model. As I do not have the patience to draw 3000 shapes I will be training this neural network using a small number of images (30 per shape) and a variety of data augmentation techniques to expand the dataset to over 3000 examples. The network will then be validated and tested on the remaining images (30 per shape). This emulates a realistic scenario in which data gathering is expensive or time consuming. The neural network is trained in augmented data, however, the network will be validated and tested against non-augmented data, from the original dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b338af9c",
   "metadata": {},
   "source": [
    "# Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9eae9a",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>Importing and processing augmented dataset</li>\n",
    "    <li>\n",
    "        Training neural network\n",
    "        <ul>\n",
    "            <li>Defining neural network geometry</li>\n",
    "            <li>Random hyperparameter search</li>\n",
    "            <li>Convergence of the cost function</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Validation dataset</li>\n",
    "    <li>Regularisation to prevent overfitting</li>\n",
    "    <li>Testing neural network</li>\n",
    "    <li>Conclusion</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67c7b2b",
   "metadata": {},
   "source": [
    "# Importing and processing augmented dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de8e3021",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0872f6",
   "metadata": {},
   "source": [
    "Import augmented training dataset. Each image has dimensions 25x25 and hence when flattened has 625 features. We import 3240 images in to a numpy matrix as X with dimensions (3240,625)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66a96729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported files: circles\\train\\circle_\n",
      "Imported files: lines\\train\\line_\n",
      "Imported files: squares\\train\\square_\n"
     ]
    }
   ],
   "source": [
    "num_images = 1080*3\n",
    "resolu_images = 25**2\n",
    "file_list = [r\"circles\\train\\circle_\",r\"lines\\train\\line_\",r\"squares\\train\\square_\"]\n",
    "X = np.zeros([num_images, resolu_images])\n",
    "counter = 0\n",
    "for i in range(3):\n",
    "    for j in range(1080):\n",
    "        file_name = file_list[i] + str(j+1) + \".jpg\"\n",
    "        X[counter] = np.matrix.flatten(np.array(Image.open(file_name).convert('L')))\n",
    "        counter += 1\n",
    "    print(\"Imported files: {}\".format(file_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c94130e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3240, 625)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590ad09e",
   "metadata": {},
   "source": [
    "Each feature has an RGB value between 0 and 255 which we now normalise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d196357",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalise RGB values\n",
    "X = X / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8169a4d2",
   "metadata": {},
   "source": [
    "We now define our target class as y with dimensions (3240,1). Each image is either a circle (0), a line (1) or a square (2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80a044e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.genfromtxt(\"train_target_class.csv\", delimiter=',')\n",
    "y = y.reshape((num_images,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4ccd2cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4aba944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3240, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bf687d",
   "metadata": {},
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2059b1",
   "metadata": {},
   "source": [
    "To artificially incraese the amount of training data we can utilise data augmentatio. For each image we flip, rotate, blur and sharpen increasing the original dataset of 90 (30 per shape) to 3240 (1080 per shape). As few exmaples of these are below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f89dcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b97d6857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1,6)\n",
    "fig_indices = [2160, 2160+30, 2160+60, 2160+120, 3240-720,3240-360]\n",
    "for i in range(6):\n",
    "    axs[i].imshow(X[fig_indices[i]].reshape((25,25)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964c1dac",
   "metadata": {},
   "source": [
    "# Training neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d23b4c6",
   "metadata": {},
   "source": [
    "### Defining neural network hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663dd083",
   "metadata": {},
   "source": [
    "We now train a neural network on this augmented data. We utilise a softmax neural network which are typically used for catagorisation problems. In this work we will make an initial assumption that a sufficiently sophisticated network can be trained on three layers (two hidden layers). To decide other hyperparameters such as the number of units per layer and the learning rate we perform a random search. We will randomly initialize hyperparameters between sensible limits and see which sets of parameters give timely and controlled minimisation of the cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613bb7dd",
   "metadata": {},
   "source": [
    "### Random hyperparameter search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9eb733",
   "metadata": {},
   "source": [
    "Units in hidden layer 1: Integer value rounded from $10^a$ for $1 \\leq a \\leq 3$.\n",
    "\n",
    "Units in hidden layer 2: Integer value rounded from $10^b$ for $-2 \\leq b \\leq 0$ times the units in hidden layer 1.\n",
    "\n",
    "Learning rate: Value $\\alpha = 10^c$ for $-7 \\leq c \\leq -1$.\n",
    "\n",
    "The number of layers in the output layer is fixed to the number of classes (3). We pick the activation function of the hidden layers to be \"relu\". The activation function of the output layer is linear using logits (equivalent to softmax). For each set of random hyperparameters we plot the loss over 50 epochs. We are looking for hyperparameters that yield a timely yet smooth decrease in loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94289925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.activations import linear, relu, sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12451ba3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "102/102 [==============================] - 1s 1ms/step - loss: 1.0986\n",
      "Epoch 2/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 3/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 4/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 5/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 6/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 7/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.0986\n",
      "Epoch 8/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.0986\n",
      "Epoch 9/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 10/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 11/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.0986\n",
      "Epoch 12/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 13/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 14/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 15/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 16/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 17/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 18/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 19/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 20/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 21/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 22/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.0986\n",
      "Epoch 23/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.0986\n",
      "Epoch 24/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.0986\n",
      "Epoch 25/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 26/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 27/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 28/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 29/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.0986\n",
      "Epoch 30/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 31/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 32/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 33/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 34/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 35/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 36/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 37/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 38/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 39/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.0986\n",
      "Epoch 40/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.0986\n",
      "Epoch 41/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 42/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 43/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 44/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.0986\n",
      "Epoch 45/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 46/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 47/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 48/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 49/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 50/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 1/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 2/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 3/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 4/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 5/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 6/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 7/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 8/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 9/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 10/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 11/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 12/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 13/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 14/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 15/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 16/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 17/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 18/50\n",
      "102/102 [==============================] - 0s 977us/step - loss: 1.0986\n",
      "Epoch 19/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 20/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 21/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 22/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 23/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 24/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 25/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 26/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 27/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 28/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 29/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 30/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 31/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 32/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 33/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 34/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 35/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 36/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 37/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 38/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 39/50\n",
      "102/102 [==============================] - 0s 967us/step - loss: 1.0986\n",
      "Epoch 40/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 41/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 42/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 43/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 44/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 45/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 46/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 47/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 48/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 49/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 50/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 1s 4ms/step - loss: 1.0040\n",
      "Epoch 2/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.8484\n",
      "Epoch 3/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.7300\n",
      "Epoch 4/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6317\n",
      "Epoch 5/50\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5489\n",
      "Epoch 6/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4923\n",
      "Epoch 7/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4420\n",
      "Epoch 8/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4017\n",
      "Epoch 9/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3598\n",
      "Epoch 10/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3426\n",
      "Epoch 11/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3116\n",
      "Epoch 12/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2858\n",
      "Epoch 13/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2669\n",
      "Epoch 14/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2526\n",
      "Epoch 15/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2358\n",
      "Epoch 16/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2325\n",
      "Epoch 17/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2181\n",
      "Epoch 18/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1955\n",
      "Epoch 19/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1834\n",
      "Epoch 20/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1708\n",
      "Epoch 21/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1603\n",
      "Epoch 22/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1589\n",
      "Epoch 23/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1636\n",
      "Epoch 24/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1355\n",
      "Epoch 25/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1338\n",
      "Epoch 26/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1257\n",
      "Epoch 27/50\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1149\n",
      "Epoch 28/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1110\n",
      "Epoch 29/50\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1053\n",
      "Epoch 30/50\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0965\n",
      "Epoch 31/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0919\n",
      "Epoch 32/50\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0827\n",
      "Epoch 33/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0864\n",
      "Epoch 34/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0876\n",
      "Epoch 35/50\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0749\n",
      "Epoch 36/50\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0679\n",
      "Epoch 37/50\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0638\n",
      "Epoch 38/50\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0619\n",
      "Epoch 39/50\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0657\n",
      "Epoch 40/50\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0578\n",
      "Epoch 41/50\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0565\n",
      "Epoch 42/50\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0465\n",
      "Epoch 43/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0418\n",
      "Epoch 44/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0422\n",
      "Epoch 45/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0416\n",
      "Epoch 46/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0375\n",
      "Epoch 47/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0354\n",
      "Epoch 48/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0361\n",
      "Epoch 49/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0444\n",
      "Epoch 50/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0619\n",
      "Epoch 1/50\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 1.1122\n",
      "Epoch 2/50\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 1.0987\n",
      "Epoch 3/50\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0987\n",
      "Epoch 4/50\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 1.0987\n",
      "Epoch 5/50\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0987\n",
      "Epoch 6/50\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 1.0987\n",
      "Epoch 7/50\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0987\n",
      "Epoch 8/50\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 1.0987\n",
      "Epoch 9/50\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 1.0987\n",
      "Epoch 10/50\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 1.0987\n",
      "Epoch 11/50\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0987\n",
      "Epoch 12/50\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0987\n",
      "Epoch 13/50\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0987\n",
      "Epoch 14/50\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0987\n",
      "Epoch 15/50\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0987\n",
      "Epoch 16/50\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0987\n",
      "Epoch 17/50\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0987\n",
      "Epoch 18/50\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0987\n",
      "Epoch 19/50\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0987\n",
      "Epoch 20/50\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0987\n",
      "Epoch 21/50\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0987\n",
      "Epoch 22/50\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0987\n",
      "Epoch 23/50\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0987\n",
      "Epoch 24/50\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0987\n",
      "Epoch 25/50\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0987\n",
      "Epoch 26/50\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0987\n",
      "Epoch 27/50\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0987\n",
      "Epoch 28/50\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 1.0987\n",
      "Epoch 29/50\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 1.0987\n",
      "Epoch 30/50\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0987\n",
      "Epoch 31/50\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0987\n",
      "Epoch 32/50\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0987\n",
      "Epoch 33/50\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0986\n",
      "Epoch 34/50\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0987\n",
      "Epoch 35/50\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0987\n",
      "Epoch 36/50\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0987\n",
      "Epoch 37/50\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0987\n",
      "Epoch 38/50\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0987\n",
      "Epoch 39/50\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0987\n",
      "Epoch 40/50\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0987\n",
      "Epoch 41/50\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 1.0986\n",
      "Epoch 42/50\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0987\n",
      "Epoch 43/50\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 1.0987\n",
      "Epoch 44/50\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0986\n",
      "Epoch 45/50\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 1.0987\n",
      "Epoch 46/50\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0987\n",
      "Epoch 47/50\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 1.0987\n",
      "Epoch 48/50\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0987\n",
      "Epoch 49/50\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 1.0986\n",
      "Epoch 50/50\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0987\n",
      "Epoch 1/50\n",
      "102/102 [==============================] - 1s 2ms/step - loss: 1.1064\n",
      "Epoch 2/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.0518\n",
      "Epoch 3/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.0245\n",
      "Epoch 4/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.0025\n",
      "Epoch 5/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9700\n",
      "Epoch 6/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9520\n",
      "Epoch 7/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9334\n",
      "Epoch 8/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.9185\n",
      "Epoch 9/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9062\n",
      "Epoch 10/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8939\n",
      "Epoch 11/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8834\n",
      "Epoch 12/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8722\n",
      "Epoch 13/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8620\n",
      "Epoch 14/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8518\n",
      "Epoch 15/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8418\n",
      "Epoch 16/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8329\n",
      "Epoch 17/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8232\n",
      "Epoch 18/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8146\n",
      "Epoch 19/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8060\n",
      "Epoch 20/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7973\n",
      "Epoch 21/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7892\n",
      "Epoch 22/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7813\n",
      "Epoch 23/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7726\n",
      "Epoch 24/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7665\n",
      "Epoch 25/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7570\n",
      "Epoch 26/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7492\n",
      "Epoch 27/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7414\n",
      "Epoch 28/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7339\n",
      "Epoch 29/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7268\n",
      "Epoch 30/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7195\n",
      "Epoch 31/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7123\n",
      "Epoch 32/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7048\n",
      "Epoch 33/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6979\n",
      "Epoch 34/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6917\n",
      "Epoch 35/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6844\n",
      "Epoch 36/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6778\n",
      "Epoch 37/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6701\n",
      "Epoch 38/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6617\n",
      "Epoch 39/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6543\n",
      "Epoch 40/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6469\n",
      "Epoch 41/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6405\n",
      "Epoch 42/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6337\n",
      "Epoch 43/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6263\n",
      "Epoch 44/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6203\n",
      "Epoch 45/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6137\n",
      "Epoch 46/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6077\n",
      "Epoch 47/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6019\n",
      "Epoch 48/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5953\n",
      "Epoch 49/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5896\n",
      "Epoch 50/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5841\n",
      "Epoch 1/50\n",
      "102/102 [==============================] - 0s 822us/step - loss: 1.0986\n",
      "Epoch 2/50\n",
      "102/102 [==============================] - 0s 795us/step - loss: 1.0986\n",
      "Epoch 3/50\n",
      "102/102 [==============================] - 0s 851us/step - loss: 1.0986\n",
      "Epoch 4/50\n",
      "102/102 [==============================] - 0s 843us/step - loss: 1.0986\n",
      "Epoch 5/50\n",
      "102/102 [==============================] - 0s 782us/step - loss: 1.0986\n",
      "Epoch 6/50\n",
      "102/102 [==============================] - 0s 809us/step - loss: 1.0986\n",
      "Epoch 7/50\n",
      "102/102 [==============================] - 0s 825us/step - loss: 1.0986\n",
      "Epoch 8/50\n",
      "102/102 [==============================] - 0s 888us/step - loss: 1.0986\n",
      "Epoch 9/50\n",
      "102/102 [==============================] - 0s 874us/step - loss: 1.0986\n",
      "Epoch 10/50\n",
      "102/102 [==============================] - 0s 857us/step - loss: 1.0986\n",
      "Epoch 11/50\n",
      "102/102 [==============================] - 0s 821us/step - loss: 1.0986\n",
      "Epoch 12/50\n",
      "102/102 [==============================] - 0s 882us/step - loss: 1.0986\n",
      "Epoch 13/50\n",
      "102/102 [==============================] - 0s 817us/step - loss: 1.0986\n",
      "Epoch 14/50\n",
      "102/102 [==============================] - 0s 789us/step - loss: 1.0986\n",
      "Epoch 15/50\n",
      "102/102 [==============================] - 0s 779us/step - loss: 1.0986\n",
      "Epoch 16/50\n",
      "102/102 [==============================] - 0s 760us/step - loss: 1.0986\n",
      "Epoch 17/50\n",
      "102/102 [==============================] - 0s 812us/step - loss: 1.0986\n",
      "Epoch 18/50\n",
      "102/102 [==============================] - 0s 822us/step - loss: 1.0986\n",
      "Epoch 19/50\n",
      "102/102 [==============================] - 0s 845us/step - loss: 1.0986\n",
      "Epoch 20/50\n",
      "102/102 [==============================] - 0s 806us/step - loss: 1.0986\n",
      "Epoch 21/50\n",
      "102/102 [==============================] - 0s 799us/step - loss: 1.0986\n",
      "Epoch 22/50\n",
      "102/102 [==============================] - 0s 818us/step - loss: 1.0986\n",
      "Epoch 23/50\n",
      "102/102 [==============================] - 0s 814us/step - loss: 1.0986\n",
      "Epoch 24/50\n",
      "102/102 [==============================] - 0s 837us/step - loss: 1.0986\n",
      "Epoch 25/50\n",
      "102/102 [==============================] - 0s 820us/step - loss: 1.0986\n",
      "Epoch 26/50\n",
      "102/102 [==============================] - 0s 823us/step - loss: 1.0986\n",
      "Epoch 27/50\n",
      "102/102 [==============================] - 0s 815us/step - loss: 1.0986\n",
      "Epoch 28/50\n",
      "102/102 [==============================] - 0s 803us/step - loss: 1.0986\n",
      "Epoch 29/50\n",
      "102/102 [==============================] - 0s 852us/step - loss: 1.0986\n",
      "Epoch 30/50\n",
      "102/102 [==============================] - 0s 865us/step - loss: 1.0986\n",
      "Epoch 31/50\n",
      "102/102 [==============================] - 0s 842us/step - loss: 1.0986\n",
      "Epoch 32/50\n",
      "102/102 [==============================] - 0s 797us/step - loss: 1.0986\n",
      "Epoch 33/50\n",
      "102/102 [==============================] - 0s 809us/step - loss: 1.0986\n",
      "Epoch 34/50\n",
      "102/102 [==============================] - 0s 814us/step - loss: 1.0986\n",
      "Epoch 35/50\n",
      "102/102 [==============================] - 0s 772us/step - loss: 1.0986\n",
      "Epoch 36/50\n",
      "102/102 [==============================] - 0s 881us/step - loss: 1.0986\n",
      "Epoch 37/50\n",
      "102/102 [==============================] - 0s 870us/step - loss: 1.0986\n",
      "Epoch 38/50\n",
      "102/102 [==============================] - 0s 808us/step - loss: 1.0986\n",
      "Epoch 39/50\n",
      "102/102 [==============================] - 0s 813us/step - loss: 1.0986\n",
      "Epoch 40/50\n",
      "102/102 [==============================] - 0s 785us/step - loss: 1.0986\n",
      "Epoch 41/50\n",
      "102/102 [==============================] - 0s 822us/step - loss: 1.0986\n",
      "Epoch 42/50\n",
      "102/102 [==============================] - 0s 844us/step - loss: 1.0986\n",
      "Epoch 43/50\n",
      "102/102 [==============================] - 0s 849us/step - loss: 1.0986\n",
      "Epoch 44/50\n",
      "102/102 [==============================] - 0s 810us/step - loss: 1.0986\n",
      "Epoch 45/50\n",
      "102/102 [==============================] - 0s 780us/step - loss: 1.0986\n",
      "Epoch 46/50\n",
      "102/102 [==============================] - 0s 792us/step - loss: 1.0986\n",
      "Epoch 47/50\n",
      "102/102 [==============================] - 0s 841us/step - loss: 1.0986\n",
      "Epoch 48/50\n",
      "102/102 [==============================] - 0s 885us/step - loss: 1.0986\n",
      "Epoch 49/50\n",
      "102/102 [==============================] - 0s 800us/step - loss: 1.0986\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 802us/step - loss: 1.0986\n",
      "Epoch 1/50\n",
      "102/102 [==============================] - 0s 833us/step - loss: 1.0986\n",
      "Epoch 2/50\n",
      "102/102 [==============================] - 0s 776us/step - loss: 1.0986\n",
      "Epoch 3/50\n",
      "102/102 [==============================] - 0s 771us/step - loss: 1.0986\n",
      "Epoch 4/50\n",
      "102/102 [==============================] - 0s 741us/step - loss: 1.0986\n",
      "Epoch 5/50\n",
      "102/102 [==============================] - 0s 813us/step - loss: 1.0986\n",
      "Epoch 6/50\n",
      "102/102 [==============================] - 0s 809us/step - loss: 1.0986\n",
      "Epoch 7/50\n",
      "102/102 [==============================] - 0s 801us/step - loss: 1.0986\n",
      "Epoch 8/50\n",
      "102/102 [==============================] - 0s 852us/step - loss: 1.0986\n",
      "Epoch 9/50\n",
      "102/102 [==============================] - 0s 823us/step - loss: 1.0986\n",
      "Epoch 10/50\n",
      "102/102 [==============================] - 0s 776us/step - loss: 1.0986\n",
      "Epoch 11/50\n",
      "102/102 [==============================] - 0s 823us/step - loss: 1.0986\n",
      "Epoch 12/50\n",
      "102/102 [==============================] - 0s 830us/step - loss: 1.0986\n",
      "Epoch 13/50\n",
      "102/102 [==============================] - 0s 904us/step - loss: 1.0986\n",
      "Epoch 14/50\n",
      "102/102 [==============================] - 0s 884us/step - loss: 1.0986\n",
      "Epoch 15/50\n",
      "102/102 [==============================] - 0s 867us/step - loss: 1.0986\n",
      "Epoch 16/50\n",
      "102/102 [==============================] - 0s 858us/step - loss: 1.0986\n",
      "Epoch 17/50\n",
      "102/102 [==============================] - 0s 815us/step - loss: 1.0986\n",
      "Epoch 18/50\n",
      "102/102 [==============================] - 0s 852us/step - loss: 1.0986\n",
      "Epoch 19/50\n",
      "102/102 [==============================] - 0s 865us/step - loss: 1.0986\n",
      "Epoch 20/50\n",
      "102/102 [==============================] - 0s 861us/step - loss: 1.0986\n",
      "Epoch 21/50\n",
      "102/102 [==============================] - 0s 798us/step - loss: 1.0986\n",
      "Epoch 22/50\n",
      "102/102 [==============================] - 0s 781us/step - loss: 1.0986\n",
      "Epoch 23/50\n",
      "102/102 [==============================] - 0s 792us/step - loss: 1.0986\n",
      "Epoch 24/50\n",
      "102/102 [==============================] - 0s 797us/step - loss: 1.0986\n",
      "Epoch 25/50\n",
      "102/102 [==============================] - 0s 805us/step - loss: 1.0986\n",
      "Epoch 26/50\n",
      "102/102 [==============================] - 0s 838us/step - loss: 1.0986\n",
      "Epoch 27/50\n",
      "102/102 [==============================] - 0s 892us/step - loss: 1.0986\n",
      "Epoch 28/50\n",
      "102/102 [==============================] - 0s 879us/step - loss: 1.0986\n",
      "Epoch 29/50\n",
      "102/102 [==============================] - 0s 842us/step - loss: 1.0986\n",
      "Epoch 30/50\n",
      "102/102 [==============================] - 0s 810us/step - loss: 1.0986\n",
      "Epoch 31/50\n",
      "102/102 [==============================] - 0s 880us/step - loss: 1.0986\n",
      "Epoch 32/50\n",
      "102/102 [==============================] - 0s 878us/step - loss: 1.0986\n",
      "Epoch 33/50\n",
      "102/102 [==============================] - 0s 855us/step - loss: 1.0986\n",
      "Epoch 34/50\n",
      "102/102 [==============================] - 0s 796us/step - loss: 1.0986\n",
      "Epoch 35/50\n",
      "102/102 [==============================] - 0s 798us/step - loss: 1.0986\n",
      "Epoch 36/50\n",
      "102/102 [==============================] - 0s 804us/step - loss: 1.0986\n",
      "Epoch 37/50\n",
      "102/102 [==============================] - 0s 810us/step - loss: 1.0986\n",
      "Epoch 38/50\n",
      "102/102 [==============================] - 0s 847us/step - loss: 1.0986\n",
      "Epoch 39/50\n",
      "102/102 [==============================] - 0s 810us/step - loss: 1.0986\n",
      "Epoch 40/50\n",
      "102/102 [==============================] - 0s 806us/step - loss: 1.0986\n",
      "Epoch 41/50\n",
      "102/102 [==============================] - 0s 844us/step - loss: 1.0986\n",
      "Epoch 42/50\n",
      "102/102 [==============================] - 0s 790us/step - loss: 1.0986\n",
      "Epoch 43/50\n",
      "102/102 [==============================] - 0s 831us/step - loss: 1.0986\n",
      "Epoch 44/50\n",
      "102/102 [==============================] - 0s 802us/step - loss: 1.0986\n",
      "Epoch 45/50\n",
      "102/102 [==============================] - 0s 829us/step - loss: 1.0986\n",
      "Epoch 46/50\n",
      "102/102 [==============================] - 0s 832us/step - loss: 1.0986\n",
      "Epoch 47/50\n",
      "102/102 [==============================] - 0s 818us/step - loss: 1.0986\n",
      "Epoch 48/50\n",
      "102/102 [==============================] - 0s 790us/step - loss: 1.0986\n",
      "Epoch 49/50\n",
      "102/102 [==============================] - 0s 818us/step - loss: 1.0986\n",
      "Epoch 50/50\n",
      "102/102 [==============================] - 0s 869us/step - loss: 1.0986\n",
      "Epoch 1/50\n",
      "102/102 [==============================] - 0s 899us/step - loss: 1.0986\n",
      "Epoch 2/50\n",
      "102/102 [==============================] - 0s 892us/step - loss: 1.0986\n",
      "Epoch 3/50\n",
      "102/102 [==============================] - 0s 904us/step - loss: 1.0986\n",
      "Epoch 4/50\n",
      "102/102 [==============================] - 0s 909us/step - loss: 1.0986\n",
      "Epoch 5/50\n",
      "102/102 [==============================] - 0s 953us/step - loss: 1.0986\n",
      "Epoch 6/50\n",
      "102/102 [==============================] - 0s 927us/step - loss: 1.0986\n",
      "Epoch 7/50\n",
      "102/102 [==============================] - 0s 913us/step - loss: 1.0986\n",
      "Epoch 8/50\n",
      "102/102 [==============================] - 0s 933us/step - loss: 1.0986\n",
      "Epoch 9/50\n",
      "102/102 [==============================] - 0s 910us/step - loss: 1.0986\n",
      "Epoch 10/50\n",
      "102/102 [==============================] - 0s 958us/step - loss: 1.0986\n",
      "Epoch 11/50\n",
      "102/102 [==============================] - 0s 949us/step - loss: 1.0986\n",
      "Epoch 12/50\n",
      "102/102 [==============================] - 0s 952us/step - loss: 1.0986\n",
      "Epoch 13/50\n",
      "102/102 [==============================] - 0s 961us/step - loss: 1.0986\n",
      "Epoch 14/50\n",
      "102/102 [==============================] - 0s 932us/step - loss: 1.0986\n",
      "Epoch 15/50\n",
      "102/102 [==============================] - 0s 938us/step - loss: 1.0986\n",
      "Epoch 16/50\n",
      "102/102 [==============================] - 0s 944us/step - loss: 1.0986\n",
      "Epoch 17/50\n",
      "102/102 [==============================] - 0s 948us/step - loss: 1.0986\n",
      "Epoch 18/50\n",
      "102/102 [==============================] - 0s 949us/step - loss: 1.0986\n",
      "Epoch 19/50\n",
      "102/102 [==============================] - 0s 908us/step - loss: 1.0986\n",
      "Epoch 20/50\n",
      "102/102 [==============================] - 0s 913us/step - loss: 1.0986\n",
      "Epoch 21/50\n",
      "102/102 [==============================] - 0s 948us/step - loss: 1.0986\n",
      "Epoch 22/50\n",
      "102/102 [==============================] - 0s 934us/step - loss: 1.0986\n",
      "Epoch 23/50\n",
      "102/102 [==============================] - 0s 932us/step - loss: 1.0986\n",
      "Epoch 24/50\n",
      "102/102 [==============================] - 0s 963us/step - loss: 1.0986\n",
      "Epoch 25/50\n",
      "102/102 [==============================] - 0s 940us/step - loss: 1.0986\n",
      "Epoch 26/50\n",
      "102/102 [==============================] - 0s 934us/step - loss: 1.0986\n",
      "Epoch 27/50\n",
      "102/102 [==============================] - 0s 947us/step - loss: 1.0986\n",
      "Epoch 28/50\n",
      "102/102 [==============================] - 0s 919us/step - loss: 1.0986\n",
      "Epoch 29/50\n",
      "102/102 [==============================] - 0s 944us/step - loss: 1.0986\n",
      "Epoch 30/50\n",
      "102/102 [==============================] - 0s 942us/step - loss: 1.0986\n",
      "Epoch 31/50\n",
      "102/102 [==============================] - 0s 938us/step - loss: 1.0986\n",
      "Epoch 32/50\n",
      "102/102 [==============================] - 0s 896us/step - loss: 1.0986\n",
      "Epoch 33/50\n",
      "102/102 [==============================] - 0s 949us/step - loss: 1.0986\n",
      "Epoch 34/50\n",
      "102/102 [==============================] - 0s 944us/step - loss: 1.0986\n",
      "Epoch 35/50\n",
      "102/102 [==============================] - 0s 952us/step - loss: 1.0986\n",
      "Epoch 36/50\n",
      "102/102 [==============================] - 0s 923us/step - loss: 1.0986\n",
      "Epoch 37/50\n",
      "102/102 [==============================] - 0s 952us/step - loss: 1.0986\n",
      "Epoch 38/50\n",
      "102/102 [==============================] - 0s 947us/step - loss: 1.0986\n",
      "Epoch 39/50\n",
      "102/102 [==============================] - 0s 882us/step - loss: 1.0986\n",
      "Epoch 40/50\n",
      "102/102 [==============================] - 0s 938us/step - loss: 1.0986\n",
      "Epoch 41/50\n",
      "102/102 [==============================] - 0s 957us/step - loss: 1.0986\n",
      "Epoch 42/50\n",
      "102/102 [==============================] - 0s 940us/step - loss: 1.0986\n",
      "Epoch 43/50\n",
      "102/102 [==============================] - 0s 879us/step - loss: 1.0986\n",
      "Epoch 44/50\n",
      "102/102 [==============================] - 0s 968us/step - loss: 1.0986\n",
      "Epoch 45/50\n",
      "102/102 [==============================] - 0s 933us/step - loss: 1.0986\n",
      "Epoch 46/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 47/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 48/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 49/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 50/50\n",
      "102/102 [==============================] - 0s 974us/step - loss: 1.0986\n",
      "Epoch 1/50\n",
      "102/102 [==============================] - 1s 1ms/step - loss: 1.0815\n",
      "Epoch 2/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.0430\n",
      "Epoch 3/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0105\n",
      "Epoch 4/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9749\n",
      "Epoch 5/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9473\n",
      "Epoch 6/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9210\n",
      "Epoch 7/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8987\n",
      "Epoch 8/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8822\n",
      "Epoch 9/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8610\n",
      "Epoch 10/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8447\n",
      "Epoch 11/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8311\n",
      "Epoch 12/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8131\n",
      "Epoch 13/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8007\n",
      "Epoch 14/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7860\n",
      "Epoch 15/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7750\n",
      "Epoch 16/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7651\n",
      "Epoch 17/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7527\n",
      "Epoch 18/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7475\n",
      "Epoch 19/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7359\n",
      "Epoch 20/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7261\n",
      "Epoch 21/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7179\n",
      "Epoch 22/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7100\n",
      "Epoch 23/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7026\n",
      "Epoch 24/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6971\n",
      "Epoch 25/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6902\n",
      "Epoch 26/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6815\n",
      "Epoch 27/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6766\n",
      "Epoch 28/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6688\n",
      "Epoch 29/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6646\n",
      "Epoch 30/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6585\n",
      "Epoch 31/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6544\n",
      "Epoch 32/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6492\n",
      "Epoch 33/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6435\n",
      "Epoch 34/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6374\n",
      "Epoch 35/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6346\n",
      "Epoch 36/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6283\n",
      "Epoch 37/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6242\n",
      "Epoch 38/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6217\n",
      "Epoch 39/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6167\n",
      "Epoch 40/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6124\n",
      "Epoch 41/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6076\n",
      "Epoch 42/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6043\n",
      "Epoch 43/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6022\n",
      "Epoch 44/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5968\n",
      "Epoch 45/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5920\n",
      "Epoch 46/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5898\n",
      "Epoch 47/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5839\n",
      "Epoch 48/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5807\n",
      "Epoch 49/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5762\n",
      "Epoch 50/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5749\n",
      "Epoch 1/50\n",
      "102/102 [==============================] - 1s 1ms/step - loss: 1.0804\n",
      "Epoch 2/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0333\n",
      "Epoch 3/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.0041\n",
      "Epoch 4/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9849\n",
      "Epoch 5/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9687\n",
      "Epoch 6/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9539\n",
      "Epoch 7/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9400\n",
      "Epoch 8/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9288\n",
      "Epoch 9/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9188\n",
      "Epoch 10/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9077\n",
      "Epoch 11/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8992\n",
      "Epoch 12/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8878\n",
      "Epoch 13/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8776\n",
      "Epoch 14/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8571\n",
      "Epoch 15/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7973\n",
      "Epoch 16/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7636\n",
      "Epoch 17/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7369\n",
      "Epoch 18/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7168\n",
      "Epoch 19/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6971\n",
      "Epoch 20/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6781\n",
      "Epoch 21/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6601\n",
      "Epoch 22/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6450\n",
      "Epoch 23/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6305\n",
      "Epoch 24/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6182\n",
      "Epoch 25/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6032\n",
      "Epoch 26/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5909\n",
      "Epoch 27/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5788\n",
      "Epoch 28/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5655\n",
      "Epoch 29/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5556\n",
      "Epoch 30/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5439\n",
      "Epoch 31/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5348\n",
      "Epoch 32/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5239\n",
      "Epoch 33/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5140\n",
      "Epoch 34/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5049\n",
      "Epoch 35/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4953\n",
      "Epoch 36/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4877\n",
      "Epoch 37/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4784\n",
      "Epoch 38/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4688\n",
      "Epoch 39/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4613\n",
      "Epoch 40/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4526\n",
      "Epoch 41/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4453\n",
      "Epoch 42/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4378\n",
      "Epoch 43/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4308\n",
      "Epoch 44/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4234\n",
      "Epoch 45/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4166\n",
      "Epoch 46/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4087\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4027\n",
      "Epoch 48/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3975\n",
      "Epoch 49/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.3912\n",
      "Epoch 50/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.3856\n",
      "Epoch 1/50\n",
      "102/102 [==============================] - 1s 3ms/step - loss: 1.0697\n",
      "Epoch 2/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.9676\n",
      "Epoch 3/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.9054\n",
      "Epoch 4/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.8577\n",
      "Epoch 5/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.8168\n",
      "Epoch 6/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.7785\n",
      "Epoch 7/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.7353\n",
      "Epoch 8/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6971\n",
      "Epoch 9/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6631\n",
      "Epoch 10/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6331\n",
      "Epoch 11/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6027\n",
      "Epoch 12/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5739\n",
      "Epoch 13/50\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5493\n",
      "Epoch 14/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5263\n",
      "Epoch 15/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5030\n",
      "Epoch 16/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4847\n",
      "Epoch 17/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4677\n",
      "Epoch 18/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4525\n",
      "Epoch 19/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4382\n",
      "Epoch 20/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4238\n",
      "Epoch 21/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4058\n",
      "Epoch 22/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3937\n",
      "Epoch 23/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3820\n",
      "Epoch 24/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3732\n",
      "Epoch 25/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3603\n",
      "Epoch 26/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3494\n",
      "Epoch 27/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3410\n",
      "Epoch 28/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3313\n",
      "Epoch 29/50\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3228\n",
      "Epoch 30/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3135\n",
      "Epoch 31/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3077\n",
      "Epoch 32/50\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2993\n",
      "Epoch 33/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2917\n",
      "Epoch 34/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2857\n",
      "Epoch 35/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2773\n",
      "Epoch 36/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2724\n",
      "Epoch 37/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2656\n",
      "Epoch 38/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2601\n",
      "Epoch 39/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2531\n",
      "Epoch 40/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2491\n",
      "Epoch 41/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2422\n",
      "Epoch 42/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2373\n",
      "Epoch 43/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2340\n",
      "Epoch 44/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2289\n",
      "Epoch 45/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2240\n",
      "Epoch 46/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2186\n",
      "Epoch 47/50\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2128\n",
      "Epoch 48/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2114\n",
      "Epoch 49/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2064\n",
      "Epoch 50/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2047\n",
      "Epoch 1/50\n",
      "102/102 [==============================] - 1s 3ms/step - loss: 1.0987\n",
      "Epoch 2/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 3/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 4/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 5/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 6/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 7/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 8/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 9/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 10/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 11/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 12/50\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0986\n",
      "Epoch 13/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 14/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 15/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 16/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 17/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 18/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 19/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 20/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 21/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 22/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 23/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 24/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 25/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 26/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 27/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 28/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 29/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 30/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 31/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 32/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 33/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 34/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 35/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 36/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 37/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 38/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 39/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 40/50\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0986\n",
      "Epoch 41/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 42/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 43/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 44/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 45/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 46/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 47/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 48/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 49/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 50/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 1/50\n",
      "102/102 [==============================] - 0s 989us/step - loss: 1.1103\n",
      "Epoch 2/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0988\n",
      "Epoch 3/50\n",
      "102/102 [==============================] - 0s 967us/step - loss: 1.0986\n",
      "Epoch 4/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0984\n",
      "Epoch 5/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0982\n",
      "Epoch 6/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0942\n",
      "Epoch 7/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0866\n",
      "Epoch 8/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0815\n",
      "Epoch 9/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0751\n",
      "Epoch 10/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0697\n",
      "Epoch 11/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0652\n",
      "Epoch 12/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0615\n",
      "Epoch 13/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0589\n",
      "Epoch 14/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0555\n",
      "Epoch 15/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0524\n",
      "Epoch 16/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0494\n",
      "Epoch 17/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0464\n",
      "Epoch 18/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0473\n",
      "Epoch 19/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0435\n",
      "Epoch 20/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0410\n",
      "Epoch 21/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0363\n",
      "Epoch 22/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0337\n",
      "Epoch 23/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0314\n",
      "Epoch 24/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0286\n",
      "Epoch 25/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0269\n",
      "Epoch 26/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0239\n",
      "Epoch 27/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0225\n",
      "Epoch 28/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0204\n",
      "Epoch 29/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0184\n",
      "Epoch 30/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0151\n",
      "Epoch 31/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0136\n",
      "Epoch 32/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0112\n",
      "Epoch 33/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0097\n",
      "Epoch 34/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0069\n",
      "Epoch 35/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0041\n",
      "Epoch 36/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0034\n",
      "Epoch 37/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0007\n",
      "Epoch 38/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9983\n",
      "Epoch 39/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9964\n",
      "Epoch 40/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9948\n",
      "Epoch 41/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9923\n",
      "Epoch 42/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9909\n",
      "Epoch 43/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9885\n",
      "Epoch 44/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9862\n",
      "Epoch 45/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9843\n",
      "Epoch 46/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9808\n",
      "Epoch 47/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9787\n",
      "Epoch 48/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9772\n",
      "Epoch 49/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9752\n",
      "Epoch 50/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9738\n",
      "Epoch 1/50\n",
      "102/102 [==============================] - 0s 830us/step - loss: 1.0986\n",
      "Epoch 2/50\n",
      "102/102 [==============================] - 0s 855us/step - loss: 1.0986\n",
      "Epoch 3/50\n",
      "102/102 [==============================] - 0s 800us/step - loss: 1.0986\n",
      "Epoch 4/50\n",
      "102/102 [==============================] - 0s 762us/step - loss: 1.0986\n",
      "Epoch 5/50\n",
      "102/102 [==============================] - 0s 838us/step - loss: 1.0986\n",
      "Epoch 6/50\n",
      "102/102 [==============================] - 0s 855us/step - loss: 1.0986\n",
      "Epoch 7/50\n",
      "102/102 [==============================] - 0s 901us/step - loss: 1.0986\n",
      "Epoch 8/50\n",
      "102/102 [==============================] - 0s 912us/step - loss: 1.0986\n",
      "Epoch 9/50\n",
      "102/102 [==============================] - 0s 831us/step - loss: 1.0986\n",
      "Epoch 10/50\n",
      "102/102 [==============================] - 0s 853us/step - loss: 1.0986\n",
      "Epoch 11/50\n",
      "102/102 [==============================] - 0s 850us/step - loss: 1.0986\n",
      "Epoch 12/50\n",
      "102/102 [==============================] - 0s 909us/step - loss: 1.0986\n",
      "Epoch 13/50\n",
      "102/102 [==============================] - 0s 903us/step - loss: 1.0986\n",
      "Epoch 14/50\n",
      "102/102 [==============================] - 0s 873us/step - loss: 1.0986\n",
      "Epoch 15/50\n",
      "102/102 [==============================] - 0s 829us/step - loss: 1.0986\n",
      "Epoch 16/50\n",
      "102/102 [==============================] - 0s 886us/step - loss: 1.0986\n",
      "Epoch 17/50\n",
      "102/102 [==============================] - 0s 829us/step - loss: 1.0986\n",
      "Epoch 18/50\n",
      "102/102 [==============================] - 0s 820us/step - loss: 1.0986\n",
      "Epoch 19/50\n",
      "102/102 [==============================] - 0s 823us/step - loss: 1.0986\n",
      "Epoch 20/50\n",
      "102/102 [==============================] - 0s 824us/step - loss: 1.0986\n",
      "Epoch 21/50\n",
      "102/102 [==============================] - 0s 851us/step - loss: 1.0986\n",
      "Epoch 22/50\n",
      "102/102 [==============================] - 0s 826us/step - loss: 1.0986\n",
      "Epoch 23/50\n",
      "102/102 [==============================] - 0s 823us/step - loss: 1.0986\n",
      "Epoch 24/50\n",
      "102/102 [==============================] - 0s 870us/step - loss: 1.0986\n",
      "Epoch 25/50\n",
      "102/102 [==============================] - 0s 809us/step - loss: 1.0986\n",
      "Epoch 26/50\n",
      "102/102 [==============================] - 0s 899us/step - loss: 1.0986\n",
      "Epoch 27/50\n",
      "102/102 [==============================] - 0s 826us/step - loss: 1.0986\n",
      "Epoch 28/50\n",
      "102/102 [==============================] - 0s 855us/step - loss: 1.0986\n",
      "Epoch 29/50\n",
      "102/102 [==============================] - 0s 946us/step - loss: 1.0986\n",
      "Epoch 30/50\n",
      "102/102 [==============================] - 0s 915us/step - loss: 1.0986\n",
      "Epoch 31/50\n",
      "102/102 [==============================] - 0s 898us/step - loss: 1.0986\n",
      "Epoch 32/50\n",
      "102/102 [==============================] - 0s 893us/step - loss: 1.0986\n",
      "Epoch 33/50\n",
      "102/102 [==============================] - 0s 870us/step - loss: 1.0986\n",
      "Epoch 34/50\n",
      "102/102 [==============================] - 0s 880us/step - loss: 1.0986\n",
      "Epoch 35/50\n",
      "102/102 [==============================] - 0s 879us/step - loss: 1.0986\n",
      "Epoch 36/50\n",
      "102/102 [==============================] - 0s 866us/step - loss: 1.0986\n",
      "Epoch 37/50\n",
      "102/102 [==============================] - 0s 818us/step - loss: 1.0986\n",
      "Epoch 38/50\n",
      "102/102 [==============================] - 0s 818us/step - loss: 1.0986\n",
      "Epoch 39/50\n",
      "102/102 [==============================] - 0s 849us/step - loss: 1.0986\n",
      "Epoch 40/50\n",
      "102/102 [==============================] - 0s 839us/step - loss: 1.0986\n",
      "Epoch 41/50\n",
      "102/102 [==============================] - 0s 826us/step - loss: 1.0986\n",
      "Epoch 42/50\n",
      "102/102 [==============================] - 0s 826us/step - loss: 1.0986\n",
      "Epoch 43/50\n",
      "102/102 [==============================] - 0s 827us/step - loss: 1.0986\n",
      "Epoch 44/50\n",
      "102/102 [==============================] - 0s 897us/step - loss: 1.0986\n",
      "Epoch 45/50\n",
      "102/102 [==============================] - 0s 894us/step - loss: 1.0986\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 985us/step - loss: 1.0986\n",
      "Epoch 47/50\n",
      "102/102 [==============================] - 0s 843us/step - loss: 1.0986\n",
      "Epoch 48/50\n",
      "102/102 [==============================] - 0s 866us/step - loss: 1.0986\n",
      "Epoch 49/50\n",
      "102/102 [==============================] - 0s 830us/step - loss: 1.0986\n",
      "Epoch 50/50\n",
      "102/102 [==============================] - 0s 908us/step - loss: 1.0986\n",
      "Epoch 1/50\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.8409\n",
      "Epoch 2/50\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.6138\n",
      "Epoch 3/50\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.4950\n",
      "Epoch 4/50\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.4411\n",
      "Epoch 5/50\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.3742\n",
      "Epoch 6/50\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.3345\n",
      "Epoch 7/50\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.2865\n",
      "Epoch 8/50\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.2689\n",
      "Epoch 9/50\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.2617\n",
      "Epoch 10/50\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.2322\n",
      "Epoch 11/50\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.2170\n",
      "Epoch 12/50\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.1972\n",
      "Epoch 13/50\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.1984\n",
      "Epoch 14/50\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.1745\n",
      "Epoch 15/50\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.2030\n",
      "Epoch 16/50\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.1621\n",
      "Epoch 17/50\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.1503\n",
      "Epoch 18/50\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.1476\n",
      "Epoch 19/50\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.1335\n",
      "Epoch 20/50\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.1177\n",
      "Epoch 21/50\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.0977\n",
      "Epoch 22/50\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0974\n",
      "Epoch 23/50\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0945\n",
      "Epoch 24/50\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.0815\n",
      "Epoch 25/50\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0750\n",
      "Epoch 26/50\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.0676\n",
      "Epoch 27/50\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0655\n",
      "Epoch 28/50\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.0609\n",
      "Epoch 29/50\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.0721\n",
      "Epoch 30/50\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.1118\n",
      "Epoch 31/50\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0657\n",
      "Epoch 32/50\n",
      "102/102 [==============================] - 1s 9ms/step - loss: 0.0416\n",
      "Epoch 33/50\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 0.0946\n",
      "Epoch 34/50\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 0.0584\n",
      "Epoch 35/50\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0416\n",
      "Epoch 36/50\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0261\n",
      "Epoch 37/50\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0218\n",
      "Epoch 38/50\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0315\n",
      "Epoch 39/50\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0406\n",
      "Epoch 40/50\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0295\n",
      "Epoch 41/50\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0569\n",
      "Epoch 42/50\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0174\n",
      "Epoch 43/50\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.0131\n",
      "Epoch 44/50\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0123\n",
      "Epoch 45/50\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.0086\n",
      "Epoch 46/50\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0094\n",
      "Epoch 47/50\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0278\n",
      "Epoch 48/50\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0259\n",
      "Epoch 49/50\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0169\n",
      "Epoch 50/50\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0343\n",
      "Epoch 1/50\n",
      "102/102 [==============================] - 1s 994us/step - loss: 1.0986\n",
      "Epoch 2/50\n",
      "102/102 [==============================] - 0s 963us/step - loss: 1.0986\n",
      "Epoch 3/50\n",
      "102/102 [==============================] - 0s 969us/step - loss: 1.0986\n",
      "Epoch 4/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 5/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 6/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 7/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 8/50\n",
      "102/102 [==============================] - 0s 978us/step - loss: 1.0986\n",
      "Epoch 9/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 10/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 11/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 12/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 13/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 14/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 15/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 16/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 17/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 18/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 19/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 20/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 21/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 22/50\n",
      "102/102 [==============================] - 0s 959us/step - loss: 1.0986\n",
      "Epoch 23/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 24/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 25/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 26/50\n",
      "102/102 [==============================] - 0s 987us/step - loss: 1.0986\n",
      "Epoch 27/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 28/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 29/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 30/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 31/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 32/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 33/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 34/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 35/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 36/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 37/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 38/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 39/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 40/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 41/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 42/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 43/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 44/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 45/50\n",
      "102/102 [==============================] - 0s 984us/step - loss: 1.0986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 47/50\n",
      "102/102 [==============================] - 0s 981us/step - loss: 1.0986\n",
      "Epoch 48/50\n",
      "102/102 [==============================] - 0s 923us/step - loss: 1.0986\n",
      "Epoch 49/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 50/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 1/50\n",
      "102/102 [==============================] - 0s 995us/step - loss: 1.0986\n",
      "Epoch 2/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 3/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 4/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 5/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 6/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 7/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 8/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 9/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 10/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 11/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 12/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 13/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 14/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.0986\n",
      "Epoch 15/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 16/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 17/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 18/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 19/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 20/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 21/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 22/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 23/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 24/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 25/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 26/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 27/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 28/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 29/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 30/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 31/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 32/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 33/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 34/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 35/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 36/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 37/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 38/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 39/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 40/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 41/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 42/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.0986\n",
      "Epoch 43/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 44/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 45/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 46/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 47/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 48/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 49/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 50/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 1/50\n",
      "102/102 [==============================] - 1s 4ms/step - loss: 1.0993\n",
      "Epoch 2/50\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0987\n",
      "Epoch 3/50\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0987\n",
      "Epoch 4/50\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0987\n",
      "Epoch 5/50\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0987\n",
      "Epoch 6/50\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0987\n",
      "Epoch 7/50\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0986\n",
      "Epoch 8/50\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.0987\n",
      "Epoch 9/50\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0987\n",
      "Epoch 10/50\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0987\n",
      "Epoch 11/50\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0987\n",
      "Epoch 12/50\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 1.0987\n",
      "Epoch 13/50\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0987\n",
      "Epoch 14/50\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0987\n",
      "Epoch 15/50\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0987\n",
      "Epoch 16/50\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0987\n",
      "Epoch 17/50\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0987\n",
      "Epoch 18/50\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0987\n",
      "Epoch 19/50\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0987\n",
      "Epoch 20/50\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 1.0986\n",
      "Epoch 21/50\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0987\n",
      "Epoch 22/50\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0987\n",
      "Epoch 23/50\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0987\n",
      "Epoch 24/50\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0987\n",
      "Epoch 25/50\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0987\n",
      "Epoch 26/50\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0987\n",
      "Epoch 27/50\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0987\n",
      "Epoch 28/50\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0987\n",
      "Epoch 29/50\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0987\n",
      "Epoch 30/50\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0987\n",
      "Epoch 31/50\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.0987\n",
      "Epoch 32/50\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0987\n",
      "Epoch 33/50\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0986\n",
      "Epoch 34/50\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0987\n",
      "Epoch 35/50\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0987\n",
      "Epoch 36/50\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0987\n",
      "Epoch 37/50\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0987\n",
      "Epoch 38/50\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0987\n",
      "Epoch 39/50\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0987\n",
      "Epoch 40/50\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 1.0987\n",
      "Epoch 41/50\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 1.0986\n",
      "Epoch 42/50\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 1.0987\n",
      "Epoch 43/50\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 1.0987\n",
      "Epoch 44/50\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0986\n",
      "Epoch 45/50\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0987\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0987\n",
      "Epoch 47/50\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0987\n",
      "Epoch 48/50\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0987\n",
      "Epoch 49/50\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0986\n",
      "Epoch 50/50\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0987\n",
      "Epoch 1/50\n",
      "102/102 [==============================] - 0s 906us/step - loss: 1.1162\n",
      "Epoch 2/50\n",
      "102/102 [==============================] - 0s 886us/step - loss: 1.0995\n",
      "Epoch 3/50\n",
      "102/102 [==============================] - 0s 899us/step - loss: 1.0991\n",
      "Epoch 4/50\n",
      "102/102 [==============================] - 0s 987us/step - loss: 1.0990\n",
      "Epoch 5/50\n",
      "102/102 [==============================] - 0s 940us/step - loss: 1.0988\n",
      "Epoch 6/50\n",
      "102/102 [==============================] - 0s 997us/step - loss: 1.0988\n",
      "Epoch 7/50\n",
      "102/102 [==============================] - 0s 980us/step - loss: 1.0987\n",
      "Epoch 8/50\n",
      "102/102 [==============================] - 0s 915us/step - loss: 1.0986\n",
      "Epoch 9/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "Epoch 10/50\n",
      "102/102 [==============================] - 0s 978us/step - loss: 1.0985\n",
      "Epoch 11/50\n",
      "102/102 [==============================] - 0s 982us/step - loss: 1.0984\n",
      "Epoch 12/50\n",
      "102/102 [==============================] - 0s 962us/step - loss: 1.0982\n",
      "Epoch 13/50\n",
      "102/102 [==============================] - 0s 906us/step - loss: 1.0981\n",
      "Epoch 14/50\n",
      "102/102 [==============================] - 0s 920us/step - loss: 1.0979\n",
      "Epoch 15/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0978\n",
      "Epoch 16/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0977\n",
      "Epoch 17/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0976\n",
      "Epoch 18/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0974\n",
      "Epoch 19/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0973\n",
      "Epoch 20/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0971\n",
      "Epoch 21/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0970\n",
      "Epoch 22/50\n",
      "102/102 [==============================] - 0s 994us/step - loss: 1.0968\n",
      "Epoch 23/50\n",
      "102/102 [==============================] - 0s 984us/step - loss: 1.0967\n",
      "Epoch 24/50\n",
      "102/102 [==============================] - 0s 950us/step - loss: 1.0964\n",
      "Epoch 25/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0964\n",
      "Epoch 26/50\n",
      "102/102 [==============================] - 0s 993us/step - loss: 1.0962\n",
      "Epoch 27/50\n",
      "102/102 [==============================] - 0s 988us/step - loss: 1.0961\n",
      "Epoch 28/50\n",
      "102/102 [==============================] - 0s 937us/step - loss: 1.0962\n",
      "Epoch 29/50\n",
      "102/102 [==============================] - 0s 962us/step - loss: 1.0958\n",
      "Epoch 30/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0957\n",
      "Epoch 31/50\n",
      "102/102 [==============================] - 0s 995us/step - loss: 1.0954\n",
      "Epoch 32/50\n",
      "102/102 [==============================] - 0s 954us/step - loss: 1.0951\n",
      "Epoch 33/50\n",
      "102/102 [==============================] - 0s 948us/step - loss: 1.0948\n",
      "Epoch 34/50\n",
      "102/102 [==============================] - 0s 977us/step - loss: 1.0943\n",
      "Epoch 35/50\n",
      "102/102 [==============================] - 0s 924us/step - loss: 1.0947\n",
      "Epoch 36/50\n",
      "102/102 [==============================] - 0s 904us/step - loss: 1.0937\n",
      "Epoch 37/50\n",
      "102/102 [==============================] - 0s 920us/step - loss: 1.0935\n",
      "Epoch 38/50\n",
      "102/102 [==============================] - 0s 940us/step - loss: 1.0924\n",
      "Epoch 39/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0915\n",
      "Epoch 40/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0902\n",
      "Epoch 41/50\n",
      "102/102 [==============================] - 0s 938us/step - loss: 1.0887\n",
      "Epoch 42/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0874\n",
      "Epoch 43/50\n",
      "102/102 [==============================] - 0s 934us/step - loss: 1.0857\n",
      "Epoch 44/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0834\n",
      "Epoch 45/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0812\n",
      "Epoch 46/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0797\n",
      "Epoch 47/50\n",
      "102/102 [==============================] - 0s 935us/step - loss: 1.0776\n",
      "Epoch 48/50\n",
      "102/102 [==============================] - 0s 949us/step - loss: 1.0761\n",
      "Epoch 49/50\n",
      "102/102 [==============================] - 0s 982us/step - loss: 1.0748\n",
      "Epoch 50/50\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0735\n",
      "Epoch 1/50\n",
      "102/102 [==============================] - 1s 3ms/step - loss: 1.1010\n",
      "Epoch 2/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 3/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 4/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 5/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 6/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 7/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 8/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 9/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 10/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 11/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 12/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 13/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 14/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 15/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 16/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 17/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 18/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 19/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 20/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 21/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 22/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 23/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 24/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 25/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 26/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 27/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 28/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 29/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 30/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 31/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 32/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 33/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 34/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 35/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 36/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 37/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 38/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 39/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 40/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 41/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 42/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 43/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 44/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 45/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 46/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 47/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 48/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n",
      "Epoch 49/50\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0986\n",
      "Epoch 50/50\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0986\n"
     ]
    }
   ],
   "source": [
    "num_iters = 20\n",
    "num_epochs = 50\n",
    "l_1_units_list = []\n",
    "l_2_units_list = []\n",
    "l_3_units_list = []\n",
    "learning_rate_val_list = []\n",
    "J_list = np.zeros((num_epochs,num_iters))\n",
    "\n",
    "for k in range(num_iters):    \n",
    "    np.random.seed(42 + k)\n",
    "    #Random search of hyperparameters\n",
    "    l_1_units = int(10**(np.random.rand()*2 + 1))\n",
    "    l_2_units = int(l_1_units / (10**(0.5 + np.random.rand())))\n",
    "    l_3_units = int(l_2_units / (10**(0.5 + np.random.rand())))\n",
    "    learning_rate_val = 10**(-np.random.rand()*3 - 3)\n",
    "    \n",
    "    l_1_units_list.append(l_1_units)\n",
    "    l_2_units_list.append(l_2_units)\n",
    "    l_3_units_list.append(l_3_units)\n",
    "    learning_rate_val_list.append(learning_rate_val)\n",
    "    \n",
    "    tf.random.set_seed(1234) # for consistent results\n",
    "    model = Sequential(\n",
    "        [               \n",
    "            ### START CODE HERE ### \n",
    "            Dense(units=l_1_units, activation='relu'),\n",
    "            Dense(units=l_2_units, activation='relu'),\n",
    "            Dense(units=l_3_units, activation='relu'),\n",
    "            Dense(units=3, activation='linear')\n",
    "            ### END CODE HERE ### \n",
    "        ], name = \"my_model\" \n",
    "    )\n",
    "    model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                 optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate_val),)\n",
    "    history = model.fit(X, y, epochs=num_epochs)\n",
    "    J_list[:,k] = history.history['loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720526c8",
   "metadata": {},
   "source": [
    "Out of each set of hyperparameters it seems that set 10 provides a steady yet timely decrease in the cost function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "daf63c60",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_iters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [47]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m marker_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m^\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[43mnum_iters\u001b[49m):\n\u001b[0;32m      3\u001b[0m     plt\u001b[38;5;241m.\u001b[39mplot(J_list[:,k], label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k), marker\u001b[38;5;241m=\u001b[39mmarker_list[k \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m4\u001b[39m])\n\u001b[0;32m      4\u001b[0m     plt\u001b[38;5;241m.\u001b[39mlegend(loc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupper center\u001b[39m\u001b[38;5;124m'\u001b[39m,bbox_to_anchor\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.05\u001b[39m), fancybox\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, shadow\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, ncol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'num_iters' is not defined"
     ]
    }
   ],
   "source": [
    "marker_list = [\"o\",\"s\",\"^\",\"|\"]\n",
    "for k in range(num_iters):\n",
    "    plt.plot(J_list[:,k], label = \"Params: {}\".format(k), marker=marker_list[k % 4])\n",
    "    plt.legend(loc='upper center',bbox_to_anchor=(0.5, -0.05), fancybox=True, shadow=True, ncol=5)\n",
    "plt.ylabel(\"Cost function\"), plt.xlabel(\"Epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92624935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For parameters k=10: layer 1 has 442 units, layer 2 has 131 units and layer 3 has 25 units.\n",
      "For parameters k=10: the learning rate is 1.3955155880057205e-05.\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "print(\"For parameters k={}: layer 1 has {} units, layer 2 has {} units and layer 3 has {} units.\".format(k, l_1_units_list[k], l_2_units_list[k], l_3_units_list[k]))\n",
    "print(\"For parameters k={}: the learning rate is {}.\".format(k, learning_rate_val_list[k], l_2_units_list[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89565526",
   "metadata": {},
   "source": [
    "### Convergence of the cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5ebe2f",
   "metadata": {},
   "source": [
    "Lets test convergence over more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05e1d137",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "102/102 [==============================] - 1s 4ms/step - loss: 1.0747\n",
      "Epoch 2/500\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.9768\n",
      "Epoch 3/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.9155\n",
      "Epoch 4/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.8688\n",
      "Epoch 5/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.8284\n",
      "Epoch 6/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.7905\n",
      "Epoch 7/500\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.7480\n",
      "Epoch 8/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.7125\n",
      "Epoch 9/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6806\n",
      "Epoch 10/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6529\n",
      "Epoch 11/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6234\n",
      "Epoch 12/500\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5951\n",
      "Epoch 13/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5692\n",
      "Epoch 14/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5460\n",
      "Epoch 15/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5242\n",
      "Epoch 16/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5063\n",
      "Epoch 17/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4891\n",
      "Epoch 18/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4731\n",
      "Epoch 19/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4584\n",
      "Epoch 20/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4431\n",
      "Epoch 21/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4253\n",
      "Epoch 22/500\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4128\n",
      "Epoch 23/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4012\n",
      "Epoch 24/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3915\n",
      "Epoch 25/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3786\n",
      "Epoch 26/500\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3677\n",
      "Epoch 27/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3587\n",
      "Epoch 28/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3486\n",
      "Epoch 29/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3393\n",
      "Epoch 30/500\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3301\n",
      "Epoch 31/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3241\n",
      "Epoch 32/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3153\n",
      "Epoch 33/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3074\n",
      "Epoch 34/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3013\n",
      "Epoch 35/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2932\n",
      "Epoch 36/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2882\n",
      "Epoch 37/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2818\n",
      "Epoch 38/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2762\n",
      "Epoch 39/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2697\n",
      "Epoch 40/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2645\n",
      "Epoch 41/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2579\n",
      "Epoch 42/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2528\n",
      "Epoch 43/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2499\n",
      "Epoch 44/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2439\n",
      "Epoch 45/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2390\n",
      "Epoch 46/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2336\n",
      "Epoch 47/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2279\n",
      "Epoch 48/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2258\n",
      "Epoch 49/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2210\n",
      "Epoch 50/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2189\n",
      "Epoch 51/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2139\n",
      "Epoch 52/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2095\n",
      "Epoch 53/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2047\n",
      "Epoch 54/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2017\n",
      "Epoch 55/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1980\n",
      "Epoch 56/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1945\n",
      "Epoch 57/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1905\n",
      "Epoch 58/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1886\n",
      "Epoch 59/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1846\n",
      "Epoch 60/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1809\n",
      "Epoch 61/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1769\n",
      "Epoch 62/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1773\n",
      "Epoch 63/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1708\n",
      "Epoch 64/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1726\n",
      "Epoch 65/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1650\n",
      "Epoch 66/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1646\n",
      "Epoch 67/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1596\n",
      "Epoch 68/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1594\n",
      "Epoch 69/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1549\n",
      "Epoch 70/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1524\n",
      "Epoch 71/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1495\n",
      "Epoch 72/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1479\n",
      "Epoch 73/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1448\n",
      "Epoch 74/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1432\n",
      "Epoch 75/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1403\n",
      "Epoch 76/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1378\n",
      "Epoch 77/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1348\n",
      "Epoch 78/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1336\n",
      "Epoch 79/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1295\n",
      "Epoch 80/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1294\n",
      "Epoch 81/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1271\n",
      "Epoch 82/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1239\n",
      "Epoch 83/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1213\n",
      "Epoch 84/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1206\n",
      "Epoch 85/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1182\n",
      "Epoch 86/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1156\n",
      "Epoch 87/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1137\n",
      "Epoch 88/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1112\n",
      "Epoch 89/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1116\n",
      "Epoch 90/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1101\n",
      "Epoch 91/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1065\n",
      "Epoch 92/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1061\n",
      "Epoch 93/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1034\n",
      "Epoch 94/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1016\n",
      "Epoch 95/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1008\n",
      "Epoch 96/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0964\n",
      "Epoch 97/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0958\n",
      "Epoch 98/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0956\n",
      "Epoch 99/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0923\n",
      "Epoch 100/500\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0906\n",
      "Epoch 101/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0886\n",
      "Epoch 102/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0888\n",
      "Epoch 103/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0865\n",
      "Epoch 104/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0849\n",
      "Epoch 105/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0846\n",
      "Epoch 106/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0807\n",
      "Epoch 107/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0799\n",
      "Epoch 108/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0811\n",
      "Epoch 109/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0780\n",
      "Epoch 110/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0761\n",
      "Epoch 111/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0741\n",
      "Epoch 112/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0736\n",
      "Epoch 113/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0734\n",
      "Epoch 114/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0713\n",
      "Epoch 115/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0703\n",
      "Epoch 116/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0692\n",
      "Epoch 117/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0676\n",
      "Epoch 118/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0656\n",
      "Epoch 119/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0639\n",
      "Epoch 120/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0629\n",
      "Epoch 121/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0609\n",
      "Epoch 122/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0601\n",
      "Epoch 123/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0598\n",
      "Epoch 124/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0589\n",
      "Epoch 125/500\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0593\n",
      "Epoch 126/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0571\n",
      "Epoch 127/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0566\n",
      "Epoch 128/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0552\n",
      "Epoch 129/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0546\n",
      "Epoch 130/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0528\n",
      "Epoch 131/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0517\n",
      "Epoch 132/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0499\n",
      "Epoch 133/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0492\n",
      "Epoch 134/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0476\n",
      "Epoch 135/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0468\n",
      "Epoch 136/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0461\n",
      "Epoch 137/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0475\n",
      "Epoch 138/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0469\n",
      "Epoch 139/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0446\n",
      "Epoch 140/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0432\n",
      "Epoch 141/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0418\n",
      "Epoch 142/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0406\n",
      "Epoch 143/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0399\n",
      "Epoch 144/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0396\n",
      "Epoch 145/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0386\n",
      "Epoch 146/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0376\n",
      "Epoch 147/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0380\n",
      "Epoch 148/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0364\n",
      "Epoch 149/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0360\n",
      "Epoch 150/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0378\n",
      "Epoch 151/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0339\n",
      "Epoch 152/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0337\n",
      "Epoch 153/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0327\n",
      "Epoch 154/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0326\n",
      "Epoch 155/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0321\n",
      "Epoch 156/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0309\n",
      "Epoch 157/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0293\n",
      "Epoch 158/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0293\n",
      "Epoch 159/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0285\n",
      "Epoch 160/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0286\n",
      "Epoch 161/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0273\n",
      "Epoch 162/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0290\n",
      "Epoch 163/500\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0266\n",
      "Epoch 164/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0257\n",
      "Epoch 165/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0253\n",
      "Epoch 166/500\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0255\n",
      "Epoch 167/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0238\n",
      "Epoch 168/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0240\n",
      "Epoch 169/500\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0234\n",
      "Epoch 170/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0225\n",
      "Epoch 171/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0223\n",
      "Epoch 172/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0217\n",
      "Epoch 173/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0217\n",
      "Epoch 174/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0209\n",
      "Epoch 175/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0200\n",
      "Epoch 176/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0201\n",
      "Epoch 177/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0208\n",
      "Epoch 178/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0197\n",
      "Epoch 179/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0195\n",
      "Epoch 180/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0190\n",
      "Epoch 181/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0176\n",
      "Epoch 182/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0185\n",
      "Epoch 183/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0168\n",
      "Epoch 184/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 185/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 186/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 187/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 188/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 189/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0148\n",
      "Epoch 190/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0142\n",
      "Epoch 191/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0136\n",
      "Epoch 192/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0139\n",
      "Epoch 193/500\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0133\n",
      "Epoch 194/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 195/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0128\n",
      "Epoch 196/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0121\n",
      "Epoch 197/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0123\n",
      "Epoch 198/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0121\n",
      "Epoch 199/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0115\n",
      "Epoch 200/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0116\n",
      "Epoch 201/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0111\n",
      "Epoch 202/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0109\n",
      "Epoch 203/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0111\n",
      "Epoch 204/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0104\n",
      "Epoch 205/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0099\n",
      "Epoch 206/500\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0101\n",
      "Epoch 207/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0095\n",
      "Epoch 208/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0098\n",
      "Epoch 209/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0095\n",
      "Epoch 210/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0088\n",
      "Epoch 211/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0086\n",
      "Epoch 212/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0087\n",
      "Epoch 213/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0090\n",
      "Epoch 214/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0084\n",
      "Epoch 215/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0090\n",
      "Epoch 216/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0085\n",
      "Epoch 217/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0076\n",
      "Epoch 218/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0070\n",
      "Epoch 219/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0074\n",
      "Epoch 220/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0068\n",
      "Epoch 221/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0071\n",
      "Epoch 222/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0067\n",
      "Epoch 223/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0064\n",
      "Epoch 224/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0065\n",
      "Epoch 225/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0061\n",
      "Epoch 226/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0063\n",
      "Epoch 227/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0062\n",
      "Epoch 228/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0056\n",
      "Epoch 229/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0056\n",
      "Epoch 230/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0059\n",
      "Epoch 231/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0054\n",
      "Epoch 232/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0050\n",
      "Epoch 233/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0051\n",
      "Epoch 234/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0048\n",
      "Epoch 235/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0048\n",
      "Epoch 236/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0047\n",
      "Epoch 237/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0048\n",
      "Epoch 238/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0046\n",
      "Epoch 239/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0046\n",
      "Epoch 240/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0041\n",
      "Epoch 241/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0044\n",
      "Epoch 242/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0045\n",
      "Epoch 243/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0038\n",
      "Epoch 244/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0040\n",
      "Epoch 245/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0036\n",
      "Epoch 246/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0037\n",
      "Epoch 247/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0035\n",
      "Epoch 248/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0036\n",
      "Epoch 249/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0035\n",
      "Epoch 250/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0033\n",
      "Epoch 251/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0031\n",
      "Epoch 252/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0035\n",
      "Epoch 253/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0035\n",
      "Epoch 254/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0030\n",
      "Epoch 255/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0031\n",
      "Epoch 256/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0030\n",
      "Epoch 257/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0028\n",
      "Epoch 258/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 259/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0027\n",
      "Epoch 260/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 261/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0027\n",
      "Epoch 262/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 263/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 264/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 265/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0022\n",
      "Epoch 266/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0021\n",
      "Epoch 267/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0021\n",
      "Epoch 268/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0020\n",
      "Epoch 269/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0021\n",
      "Epoch 270/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0019\n",
      "Epoch 271/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0021\n",
      "Epoch 272/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0017\n",
      "Epoch 273/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0018\n",
      "Epoch 274/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0017\n",
      "Epoch 275/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0021\n",
      "Epoch 276/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0016\n",
      "Epoch 277/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0019\n",
      "Epoch 278/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0022\n",
      "Epoch 279/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0016\n",
      "Epoch 280/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0015\n",
      "Epoch 281/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0014\n",
      "Epoch 282/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0013\n",
      "Epoch 283/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0014\n",
      "Epoch 284/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0014\n",
      "Epoch 285/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0014\n",
      "Epoch 286/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0039\n",
      "Epoch 287/500\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0012\n",
      "Epoch 288/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0012\n",
      "Epoch 289/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0011\n",
      "Epoch 290/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0011\n",
      "Epoch 291/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0011\n",
      "Epoch 292/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0011\n",
      "Epoch 293/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0011\n",
      "Epoch 294/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0010\n",
      "Epoch 295/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0010\n",
      "Epoch 296/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 9.4911e-04\n",
      "Epoch 297/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 9.7633e-04\n",
      "Epoch 298/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 9.8568e-04\n",
      "Epoch 299/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 8.9304e-04\n",
      "Epoch 300/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 8.8149e-04\n",
      "Epoch 301/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0011\n",
      "Epoch 302/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 9.1153e-04\n",
      "Epoch 303/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 8.6818e-04\n",
      "Epoch 304/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 8.3164e-04\n",
      "Epoch 305/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 7.9128e-04\n",
      "Epoch 306/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 8.3832e-04\n",
      "Epoch 307/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 7.8636e-04\n",
      "Epoch 308/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 7.4460e-04\n",
      "Epoch 309/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 7.5216e-04\n",
      "Epoch 310/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 7.1371e-04\n",
      "Epoch 311/500\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 8.0603e-04\n",
      "Epoch 312/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 7.2135e-04\n",
      "Epoch 313/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 6.8879e-04\n",
      "Epoch 314/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 6.8375e-04\n",
      "Epoch 315/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 7.3472e-04\n",
      "Epoch 316/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 9.5354e-04\n",
      "Epoch 317/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 5.9937e-04\n",
      "Epoch 318/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 7.6356e-04\n",
      "Epoch 319/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 6.0389e-04\n",
      "Epoch 320/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 5.4274e-04\n",
      "Epoch 321/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0010\n",
      "Epoch 322/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 5.9262e-04\n",
      "Epoch 323/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 4.7891e-04\n",
      "Epoch 324/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 4.9600e-04\n",
      "Epoch 325/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 4.6445e-04\n",
      "Epoch 326/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 4.8995e-04\n",
      "Epoch 327/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 4.6618e-04\n",
      "Epoch 328/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 4.4845e-04\n",
      "Epoch 329/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 4.1669e-04\n",
      "Epoch 330/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 6.0004e-04\n",
      "Epoch 331/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 6.8820e-04\n",
      "Epoch 332/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 3.9205e-04\n",
      "Epoch 333/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 3.6505e-04\n",
      "Epoch 334/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 3.7879e-04\n",
      "Epoch 335/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 3.9732e-04\n",
      "Epoch 336/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 3.4890e-04\n",
      "Epoch 337/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 3.3471e-04\n",
      "Epoch 338/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 3.6806e-04\n",
      "Epoch 339/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 4.3936e-04\n",
      "Epoch 340/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 3.2751e-04\n",
      "Epoch 341/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 3.3124e-04\n",
      "Epoch 342/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 2.9104e-04\n",
      "Epoch 343/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 2.9080e-04\n",
      "Epoch 344/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 2.8952e-04\n",
      "Epoch 345/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 3.3666e-04\n",
      "Epoch 346/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 2.7873e-04\n",
      "Epoch 347/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 2.6343e-04\n",
      "Epoch 348/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 2.4560e-04\n",
      "Epoch 349/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 3.4508e-04\n",
      "Epoch 350/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 3.2143e-04\n",
      "Epoch 351/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 2.7050e-04\n",
      "Epoch 352/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 2.2361e-04\n",
      "Epoch 353/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 2.2144e-04\n",
      "Epoch 354/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 2.0803e-04\n",
      "Epoch 355/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 2.1595e-04\n",
      "Epoch 356/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 2.0667e-04\n",
      "Epoch 357/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 2.0011e-04\n",
      "Epoch 358/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 2.1505e-04\n",
      "Epoch 359/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.9017e-04\n",
      "Epoch 360/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 2.3646e-04\n",
      "Epoch 361/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 3.3776e-04\n",
      "Epoch 362/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 2.0164e-04\n",
      "Epoch 363/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.7563e-04\n",
      "Epoch 364/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.6528e-04\n",
      "Epoch 365/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.6759e-04\n",
      "Epoch 366/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.5707e-04\n",
      "Epoch 367/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.5570e-04\n",
      "Epoch 368/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.4644e-04\n",
      "Epoch 369/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.4393e-04\n",
      "Epoch 370/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.4097e-04\n",
      "Epoch 371/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.5991e-04\n",
      "Epoch 372/500\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.3532e-04\n",
      "Epoch 373/500\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.2288e-04\n",
      "Epoch 374/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.2707e-04\n",
      "Epoch 375/500\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1607e-04\n",
      "Epoch 376/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.5008e-04\n",
      "Epoch 377/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0072\n",
      "Epoch 378/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 4.4911e-04\n",
      "Epoch 379/500\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 2.0565e-04\n",
      "Epoch 380/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.8526e-04\n",
      "Epoch 381/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.7251e-04\n",
      "Epoch 382/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.5703e-04\n",
      "Epoch 383/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.4824e-04\n",
      "Epoch 384/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.3950e-04\n",
      "Epoch 385/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.3358e-04\n",
      "Epoch 386/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 3ms/step - loss: 1.2693e-04\n",
      "Epoch 387/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.2246e-04\n",
      "Epoch 388/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.1793e-04\n",
      "Epoch 389/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.1475e-04\n",
      "Epoch 390/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.1062e-04\n",
      "Epoch 391/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0926e-04\n",
      "Epoch 392/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0479e-04\n",
      "Epoch 393/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0273e-04\n",
      "Epoch 394/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0066e-04\n",
      "Epoch 395/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 9.8144e-05\n",
      "Epoch 396/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 9.6188e-05\n",
      "Epoch 397/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 9.5642e-05\n",
      "Epoch 398/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 9.3798e-05\n",
      "Epoch 399/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 9.2357e-05\n",
      "Epoch 400/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 9.1850e-05\n",
      "Epoch 401/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 9.0087e-05\n",
      "Epoch 402/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 8.9815e-05\n",
      "Epoch 403/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 8.8419e-05\n",
      "Epoch 404/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 8.8105e-05\n",
      "Epoch 405/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 8.7432e-05\n",
      "Epoch 406/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 8.8178e-05\n",
      "Epoch 407/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 8.6007e-05\n",
      "Epoch 408/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 8.4996e-05\n",
      "Epoch 409/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 8.5180e-05\n",
      "Epoch 410/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 8.3563e-05\n",
      "Epoch 411/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 8.2402e-05\n",
      "Epoch 412/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 8.2840e-05\n",
      "Epoch 413/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 8.1098e-05\n",
      "Epoch 414/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 8.0040e-05\n",
      "Epoch 415/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 8.0189e-05\n",
      "Epoch 416/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 8.1696e-05\n",
      "Epoch 417/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 7.9422e-05\n",
      "Epoch 418/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 7.9644e-05\n",
      "Epoch 419/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 7.8236e-05\n",
      "Epoch 420/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 7.7797e-05\n",
      "Epoch 421/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 7.8103e-05\n",
      "Epoch 422/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 7.9131e-05\n",
      "Epoch 423/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 7.8175e-05\n",
      "Epoch 424/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 7.3965e-05\n",
      "Epoch 425/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 7.2361e-05\n",
      "Epoch 426/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 7.4499e-05\n",
      "Epoch 427/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 7.4317e-05\n",
      "Epoch 428/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 7.3122e-05\n",
      "Epoch 429/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 8.3740e-05\n",
      "Epoch 430/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 7.1722e-05\n",
      "Epoch 431/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 6.9534e-05\n",
      "Epoch 432/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 6.7662e-05\n",
      "Epoch 433/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 6.9270e-05\n",
      "Epoch 434/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 7.2894e-05\n",
      "Epoch 435/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 6.6064e-05\n",
      "Epoch 436/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 6.7685e-05\n",
      "Epoch 437/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 6.6189e-05\n",
      "Epoch 438/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 6.5896e-05\n",
      "Epoch 439/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 6.4717e-05\n",
      "Epoch 440/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 6.5662e-05\n",
      "Epoch 441/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 6.0854e-05\n",
      "Epoch 442/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 6.1053e-05\n",
      "Epoch 443/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 6.0480e-05\n",
      "Epoch 444/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 5.8053e-05\n",
      "Epoch 445/500\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 5.8189e-05\n",
      "Epoch 446/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 5.6192e-05\n",
      "Epoch 447/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 6.7574e-05\n",
      "Epoch 448/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 5.4856e-05\n",
      "Epoch 449/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 6.0810e-05\n",
      "Epoch 450/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 5.8413e-05\n",
      "Epoch 451/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 4.9771e-05\n",
      "Epoch 452/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 4.8042e-05\n",
      "Epoch 453/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 4.9510e-05\n",
      "Epoch 454/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 4.5784e-05\n",
      "Epoch 455/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 5.0156e-05\n",
      "Epoch 456/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 4.5467e-05\n",
      "Epoch 457/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 4.5013e-05\n",
      "Epoch 458/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 4.8628e-05\n",
      "Epoch 459/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 7.4764e-05\n",
      "Epoch 460/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0085\n",
      "Epoch 461/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.3088e-04\n",
      "Epoch 462/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0134e-04\n",
      "Epoch 463/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 8.9568e-05\n",
      "Epoch 464/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 8.0094e-05\n",
      "Epoch 465/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 7.3990e-05\n",
      "Epoch 466/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 6.8458e-05\n",
      "Epoch 467/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 6.3935e-05\n",
      "Epoch 468/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 6.0626e-05\n",
      "Epoch 469/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 5.7635e-05\n",
      "Epoch 470/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 5.5296e-05\n",
      "Epoch 471/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 5.3081e-05\n",
      "Epoch 472/500\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 5.1708e-05\n",
      "Epoch 473/500\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 4.9739e-05\n",
      "Epoch 474/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 4.8147e-05\n",
      "Epoch 475/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 4.7014e-05\n",
      "Epoch 476/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 4.5798e-05\n",
      "Epoch 477/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 4.4712e-05\n",
      "Epoch 478/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 4.3866e-05\n",
      "Epoch 479/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 4.2693e-05\n",
      "Epoch 480/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 4.1769e-05\n",
      "Epoch 481/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 4.0850e-05\n",
      "Epoch 482/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 4.0163e-05\n",
      "Epoch 483/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 3.9804e-05\n",
      "Epoch 484/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 3.9190e-05\n",
      "Epoch 485/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 3.8217e-05\n",
      "Epoch 486/500\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 3.7701e-05\n",
      "Epoch 487/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 3.7312e-05\n",
      "Epoch 488/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 3.6801e-05\n",
      "Epoch 489/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 3.6443e-05\n",
      "Epoch 490/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 3.5800e-05\n",
      "Epoch 491/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 3.5929e-05\n",
      "Epoch 492/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 3.5341e-05\n",
      "Epoch 493/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 3.5131e-05\n",
      "Epoch 494/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 3.4431e-05\n",
      "Epoch 495/500\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 3.4283e-05\n",
      "Epoch 496/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 3.3778e-05\n",
      "Epoch 497/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 3.3735e-05\n",
      "Epoch 498/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 3.3197e-05\n",
      "Epoch 499/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 3.3112e-05\n",
      "Epoch 500/500\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 3.2844e-05\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 500    \n",
    "tf.random.set_seed(1234) # for consistent results\n",
    "model = Sequential(\n",
    "    [               \n",
    "        ### START CODE HERE ### \n",
    "        Dense(units=442, activation='relu'),\n",
    "        Dense(units=131, activation='relu'),\n",
    "        Dense(units=25, activation='relu'),\n",
    "        Dense(units=3, activation='linear')\n",
    "        ### END CODE HERE ### \n",
    "    ], name = \"my_model\" \n",
    ")\n",
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "             optimizer=tf.keras.optimizers.Adam(learning_rate=1.29e-05),)\n",
    "history = model.fit(X, y, epochs=num_epochs)\n",
    "J = history.history['loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e474103",
   "metadata": {},
   "source": [
    "We reach convergence in the cost function in 500 epochs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd37be29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x184456f6610>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3704753f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(X)\n",
    "prediction_p = tf.nn.softmax(prediction)\n",
    "y_hat = np.zeros((len(prediction_p),1))\n",
    "for i in range(len(y_hat)):\n",
    "    y_hat[i] = np.argmax(prediction_p[i])\n",
    "plt.ylabel(\"Cost function\"), plt.xlabel(\"Epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d543e9ab",
   "metadata": {},
   "source": [
    "We can see that our neural network predicts the test data we get an accuracy of 100%. This tells us that our model is sufficiently large enough to predict such results. If we could not reach high accuracy on training data we would need to increase the size of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "169f2819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_hat == y)/len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f675aa",
   "metadata": {},
   "source": [
    "# Validation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d875778",
   "metadata": {},
   "source": [
    "Lets load in our validation dataset. Note that our validation data is raw data and not augmented like our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5d734adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported files: circles\\valid\\circle_\n",
      "Imported files: lines\\valid\\line_\n",
      "Imported files: squares\\valid\\square_\n"
     ]
    }
   ],
   "source": [
    "num_images = 15*3\n",
    "resolu_images = 25**2\n",
    "file_list = [r\"circles\\valid\\circle_\",r\"lines\\valid\\line_\",r\"squares\\valid\\square_\"]\n",
    "X_valid = np.zeros([num_images, resolu_images])\n",
    "counter = 0\n",
    "for i in range(3):\n",
    "    for j in range(15):\n",
    "        file_name = file_list[i] + str(j+1) + \".jpg\"\n",
    "        X_valid[counter] = np.matrix.flatten(np.array(Image.open(file_name).convert('L')))\n",
    "        counter += 1\n",
    "    print(\"Imported files: {}\".format(file_list[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7543af64",
   "metadata": {},
   "source": [
    "Normalise validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d62ba23",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = X_valid / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f44c5a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 625)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "541f7790",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = np.genfromtxt(\"valid_target_class.csv\", delimiter=',')\n",
    "y_valid = y_valid.reshape((num_images,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "673c625b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a26d3f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction_valid = model.predict(X_valid)\n",
    "prediction_valid_p = tf.nn.softmax(prediction_valid)\n",
    "y_hat_valid = np.zeros((len(prediction_valid_p),1))\n",
    "for i in range(len(y_hat_valid)):\n",
    "    y_hat_valid[i] = np.argmax(prediction_valid_p[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ee61818f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8888888888888888"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_hat_valid == y_valid)/len(y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4805a842",
   "metadata": {},
   "source": [
    "We actually achieve 89% accuracy on our validation data which is good considering we have not yet adjusted for overfitting to our training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e3e73e",
   "metadata": {},
   "source": [
    "# Regularisation to prevent overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e688f271",
   "metadata": {},
   "source": [
    "To prevent overfitting to the test dataset we utilise L2 regularisation. Lets perform a grid search with varying degrees of L2 regularisation to try and increase our validation dataset accuracy at the expense of training dataset accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7f83cc",
   "metadata": {},
   "source": [
    "We vary the amount of L2 regularisation with values $10^d$ where $d = [-3, -2.5, -2, -1.5, -1, -0.5, 0]$. Then the neural network is trained on the training dataset towards convergence (~300 epochs). Then the training dataset accuracy is compared to the test dataset accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ecf9e3aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 1.3298\n",
      "Epoch 2/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0418\n",
      "Epoch 3/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.9163\n",
      "Epoch 4/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.8216\n",
      "Epoch 5/300\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 0.7530\n",
      "Epoch 6/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.6912\n",
      "Epoch 7/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.6424\n",
      "Epoch 8/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.5974\n",
      "Epoch 9/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.5527\n",
      "Epoch 10/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5211\n",
      "Epoch 11/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.4894\n",
      "Epoch 12/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.4614\n",
      "Epoch 13/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4388\n",
      "Epoch 14/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.4206\n",
      "Epoch 15/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.3958\n",
      "Epoch 16/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.3865\n",
      "Epoch 17/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.3630\n",
      "Epoch 18/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.3507\n",
      "Epoch 19/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.3335\n",
      "Epoch 20/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3236\n",
      "Epoch 21/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3086\n",
      "Epoch 22/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2984\n",
      "Epoch 23/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2878\n",
      "Epoch 24/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2796\n",
      "Epoch 25/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2663\n",
      "Epoch 26/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2572\n",
      "Epoch 27/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2524\n",
      "Epoch 28/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2395\n",
      "Epoch 29/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2311\n",
      "Epoch 30/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2256\n",
      "Epoch 31/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2171\n",
      "Epoch 32/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2111\n",
      "Epoch 33/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2047\n",
      "Epoch 34/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2003\n",
      "Epoch 35/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1900\n",
      "Epoch 36/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1844\n",
      "Epoch 37/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1793\n",
      "Epoch 38/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1747\n",
      "Epoch 39/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1687\n",
      "Epoch 40/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1639\n",
      "Epoch 41/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.1602\n",
      "Epoch 42/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.1559\n",
      "Epoch 43/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.1496\n",
      "Epoch 44/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.1454\n",
      "Epoch 45/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.1425\n",
      "Epoch 46/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.1382\n",
      "Epoch 47/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1345\n",
      "Epoch 48/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1323\n",
      "Epoch 49/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1285\n",
      "Epoch 50/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1279\n",
      "Epoch 51/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1217\n",
      "Epoch 52/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1208\n",
      "Epoch 53/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.1151\n",
      "Epoch 54/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1129\n",
      "Epoch 55/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1109\n",
      "Epoch 56/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1085\n",
      "Epoch 57/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1067\n",
      "Epoch 58/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.1036\n",
      "Epoch 59/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.1021\n",
      "Epoch 60/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.1008\n",
      "Epoch 61/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0982\n",
      "Epoch 62/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0967\n",
      "Epoch 63/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0951\n",
      "Epoch 64/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0931\n",
      "Epoch 65/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0919\n",
      "Epoch 66/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0899\n",
      "Epoch 67/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0878\n",
      "Epoch 68/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0861\n",
      "Epoch 69/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0851\n",
      "Epoch 70/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0848\n",
      "Epoch 71/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0832\n",
      "Epoch 72/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0816\n",
      "Epoch 73/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0814\n",
      "Epoch 74/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0800\n",
      "Epoch 75/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0800\n",
      "Epoch 76/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0778\n",
      "Epoch 77/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0776\n",
      "Epoch 78/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0760\n",
      "Epoch 79/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0752\n",
      "Epoch 80/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0745\n",
      "Epoch 81/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0739\n",
      "Epoch 82/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0734\n",
      "Epoch 83/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0723\n",
      "Epoch 84/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0726\n",
      "Epoch 85/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0711\n",
      "Epoch 86/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0705\n",
      "Epoch 87/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0697\n",
      "Epoch 88/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0689\n",
      "Epoch 89/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0686\n",
      "Epoch 90/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0685\n",
      "Epoch 91/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0673\n",
      "Epoch 92/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0667\n",
      "Epoch 93/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0660\n",
      "Epoch 94/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0654\n",
      "Epoch 95/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0650\n",
      "Epoch 96/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0643\n",
      "Epoch 97/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0646\n",
      "Epoch 98/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0634\n",
      "Epoch 99/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0633\n",
      "Epoch 100/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0623\n",
      "Epoch 101/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0619\n",
      "Epoch 102/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0618\n",
      "Epoch 103/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0611\n",
      "Epoch 104/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0607\n",
      "Epoch 105/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0603\n",
      "Epoch 106/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0598\n",
      "Epoch 107/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0597\n",
      "Epoch 108/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0594\n",
      "Epoch 109/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0586\n",
      "Epoch 110/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.0583\n",
      "Epoch 111/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0581\n",
      "Epoch 112/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0576\n",
      "Epoch 113/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0573\n",
      "Epoch 114/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0567\n",
      "Epoch 115/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0567\n",
      "Epoch 116/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0561\n",
      "Epoch 117/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0562\n",
      "Epoch 118/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0555\n",
      "Epoch 119/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0550\n",
      "Epoch 120/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0555\n",
      "Epoch 121/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0548\n",
      "Epoch 122/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0544\n",
      "Epoch 123/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0539\n",
      "Epoch 124/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0536\n",
      "Epoch 125/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0536\n",
      "Epoch 126/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0530\n",
      "Epoch 127/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0528\n",
      "Epoch 128/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0524\n",
      "Epoch 129/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0522\n",
      "Epoch 130/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0521\n",
      "Epoch 131/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0522\n",
      "Epoch 132/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0516\n",
      "Epoch 133/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0513\n",
      "Epoch 134/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0512\n",
      "Epoch 135/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0508\n",
      "Epoch 136/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0506\n",
      "Epoch 137/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0504\n",
      "Epoch 138/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0502\n",
      "Epoch 139/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0501\n",
      "Epoch 140/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0502\n",
      "Epoch 141/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0499\n",
      "Epoch 142/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0493\n",
      "Epoch 143/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0491\n",
      "Epoch 144/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0490\n",
      "Epoch 145/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0488\n",
      "Epoch 146/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0485\n",
      "Epoch 147/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0484\n",
      "Epoch 148/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0482\n",
      "Epoch 149/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0494\n",
      "Epoch 150/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0480\n",
      "Epoch 151/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0478\n",
      "Epoch 152/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0477\n",
      "Epoch 153/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0473\n",
      "Epoch 154/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0472\n",
      "Epoch 155/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0473\n",
      "Epoch 156/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0471\n",
      "Epoch 157/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0468\n",
      "Epoch 158/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0470\n",
      "Epoch 159/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0466\n",
      "Epoch 160/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0464\n",
      "Epoch 161/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0463\n",
      "Epoch 162/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0463\n",
      "Epoch 163/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0460\n",
      "Epoch 164/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0458\n",
      "Epoch 165/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0457\n",
      "Epoch 166/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0456\n",
      "Epoch 167/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0454\n",
      "Epoch 168/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0453\n",
      "Epoch 169/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0452\n",
      "Epoch 170/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0452\n",
      "Epoch 171/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0451\n",
      "Epoch 172/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0450\n",
      "Epoch 173/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0448\n",
      "Epoch 174/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0446\n",
      "Epoch 175/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0446\n",
      "Epoch 176/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0444\n",
      "Epoch 177/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0443\n",
      "Epoch 178/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0443\n",
      "Epoch 179/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0441\n",
      "Epoch 180/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0441\n",
      "Epoch 181/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0443\n",
      "Epoch 182/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0444\n",
      "Epoch 183/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.0447\n",
      "Epoch 184/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0437\n",
      "Epoch 185/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0434\n",
      "Epoch 186/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0433\n",
      "Epoch 187/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0433\n",
      "Epoch 188/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0432\n",
      "Epoch 189/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0431\n",
      "Epoch 190/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0432\n",
      "Epoch 191/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0430\n",
      "Epoch 192/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0430\n",
      "Epoch 193/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0429\n",
      "Epoch 194/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0427\n",
      "Epoch 195/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0427\n",
      "Epoch 196/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0426\n",
      "Epoch 197/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0426\n",
      "Epoch 198/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0425\n",
      "Epoch 199/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0424\n",
      "Epoch 200/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0424\n",
      "Epoch 201/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0602\n",
      "Epoch 202/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0665\n",
      "Epoch 203/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0446\n",
      "Epoch 204/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0435\n",
      "Epoch 205/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0430\n",
      "Epoch 206/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0427\n",
      "Epoch 207/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0426\n",
      "Epoch 208/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0425\n",
      "Epoch 209/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0424\n",
      "Epoch 210/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0423\n",
      "Epoch 211/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0422\n",
      "Epoch 212/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0421\n",
      "Epoch 213/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0421\n",
      "Epoch 214/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0420\n",
      "Epoch 215/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0420\n",
      "Epoch 216/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0419\n",
      "Epoch 217/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0419\n",
      "Epoch 218/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0418\n",
      "Epoch 219/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0418\n",
      "Epoch 220/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0417\n",
      "Epoch 221/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0417\n",
      "Epoch 222/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0416\n",
      "Epoch 223/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0416\n",
      "Epoch 224/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0415\n",
      "Epoch 225/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0415\n",
      "Epoch 226/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0415\n",
      "Epoch 227/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0414\n",
      "Epoch 228/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0413\n",
      "Epoch 229/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0413\n",
      "Epoch 230/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0413\n",
      "Epoch 231/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0412\n",
      "Epoch 232/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0412\n",
      "Epoch 233/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0411\n",
      "Epoch 234/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0411\n",
      "Epoch 235/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0410\n",
      "Epoch 236/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0410\n",
      "Epoch 237/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0409\n",
      "Epoch 238/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0409\n",
      "Epoch 239/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0409\n",
      "Epoch 240/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0408\n",
      "Epoch 241/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0408\n",
      "Epoch 242/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0407\n",
      "Epoch 243/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0407\n",
      "Epoch 244/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0406\n",
      "Epoch 245/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0406\n",
      "Epoch 246/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.0405\n",
      "Epoch 247/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0405\n",
      "Epoch 248/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0405\n",
      "Epoch 249/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.0404\n",
      "Epoch 250/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.0404\n",
      "Epoch 251/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.0404\n",
      "Epoch 252/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0403\n",
      "Epoch 253/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0403\n",
      "Epoch 254/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0402\n",
      "Epoch 255/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0402\n",
      "Epoch 256/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0402\n",
      "Epoch 257/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0402\n",
      "Epoch 258/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0401\n",
      "Epoch 259/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0400\n",
      "Epoch 260/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0400\n",
      "Epoch 261/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0399\n",
      "Epoch 262/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0400\n",
      "Epoch 263/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0399\n",
      "Epoch 264/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0398\n",
      "Epoch 265/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0398\n",
      "Epoch 266/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0398\n",
      "Epoch 267/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0397\n",
      "Epoch 268/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0397\n",
      "Epoch 269/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0398\n",
      "Epoch 270/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0397\n",
      "Epoch 271/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0399\n",
      "Epoch 272/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0397\n",
      "Epoch 273/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0395\n",
      "Epoch 274/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0395\n",
      "Epoch 275/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0394\n",
      "Epoch 276/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0394\n",
      "Epoch 277/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0393\n",
      "Epoch 278/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0394\n",
      "Epoch 279/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0395\n",
      "Epoch 280/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0395\n",
      "Epoch 281/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0393\n",
      "Epoch 282/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0393\n",
      "Epoch 283/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0392\n",
      "Epoch 284/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0392\n",
      "Epoch 285/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0390\n",
      "Epoch 286/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0391\n",
      "Epoch 287/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0390\n",
      "Epoch 288/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0390\n",
      "Epoch 289/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0391\n",
      "Epoch 290/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0390\n",
      "Epoch 291/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0389\n",
      "Epoch 292/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0390\n",
      "Epoch 293/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0390\n",
      "Epoch 294/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0389\n",
      "Epoch 295/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0388\n",
      "Epoch 296/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0389\n",
      "Epoch 297/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0389\n",
      "Epoch 298/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0389\n",
      "Epoch 299/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.0387\n",
      "Epoch 300/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.0388\n",
      "102/102 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1/300\n",
      "102/102 [==============================] - 1s 4ms/step - loss: 1.6262\n",
      "Epoch 2/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1322\n",
      "Epoch 3/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.9891\n",
      "Epoch 4/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.9030\n",
      "Epoch 5/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.8389\n",
      "Epoch 6/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7824\n",
      "Epoch 7/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7338\n",
      "Epoch 8/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6905\n",
      "Epoch 9/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6468\n",
      "Epoch 10/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6112\n",
      "Epoch 11/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5773\n",
      "Epoch 12/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5473\n",
      "Epoch 13/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5221\n",
      "Epoch 14/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.5000\n",
      "Epoch 15/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.4769\n",
      "Epoch 16/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4626\n",
      "Epoch 17/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.4393\n",
      "Epoch 18/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4257\n",
      "Epoch 19/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4066\n",
      "Epoch 20/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.3947\n",
      "Epoch 21/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.3784\n",
      "Epoch 22/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3679\n",
      "Epoch 23/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.3548\n",
      "Epoch 24/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.3442\n",
      "Epoch 25/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3321\n",
      "Epoch 26/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.3217\n",
      "Epoch 27/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3129\n",
      "Epoch 28/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.3016\n",
      "Epoch 29/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2926\n",
      "Epoch 30/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2854\n",
      "Epoch 31/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2763\n",
      "Epoch 32/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2694\n",
      "Epoch 33/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2609\n",
      "Epoch 34/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2556\n",
      "Epoch 35/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2440\n",
      "Epoch 36/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2368\n",
      "Epoch 37/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2303\n",
      "Epoch 38/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2258\n",
      "Epoch 39/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2195\n",
      "Epoch 40/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2147\n",
      "Epoch 41/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2099\n",
      "Epoch 42/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2057\n",
      "Epoch 43/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2008\n",
      "Epoch 44/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1966\n",
      "Epoch 45/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1938\n",
      "Epoch 46/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.1894\n",
      "Epoch 47/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.1870\n",
      "Epoch 48/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.1849\n",
      "Epoch 49/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.1821\n",
      "Epoch 50/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1785\n",
      "Epoch 51/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1752\n",
      "Epoch 52/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1737\n",
      "Epoch 53/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1704\n",
      "Epoch 54/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1681\n",
      "Epoch 55/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.1659\n",
      "Epoch 56/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1641\n",
      "Epoch 57/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1622\n",
      "Epoch 58/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.1600\n",
      "Epoch 59/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.1583\n",
      "Epoch 60/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.1573\n",
      "Epoch 61/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.1552\n",
      "Epoch 62/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.1538\n",
      "Epoch 63/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1523\n",
      "Epoch 64/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.1512\n",
      "Epoch 65/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.1497\n",
      "Epoch 66/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.1487\n",
      "Epoch 67/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.1470\n",
      "Epoch 68/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.1449\n",
      "Epoch 69/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.1442\n",
      "Epoch 70/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1431\n",
      "Epoch 71/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1418\n",
      "Epoch 72/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1406\n",
      "Epoch 73/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1399\n",
      "Epoch 74/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1384\n",
      "Epoch 75/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1378\n",
      "Epoch 76/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1363\n",
      "Epoch 77/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.1353\n",
      "Epoch 78/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1341\n",
      "Epoch 79/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1333\n",
      "Epoch 80/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1324\n",
      "Epoch 81/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.1315\n",
      "Epoch 82/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1307\n",
      "Epoch 83/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1296\n",
      "Epoch 84/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1295\n",
      "Epoch 85/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1280\n",
      "Epoch 86/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1270\n",
      "Epoch 87/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1265\n",
      "Epoch 88/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1252\n",
      "Epoch 89/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1248\n",
      "Epoch 90/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1246\n",
      "Epoch 91/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1235\n",
      "Epoch 92/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.1230\n",
      "Epoch 93/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1221\n",
      "Epoch 94/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1210\n",
      "Epoch 95/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1204\n",
      "Epoch 96/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1197\n",
      "Epoch 97/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1196\n",
      "Epoch 98/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.1186\n",
      "Epoch 99/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1183\n",
      "Epoch 100/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1176\n",
      "Epoch 101/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1169\n",
      "Epoch 102/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1164\n",
      "Epoch 103/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1158\n",
      "Epoch 104/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1152\n",
      "Epoch 105/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1146\n",
      "Epoch 106/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1144\n",
      "Epoch 107/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1136\n",
      "Epoch 108/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1132\n",
      "Epoch 109/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1127\n",
      "Epoch 110/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.1124\n",
      "Epoch 111/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.1121\n",
      "Epoch 112/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1121\n",
      "Epoch 113/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1109\n",
      "Epoch 114/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1104\n",
      "Epoch 115/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.1100\n",
      "Epoch 116/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.1097\n",
      "Epoch 117/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1091\n",
      "Epoch 118/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1088\n",
      "Epoch 119/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1084\n",
      "Epoch 120/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1087\n",
      "Epoch 121/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.1077\n",
      "Epoch 122/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1073\n",
      "Epoch 123/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.1068\n",
      "Epoch 124/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.1065\n",
      "Epoch 125/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1064\n",
      "Epoch 126/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.1059\n",
      "Epoch 127/300\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 0.1055\n",
      "Epoch 128/300\n",
      "102/102 [==============================] - 1s 9ms/step - loss: 0.1054\n",
      "Epoch 129/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.1048\n",
      "Epoch 130/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.1046\n",
      "Epoch 131/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.1042\n",
      "Epoch 132/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.1037\n",
      "Epoch 133/300\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 0.1037\n",
      "Epoch 134/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.1035\n",
      "Epoch 135/300\n",
      "102/102 [==============================] - 1s 9ms/step - loss: 0.1031\n",
      "Epoch 136/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.1026\n",
      "Epoch 137/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.1025\n",
      "Epoch 138/300\n",
      "102/102 [==============================] - 1s 9ms/step - loss: 0.1023\n",
      "Epoch 139/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.1021\n",
      "Epoch 140/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.1020\n",
      "Epoch 141/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.1015\n",
      "Epoch 142/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1012\n",
      "Epoch 143/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.1008\n",
      "Epoch 144/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1021\n",
      "Epoch 145/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1008\n",
      "Epoch 146/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.1002\n",
      "Epoch 147/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0998\n",
      "Epoch 148/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.0997\n",
      "Epoch 149/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.0995\n",
      "Epoch 150/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0993\n",
      "Epoch 151/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0991\n",
      "Epoch 152/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1164\n",
      "Epoch 153/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1012\n",
      "Epoch 154/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0992\n",
      "Epoch 155/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0987\n",
      "Epoch 156/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0983\n",
      "Epoch 157/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0980\n",
      "Epoch 158/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0978\n",
      "Epoch 159/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0976\n",
      "Epoch 160/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0974\n",
      "Epoch 161/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0972\n",
      "Epoch 162/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0971\n",
      "Epoch 163/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0970\n",
      "Epoch 164/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0968\n",
      "Epoch 165/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0966\n",
      "Epoch 166/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0965\n",
      "Epoch 167/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0963\n",
      "Epoch 168/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0962\n",
      "Epoch 169/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0961\n",
      "Epoch 170/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0959\n",
      "Epoch 171/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0958\n",
      "Epoch 172/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0956\n",
      "Epoch 173/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0955\n",
      "Epoch 174/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0953\n",
      "Epoch 175/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0953\n",
      "Epoch 176/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0950\n",
      "Epoch 177/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0949\n",
      "Epoch 178/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0949\n",
      "Epoch 179/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0947\n",
      "Epoch 180/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0946\n",
      "Epoch 181/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0945\n",
      "Epoch 182/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0943\n",
      "Epoch 183/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0950\n",
      "Epoch 184/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0943\n",
      "Epoch 185/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0938\n",
      "Epoch 186/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0937\n",
      "Epoch 187/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0936\n",
      "Epoch 188/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0940\n",
      "Epoch 189/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0936\n",
      "Epoch 190/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0933\n",
      "Epoch 191/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0933\n",
      "Epoch 192/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0930\n",
      "Epoch 193/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0930\n",
      "Epoch 194/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0927\n",
      "Epoch 195/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0928\n",
      "Epoch 196/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0931\n",
      "Epoch 197/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0944\n",
      "Epoch 198/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0928\n",
      "Epoch 199/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0922\n",
      "Epoch 200/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0921\n",
      "Epoch 201/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0923\n",
      "Epoch 202/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0920\n",
      "Epoch 203/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0920\n",
      "Epoch 204/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0917\n",
      "Epoch 205/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0916\n",
      "Epoch 206/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0915\n",
      "Epoch 207/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0914\n",
      "Epoch 208/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0912\n",
      "Epoch 209/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0912\n",
      "Epoch 210/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0912\n",
      "Epoch 211/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0912\n",
      "Epoch 212/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.0910\n",
      "Epoch 213/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0909\n",
      "Epoch 214/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0908\n",
      "Epoch 215/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0909\n",
      "Epoch 216/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.0910\n",
      "Epoch 217/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0907\n",
      "Epoch 218/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0905\n",
      "Epoch 219/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0908\n",
      "Epoch 220/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0906\n",
      "Epoch 221/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0903\n",
      "Epoch 222/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0903\n",
      "Epoch 223/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0899\n",
      "Epoch 224/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0899\n",
      "Epoch 225/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0901\n",
      "Epoch 226/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0900\n",
      "Epoch 227/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.0897\n",
      "Epoch 228/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0896\n",
      "Epoch 229/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0896\n",
      "Epoch 230/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0895\n",
      "Epoch 231/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0899\n",
      "Epoch 232/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0896\n",
      "Epoch 233/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0895\n",
      "Epoch 234/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0892\n",
      "Epoch 235/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0892\n",
      "Epoch 236/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0893\n",
      "Epoch 237/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0892\n",
      "Epoch 238/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0890\n",
      "Epoch 239/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0890\n",
      "Epoch 240/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0890\n",
      "Epoch 241/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0888\n",
      "Epoch 242/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0886\n",
      "Epoch 243/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0887\n",
      "Epoch 244/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0885\n",
      "Epoch 245/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0885\n",
      "Epoch 246/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0883\n",
      "Epoch 247/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0884\n",
      "Epoch 248/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0887\n",
      "Epoch 249/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0887\n",
      "Epoch 250/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1298\n",
      "Epoch 251/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0956\n",
      "Epoch 252/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0896\n",
      "Epoch 253/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0889\n",
      "Epoch 254/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0886\n",
      "Epoch 255/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0885\n",
      "Epoch 256/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0883\n",
      "Epoch 257/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0883\n",
      "Epoch 258/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0882\n",
      "Epoch 259/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0881\n",
      "Epoch 260/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0880\n",
      "Epoch 261/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0880\n",
      "Epoch 262/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0879\n",
      "Epoch 263/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0878\n",
      "Epoch 264/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0878\n",
      "Epoch 265/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0877\n",
      "Epoch 266/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0877\n",
      "Epoch 267/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0877\n",
      "Epoch 268/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0876\n",
      "Epoch 269/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0876\n",
      "Epoch 270/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0875\n",
      "Epoch 271/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0875\n",
      "Epoch 272/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0874\n",
      "Epoch 273/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0874\n",
      "Epoch 274/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0873\n",
      "Epoch 275/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0873\n",
      "Epoch 276/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0873\n",
      "Epoch 277/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0872\n",
      "Epoch 278/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0872\n",
      "Epoch 279/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0871\n",
      "Epoch 280/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0871\n",
      "Epoch 281/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0870\n",
      "Epoch 282/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0870\n",
      "Epoch 283/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0870\n",
      "Epoch 284/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0869\n",
      "Epoch 285/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0869\n",
      "Epoch 286/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0868\n",
      "Epoch 287/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0868\n",
      "Epoch 288/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0868\n",
      "Epoch 289/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0867\n",
      "Epoch 290/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0867\n",
      "Epoch 291/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0867\n",
      "Epoch 292/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0866\n",
      "Epoch 293/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0866\n",
      "Epoch 294/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0865\n",
      "Epoch 295/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0865\n",
      "Epoch 296/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0865\n",
      "Epoch 297/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0865\n",
      "Epoch 298/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0864\n",
      "Epoch 299/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0864\n",
      "Epoch 300/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0866\n",
      "102/102 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1/300\n",
      "102/102 [==============================] - 1s 3ms/step - loss: 2.3424\n",
      "Epoch 2/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.2997\n",
      "Epoch 3/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1521\n",
      "Epoch 4/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0736\n",
      "Epoch 5/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0121\n",
      "Epoch 6/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.9574\n",
      "Epoch 7/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.9073\n",
      "Epoch 8/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.8637\n",
      "Epoch 9/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.8195\n",
      "Epoch 10/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7848\n",
      "Epoch 11/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7508\n",
      "Epoch 12/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7183\n",
      "Epoch 13/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6911\n",
      "Epoch 14/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6662\n",
      "Epoch 15/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6417\n",
      "Epoch 16/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6213\n",
      "Epoch 17/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5981\n",
      "Epoch 18/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5807\n",
      "Epoch 19/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5607\n",
      "Epoch 20/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5458\n",
      "Epoch 21/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5276\n",
      "Epoch 22/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5141\n",
      "Epoch 23/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5006\n",
      "Epoch 24/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4878\n",
      "Epoch 25/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4752\n",
      "Epoch 26/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4640\n",
      "Epoch 27/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4537\n",
      "Epoch 28/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4411\n",
      "Epoch 29/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4304\n",
      "Epoch 30/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4187\n",
      "Epoch 31/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4085\n",
      "Epoch 32/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3998\n",
      "Epoch 33/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3911\n",
      "Epoch 34/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3855\n",
      "Epoch 35/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3763\n",
      "Epoch 36/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3699\n",
      "Epoch 37/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3629\n",
      "Epoch 38/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3577\n",
      "Epoch 39/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3522\n",
      "Epoch 40/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3468\n",
      "Epoch 41/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3414\n",
      "Epoch 42/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3372\n",
      "Epoch 43/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3321\n",
      "Epoch 44/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3278\n",
      "Epoch 45/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3242\n",
      "Epoch 46/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3200\n",
      "Epoch 47/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3168\n",
      "Epoch 48/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3140\n",
      "Epoch 49/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3114\n",
      "Epoch 50/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3073\n",
      "Epoch 51/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3037\n",
      "Epoch 52/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3020\n",
      "Epoch 53/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2981\n",
      "Epoch 54/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2959\n",
      "Epoch 55/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2930\n",
      "Epoch 56/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2907\n",
      "Epoch 57/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2879\n",
      "Epoch 58/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2855\n",
      "Epoch 59/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2838\n",
      "Epoch 60/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2820\n",
      "Epoch 61/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2798\n",
      "Epoch 62/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2779\n",
      "Epoch 63/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2756\n",
      "Epoch 64/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2740\n",
      "Epoch 65/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2719\n",
      "Epoch 66/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2707\n",
      "Epoch 67/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2686\n",
      "Epoch 68/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2666\n",
      "Epoch 69/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2655\n",
      "Epoch 70/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2634\n",
      "Epoch 71/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2620\n",
      "Epoch 72/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2607\n",
      "Epoch 73/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2592\n",
      "Epoch 74/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2577\n",
      "Epoch 75/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2560\n",
      "Epoch 76/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2548\n",
      "Epoch 77/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2538\n",
      "Epoch 78/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2519\n",
      "Epoch 79/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2510\n",
      "Epoch 80/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2497\n",
      "Epoch 81/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2488\n",
      "Epoch 82/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2476\n",
      "Epoch 83/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2462\n",
      "Epoch 84/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2451\n",
      "Epoch 85/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2442\n",
      "Epoch 86/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2429\n",
      "Epoch 87/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2417\n",
      "Epoch 88/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2406\n",
      "Epoch 89/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2402\n",
      "Epoch 90/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2391\n",
      "Epoch 91/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2379\n",
      "Epoch 92/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2374\n",
      "Epoch 93/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2364\n",
      "Epoch 94/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2357\n",
      "Epoch 95/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2345\n",
      "Epoch 96/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2333\n",
      "Epoch 97/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2327\n",
      "Epoch 98/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2317\n",
      "Epoch 99/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2311\n",
      "Epoch 100/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2302\n",
      "Epoch 101/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2295\n",
      "Epoch 102/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2288\n",
      "Epoch 103/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2278\n",
      "Epoch 104/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2272\n",
      "Epoch 105/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2266\n",
      "Epoch 106/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2258\n",
      "Epoch 107/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2249\n",
      "Epoch 108/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2247\n",
      "Epoch 109/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2237\n",
      "Epoch 110/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2233\n",
      "Epoch 111/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2231\n",
      "Epoch 112/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2221\n",
      "Epoch 113/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2218\n",
      "Epoch 114/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2208\n",
      "Epoch 115/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2204\n",
      "Epoch 116/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2197\n",
      "Epoch 117/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2195\n",
      "Epoch 118/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2190\n",
      "Epoch 119/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2183\n",
      "Epoch 120/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2178\n",
      "Epoch 121/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2170\n",
      "Epoch 122/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2164\n",
      "Epoch 123/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2158\n",
      "Epoch 124/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2156\n",
      "Epoch 125/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2155\n",
      "Epoch 126/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2148\n",
      "Epoch 127/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2142\n",
      "Epoch 128/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2137\n",
      "Epoch 129/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2141\n",
      "Epoch 130/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2132\n",
      "Epoch 131/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2125\n",
      "Epoch 132/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2119\n",
      "Epoch 133/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2118\n",
      "Epoch 134/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2112\n",
      "Epoch 135/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2112\n",
      "Epoch 136/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2109\n",
      "Epoch 137/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2102\n",
      "Epoch 138/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2098\n",
      "Epoch 139/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2094\n",
      "Epoch 140/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2091\n",
      "Epoch 141/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2093\n",
      "Epoch 142/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2098\n",
      "Epoch 143/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2080\n",
      "Epoch 144/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2075\n",
      "Epoch 145/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2071\n",
      "Epoch 146/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2073\n",
      "Epoch 147/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2067\n",
      "Epoch 148/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2063\n",
      "Epoch 149/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2070\n",
      "Epoch 150/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2057\n",
      "Epoch 151/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2054\n",
      "Epoch 152/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2049\n",
      "Epoch 153/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2048\n",
      "Epoch 154/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2046\n",
      "Epoch 155/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2043\n",
      "Epoch 156/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2043\n",
      "Epoch 157/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2037\n",
      "Epoch 158/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2033\n",
      "Epoch 159/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2033\n",
      "Epoch 160/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2029\n",
      "Epoch 161/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2025\n",
      "Epoch 162/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2021\n",
      "Epoch 163/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2019\n",
      "Epoch 164/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2018\n",
      "Epoch 165/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2016\n",
      "Epoch 166/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2016\n",
      "Epoch 167/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2016\n",
      "Epoch 168/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2018\n",
      "Epoch 169/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2011\n",
      "Epoch 170/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2001\n",
      "Epoch 171/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2000\n",
      "Epoch 172/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1998\n",
      "Epoch 173/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1997\n",
      "Epoch 174/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1994\n",
      "Epoch 175/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1991\n",
      "Epoch 176/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1989\n",
      "Epoch 177/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1988\n",
      "Epoch 178/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1984\n",
      "Epoch 179/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1982\n",
      "Epoch 180/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1984\n",
      "Epoch 181/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1979\n",
      "Epoch 182/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1977\n",
      "Epoch 183/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1977\n",
      "Epoch 184/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1975\n",
      "Epoch 185/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1971\n",
      "Epoch 186/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1968\n",
      "Epoch 187/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1973\n",
      "Epoch 188/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1964\n",
      "Epoch 189/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1964\n",
      "Epoch 190/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1964\n",
      "Epoch 191/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1959\n",
      "Epoch 192/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1957\n",
      "Epoch 193/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1957\n",
      "Epoch 194/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1954\n",
      "Epoch 195/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1952\n",
      "Epoch 196/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1957\n",
      "Epoch 197/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1953\n",
      "Epoch 198/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1955\n",
      "Epoch 199/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1943\n",
      "Epoch 200/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1941\n",
      "Epoch 201/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1950\n",
      "Epoch 202/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1943\n",
      "Epoch 203/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1938\n",
      "Epoch 204/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1939\n",
      "Epoch 205/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1936\n",
      "Epoch 206/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1933\n",
      "Epoch 207/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1932\n",
      "Epoch 208/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1932\n",
      "Epoch 209/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1933\n",
      "Epoch 210/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1931\n",
      "Epoch 211/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1961\n",
      "Epoch 212/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2056\n",
      "Epoch 213/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1939\n",
      "Epoch 214/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1926\n",
      "Epoch 215/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1924\n",
      "Epoch 216/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1922\n",
      "Epoch 217/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1920\n",
      "Epoch 218/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1917\n",
      "Epoch 219/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1916\n",
      "Epoch 220/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1915\n",
      "Epoch 221/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1914\n",
      "Epoch 222/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1912\n",
      "Epoch 223/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1911\n",
      "Epoch 224/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1909\n",
      "Epoch 225/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1908\n",
      "Epoch 226/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1909\n",
      "Epoch 227/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1907\n",
      "Epoch 228/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1905\n",
      "Epoch 229/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1902\n",
      "Epoch 230/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1902\n",
      "Epoch 231/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1901\n",
      "Epoch 232/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1899\n",
      "Epoch 233/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1900\n",
      "Epoch 234/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1901\n",
      "Epoch 235/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1898\n",
      "Epoch 236/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1901\n",
      "Epoch 237/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1903\n",
      "Epoch 238/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1898\n",
      "Epoch 239/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1894\n",
      "Epoch 240/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1896\n",
      "Epoch 241/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1913\n",
      "Epoch 242/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2075\n",
      "Epoch 243/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1993\n",
      "Epoch 244/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1905\n",
      "Epoch 245/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1894\n",
      "Epoch 246/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1891\n",
      "Epoch 247/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1889\n",
      "Epoch 248/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1888\n",
      "Epoch 249/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1886\n",
      "Epoch 250/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1885\n",
      "Epoch 251/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1884\n",
      "Epoch 252/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1883\n",
      "Epoch 253/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1882\n",
      "Epoch 254/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1881\n",
      "Epoch 255/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1880\n",
      "Epoch 256/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1879\n",
      "Epoch 257/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1878\n",
      "Epoch 258/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1877\n",
      "Epoch 259/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1876\n",
      "Epoch 260/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1875\n",
      "Epoch 261/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1874\n",
      "Epoch 262/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1874\n",
      "Epoch 263/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1872\n",
      "Epoch 264/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1872\n",
      "Epoch 265/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1872\n",
      "Epoch 266/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1872\n",
      "Epoch 267/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1872\n",
      "Epoch 268/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1869\n",
      "Epoch 269/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1868\n",
      "Epoch 270/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1867\n",
      "Epoch 271/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1866\n",
      "Epoch 272/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1867\n",
      "Epoch 273/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1867\n",
      "Epoch 274/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1866\n",
      "Epoch 275/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1865\n",
      "Epoch 276/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1866\n",
      "Epoch 277/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1862\n",
      "Epoch 278/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1861\n",
      "Epoch 279/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1860\n",
      "Epoch 280/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1867\n",
      "Epoch 281/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1865\n",
      "Epoch 282/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2028\n",
      "Epoch 283/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2034\n",
      "Epoch 284/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1888\n",
      "Epoch 285/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1868\n",
      "Epoch 286/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1865\n",
      "Epoch 287/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1862\n",
      "Epoch 288/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1861\n",
      "Epoch 289/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1859\n",
      "Epoch 290/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1859\n",
      "Epoch 291/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1857\n",
      "Epoch 292/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1856\n",
      "Epoch 293/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1855\n",
      "Epoch 294/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1854\n",
      "Epoch 295/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1854\n",
      "Epoch 296/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1853\n",
      "Epoch 297/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1852\n",
      "Epoch 298/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1851\n",
      "Epoch 299/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1851\n",
      "Epoch 300/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1850\n",
      "102/102 [==============================] - 1s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1/300\n",
      "102/102 [==============================] - 1s 4ms/step - loss: 4.4474\n",
      "Epoch 2/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.5978\n",
      "Epoch 3/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.3479\n",
      "Epoch 4/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.2912\n",
      "Epoch 5/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.2546\n",
      "Epoch 6/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.2155\n",
      "Epoch 7/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1730\n",
      "Epoch 8/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.1317\n",
      "Epoch 9/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 1.0903\n",
      "Epoch 10/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 1.0523\n",
      "Epoch 11/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 1.0153\n",
      "Epoch 12/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.9809\n",
      "Epoch 13/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.9501\n",
      "Epoch 14/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.9229\n",
      "Epoch 15/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.8962\n",
      "Epoch 16/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.8725\n",
      "Epoch 17/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.8500\n",
      "Epoch 18/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.8301\n",
      "Epoch 19/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.8107\n",
      "Epoch 20/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7934\n",
      "Epoch 21/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7762\n",
      "Epoch 22/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7594\n",
      "Epoch 23/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7450\n",
      "Epoch 24/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7308\n",
      "Epoch 25/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7173\n",
      "Epoch 26/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7050\n",
      "Epoch 27/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6935\n",
      "Epoch 28/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6809\n",
      "Epoch 29/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.6709\n",
      "Epoch 30/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6609\n",
      "Epoch 31/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.6516\n",
      "Epoch 32/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.6420\n",
      "Epoch 33/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.6339\n",
      "Epoch 34/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.6270\n",
      "Epoch 35/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.6190\n",
      "Epoch 36/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.6115\n",
      "Epoch 37/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.6036\n",
      "Epoch 38/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5976\n",
      "Epoch 39/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5916\n",
      "Epoch 40/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5851\n",
      "Epoch 41/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5783\n",
      "Epoch 42/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5718\n",
      "Epoch 43/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5644\n",
      "Epoch 44/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5587\n",
      "Epoch 45/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5535\n",
      "Epoch 46/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5478\n",
      "Epoch 47/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5441\n",
      "Epoch 48/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5406\n",
      "Epoch 49/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5358\n",
      "Epoch 50/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5312\n",
      "Epoch 51/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5281\n",
      "Epoch 52/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5243\n",
      "Epoch 53/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5207\n",
      "Epoch 54/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5172\n",
      "Epoch 55/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5146\n",
      "Epoch 56/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5108\n",
      "Epoch 57/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5077\n",
      "Epoch 58/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5050\n",
      "Epoch 59/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5019\n",
      "Epoch 60/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4997\n",
      "Epoch 61/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4972\n",
      "Epoch 62/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4944\n",
      "Epoch 63/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4925\n",
      "Epoch 64/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4902\n",
      "Epoch 65/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4869\n",
      "Epoch 66/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4853\n",
      "Epoch 67/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4826\n",
      "Epoch 68/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4804\n",
      "Epoch 69/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4785\n",
      "Epoch 70/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4767\n",
      "Epoch 71/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4742\n",
      "Epoch 72/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4730\n",
      "Epoch 73/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4708\n",
      "Epoch 74/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4689\n",
      "Epoch 75/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4669\n",
      "Epoch 76/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4654\n",
      "Epoch 77/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4637\n",
      "Epoch 78/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4622\n",
      "Epoch 79/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4604\n",
      "Epoch 80/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4590\n",
      "Epoch 81/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4580\n",
      "Epoch 82/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4564\n",
      "Epoch 83/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4548\n",
      "Epoch 84/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4529\n",
      "Epoch 85/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4519\n",
      "Epoch 86/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4501\n",
      "Epoch 87/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4495\n",
      "Epoch 88/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4476\n",
      "Epoch 89/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4468\n",
      "Epoch 90/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4457\n",
      "Epoch 91/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4437\n",
      "Epoch 92/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4430\n",
      "Epoch 93/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4421\n",
      "Epoch 94/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4410\n",
      "Epoch 95/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.4396\n",
      "Epoch 96/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.4382\n",
      "Epoch 97/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.4379\n",
      "Epoch 98/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.4363\n",
      "Epoch 99/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.4352\n",
      "Epoch 100/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.4344\n",
      "Epoch 101/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4329\n",
      "Epoch 102/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4322\n",
      "Epoch 103/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4316\n",
      "Epoch 104/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4301\n",
      "Epoch 105/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4293\n",
      "Epoch 106/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4288\n",
      "Epoch 107/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4273\n",
      "Epoch 108/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4269\n",
      "Epoch 109/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4258\n",
      "Epoch 110/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4254\n",
      "Epoch 111/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4250\n",
      "Epoch 112/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4235\n",
      "Epoch 113/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4231\n",
      "Epoch 114/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4223\n",
      "Epoch 115/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4212\n",
      "Epoch 116/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4203\n",
      "Epoch 117/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4200\n",
      "Epoch 118/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4187\n",
      "Epoch 119/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4179\n",
      "Epoch 120/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4183\n",
      "Epoch 121/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4171\n",
      "Epoch 122/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4161\n",
      "Epoch 123/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4164\n",
      "Epoch 124/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4144\n",
      "Epoch 125/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4143\n",
      "Epoch 126/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4132\n",
      "Epoch 127/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4127\n",
      "Epoch 128/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4120\n",
      "Epoch 129/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4113\n",
      "Epoch 130/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4106\n",
      "Epoch 131/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4103\n",
      "Epoch 132/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4099\n",
      "Epoch 133/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4096\n",
      "Epoch 134/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4096\n",
      "Epoch 135/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4081\n",
      "Epoch 136/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4074\n",
      "Epoch 137/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4067\n",
      "Epoch 138/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4063\n",
      "Epoch 139/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4065\n",
      "Epoch 140/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4059\n",
      "Epoch 141/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4047\n",
      "Epoch 142/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4041\n",
      "Epoch 143/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4034\n",
      "Epoch 144/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4035\n",
      "Epoch 145/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4039\n",
      "Epoch 146/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4027\n",
      "Epoch 147/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4021\n",
      "Epoch 148/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4017\n",
      "Epoch 149/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4010\n",
      "Epoch 150/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4004\n",
      "Epoch 151/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4014\n",
      "Epoch 152/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4003\n",
      "Epoch 153/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3997\n",
      "Epoch 154/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3987\n",
      "Epoch 155/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3981\n",
      "Epoch 156/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3981\n",
      "Epoch 157/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3978\n",
      "Epoch 158/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3974\n",
      "Epoch 159/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3971\n",
      "Epoch 160/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3965\n",
      "Epoch 161/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3962\n",
      "Epoch 162/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3955\n",
      "Epoch 163/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3954\n",
      "Epoch 164/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3947\n",
      "Epoch 165/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3950\n",
      "Epoch 166/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3949\n",
      "Epoch 167/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3948\n",
      "Epoch 168/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3942\n",
      "Epoch 169/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3937\n",
      "Epoch 170/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3931\n",
      "Epoch 171/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3931\n",
      "Epoch 172/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3926\n",
      "Epoch 173/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3920\n",
      "Epoch 174/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3918\n",
      "Epoch 175/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3914\n",
      "Epoch 176/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3908\n",
      "Epoch 177/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3908\n",
      "Epoch 178/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3902\n",
      "Epoch 179/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3899\n",
      "Epoch 180/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3893\n",
      "Epoch 181/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3902\n",
      "Epoch 182/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3904\n",
      "Epoch 183/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3887\n",
      "Epoch 184/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3882\n",
      "Epoch 185/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3878\n",
      "Epoch 186/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3883\n",
      "Epoch 187/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3892\n",
      "Epoch 188/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3881\n",
      "Epoch 189/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3888\n",
      "Epoch 190/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3909\n",
      "Epoch 191/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3882\n",
      "Epoch 192/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3862\n",
      "Epoch 193/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3857\n",
      "Epoch 194/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3857\n",
      "Epoch 195/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3854\n",
      "Epoch 196/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3850\n",
      "Epoch 197/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3851\n",
      "Epoch 198/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3845\n",
      "Epoch 199/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3842\n",
      "Epoch 200/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3839\n",
      "Epoch 201/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3837\n",
      "Epoch 202/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3837\n",
      "Epoch 203/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3846\n",
      "Epoch 204/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3845\n",
      "Epoch 205/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3882\n",
      "Epoch 206/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3945\n",
      "Epoch 207/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3899\n",
      "Epoch 208/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3850\n",
      "Epoch 209/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3827\n",
      "Epoch 210/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3820\n",
      "Epoch 211/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3817\n",
      "Epoch 212/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3814\n",
      "Epoch 213/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3813\n",
      "Epoch 214/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3811\n",
      "Epoch 215/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3807\n",
      "Epoch 216/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3805\n",
      "Epoch 217/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3805\n",
      "Epoch 218/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3803\n",
      "Epoch 219/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3801\n",
      "Epoch 220/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3798\n",
      "Epoch 221/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3798\n",
      "Epoch 222/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3794\n",
      "Epoch 223/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3793\n",
      "Epoch 224/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3795\n",
      "Epoch 225/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3798\n",
      "Epoch 226/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3795\n",
      "Epoch 227/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3789\n",
      "Epoch 228/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3791\n",
      "Epoch 229/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3804\n",
      "Epoch 230/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3841\n",
      "Epoch 231/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3795\n",
      "Epoch 232/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3781\n",
      "Epoch 233/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3776\n",
      "Epoch 234/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3780\n",
      "Epoch 235/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3779\n",
      "Epoch 236/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3774\n",
      "Epoch 237/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3770\n",
      "Epoch 238/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3768\n",
      "Epoch 239/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3772\n",
      "Epoch 240/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3778\n",
      "Epoch 241/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3770\n",
      "Epoch 242/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3763\n",
      "Epoch 243/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3770\n",
      "Epoch 244/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3776\n",
      "Epoch 245/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3761\n",
      "Epoch 246/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3767\n",
      "Epoch 247/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3756\n",
      "Epoch 248/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3754\n",
      "Epoch 249/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3753\n",
      "Epoch 250/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.3764\n",
      "Epoch 251/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3773\n",
      "Epoch 252/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3760\n",
      "Epoch 253/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3747\n",
      "Epoch 254/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3748\n",
      "Epoch 255/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3764\n",
      "Epoch 256/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3759\n",
      "Epoch 257/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3744\n",
      "Epoch 258/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3755\n",
      "Epoch 259/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3744\n",
      "Epoch 260/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3740\n",
      "Epoch 261/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3737\n",
      "Epoch 262/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3736\n",
      "Epoch 263/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3733\n",
      "Epoch 264/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3740\n",
      "Epoch 265/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3739\n",
      "Epoch 266/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3738\n",
      "Epoch 267/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3743\n",
      "Epoch 268/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3762\n",
      "Epoch 269/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3813\n",
      "Epoch 270/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3774\n",
      "Epoch 271/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3757\n",
      "Epoch 272/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3748\n",
      "Epoch 273/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3738\n",
      "Epoch 274/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3732\n",
      "Epoch 275/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3730\n",
      "Epoch 276/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3722\n",
      "Epoch 277/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3723\n",
      "Epoch 278/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3720\n",
      "Epoch 279/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3717\n",
      "Epoch 280/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3715\n",
      "Epoch 281/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3717\n",
      "Epoch 282/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3742\n",
      "Epoch 283/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3739\n",
      "Epoch 284/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3734\n",
      "Epoch 285/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3719\n",
      "Epoch 286/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3712\n",
      "Epoch 287/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3709\n",
      "Epoch 288/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3708\n",
      "Epoch 289/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3707\n",
      "Epoch 290/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3706\n",
      "Epoch 291/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3705\n",
      "Epoch 292/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3710\n",
      "Epoch 293/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3788\n",
      "Epoch 294/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3823\n",
      "Epoch 295/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3897\n",
      "Epoch 296/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3780\n",
      "Epoch 297/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3734\n",
      "Epoch 298/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3717\n",
      "Epoch 299/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3713\n",
      "Epoch 300/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3707\n",
      "102/102 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1/300\n",
      "102/102 [==============================] - 1s 4ms/step - loss: 10.9599\n",
      "Epoch 2/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 2.2276\n",
      "Epoch 3/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.5077\n",
      "Epoch 4/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.4050\n",
      "Epoch 5/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.3769\n",
      "Epoch 6/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.3605\n",
      "Epoch 7/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.3458\n",
      "Epoch 8/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.3308\n",
      "Epoch 9/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.3156\n",
      "Epoch 10/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.2997\n",
      "Epoch 11/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.2838\n",
      "Epoch 12/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.2677\n",
      "Epoch 13/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.2507\n",
      "Epoch 14/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.2328\n",
      "Epoch 15/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.2146\n",
      "Epoch 16/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1961\n",
      "Epoch 17/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1789\n",
      "Epoch 18/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1620\n",
      "Epoch 19/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1445\n",
      "Epoch 20/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1283\n",
      "Epoch 21/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1124\n",
      "Epoch 22/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0979\n",
      "Epoch 23/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0846\n",
      "Epoch 24/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0709\n",
      "Epoch 25/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0587\n",
      "Epoch 26/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0471\n",
      "Epoch 27/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0352\n",
      "Epoch 28/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0242\n",
      "Epoch 29/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0144\n",
      "Epoch 30/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0050\n",
      "Epoch 31/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.9958\n",
      "Epoch 32/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.9868\n",
      "Epoch 33/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.9791\n",
      "Epoch 34/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.9715\n",
      "Epoch 35/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.9637\n",
      "Epoch 36/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.9561\n",
      "Epoch 37/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.9485\n",
      "Epoch 38/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.9421\n",
      "Epoch 39/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.9361\n",
      "Epoch 40/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.9297\n",
      "Epoch 41/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.9232\n",
      "Epoch 42/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.9182\n",
      "Epoch 43/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.9122\n",
      "Epoch 44/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.9070\n",
      "Epoch 45/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.9020\n",
      "Epoch 46/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.8963\n",
      "Epoch 47/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.8921\n",
      "Epoch 48/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.8871\n",
      "Epoch 49/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.8830\n",
      "Epoch 50/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.8782\n",
      "Epoch 51/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.8746\n",
      "Epoch 52/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.8701\n",
      "Epoch 53/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.8657\n",
      "Epoch 54/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.8628\n",
      "Epoch 55/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.8589\n",
      "Epoch 56/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.8545\n",
      "Epoch 57/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.8513\n",
      "Epoch 58/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.8480\n",
      "Epoch 59/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.8443\n",
      "Epoch 60/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.8422\n",
      "Epoch 61/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.8379\n",
      "Epoch 62/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.8355\n",
      "Epoch 63/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.8329\n",
      "Epoch 64/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 4ms/step - loss: 0.8293\n",
      "Epoch 65/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.8266\n",
      "Epoch 66/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.8241\n",
      "Epoch 67/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.8214\n",
      "Epoch 68/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.8184\n",
      "Epoch 69/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.8156\n",
      "Epoch 70/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.8131\n",
      "Epoch 71/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.8110\n",
      "Epoch 72/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.8087\n",
      "Epoch 73/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.8065\n",
      "Epoch 74/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.8038\n",
      "Epoch 75/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.8019\n",
      "Epoch 76/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7998\n",
      "Epoch 77/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7969\n",
      "Epoch 78/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7952\n",
      "Epoch 79/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7929\n",
      "Epoch 80/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7905\n",
      "Epoch 81/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7876\n",
      "Epoch 82/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7856\n",
      "Epoch 83/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7835\n",
      "Epoch 84/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7816\n",
      "Epoch 85/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7802\n",
      "Epoch 86/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7778\n",
      "Epoch 87/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7762\n",
      "Epoch 88/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7739\n",
      "Epoch 89/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7725\n",
      "Epoch 90/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7714\n",
      "Epoch 91/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7688\n",
      "Epoch 92/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7674\n",
      "Epoch 93/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7658\n",
      "Epoch 94/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7651\n",
      "Epoch 95/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7634\n",
      "Epoch 96/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7623\n",
      "Epoch 97/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7614\n",
      "Epoch 98/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7588\n",
      "Epoch 99/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7568\n",
      "Epoch 100/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7565\n",
      "Epoch 101/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7544\n",
      "Epoch 102/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7531\n",
      "Epoch 103/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7516\n",
      "Epoch 104/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7502\n",
      "Epoch 105/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7489\n",
      "Epoch 106/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7476\n",
      "Epoch 107/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7463\n",
      "Epoch 108/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7461\n",
      "Epoch 109/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7439\n",
      "Epoch 110/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7438\n",
      "Epoch 111/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7423\n",
      "Epoch 112/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7412\n",
      "Epoch 113/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7399\n",
      "Epoch 114/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7384\n",
      "Epoch 115/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7377\n",
      "Epoch 116/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7364\n",
      "Epoch 117/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7364\n",
      "Epoch 118/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7358\n",
      "Epoch 119/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7333\n",
      "Epoch 120/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7330\n",
      "Epoch 121/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7317\n",
      "Epoch 122/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7307\n",
      "Epoch 123/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7299\n",
      "Epoch 124/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7287\n",
      "Epoch 125/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7276\n",
      "Epoch 126/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7268\n",
      "Epoch 127/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7259\n",
      "Epoch 128/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7250\n",
      "Epoch 129/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7243\n",
      "Epoch 130/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7233\n",
      "Epoch 131/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7227\n",
      "Epoch 132/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7217\n",
      "Epoch 133/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7209\n",
      "Epoch 134/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7199\n",
      "Epoch 135/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7193\n",
      "Epoch 136/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7190\n",
      "Epoch 137/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7174\n",
      "Epoch 138/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7178\n",
      "Epoch 139/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7163\n",
      "Epoch 140/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7158\n",
      "Epoch 141/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7150\n",
      "Epoch 142/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7136\n",
      "Epoch 143/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7134\n",
      "Epoch 144/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7130\n",
      "Epoch 145/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7122\n",
      "Epoch 146/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7115\n",
      "Epoch 147/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7112\n",
      "Epoch 148/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.7095\n",
      "Epoch 149/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7094\n",
      "Epoch 150/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7088\n",
      "Epoch 151/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7083\n",
      "Epoch 152/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7078\n",
      "Epoch 153/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7069\n",
      "Epoch 154/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7075\n",
      "Epoch 155/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7067\n",
      "Epoch 156/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7077\n",
      "Epoch 157/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7051\n",
      "Epoch 158/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7038\n",
      "Epoch 159/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7028\n",
      "Epoch 160/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7025\n",
      "Epoch 161/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7019\n",
      "Epoch 162/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7027\n",
      "Epoch 163/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7017\n",
      "Epoch 164/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7008\n",
      "Epoch 165/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7004\n",
      "Epoch 166/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7002\n",
      "Epoch 167/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7003\n",
      "Epoch 168/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7003\n",
      "Epoch 169/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6978\n",
      "Epoch 170/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6982\n",
      "Epoch 171/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6973\n",
      "Epoch 172/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6972\n",
      "Epoch 173/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6963\n",
      "Epoch 174/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6965\n",
      "Epoch 175/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6959\n",
      "Epoch 176/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6959\n",
      "Epoch 177/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6954\n",
      "Epoch 178/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6940\n",
      "Epoch 179/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6938\n",
      "Epoch 180/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6933\n",
      "Epoch 181/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6931\n",
      "Epoch 182/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6928\n",
      "Epoch 183/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6933\n",
      "Epoch 184/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6949\n",
      "Epoch 185/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6943\n",
      "Epoch 186/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6943\n",
      "Epoch 187/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6940\n",
      "Epoch 188/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6906\n",
      "Epoch 189/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6898\n",
      "Epoch 190/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6918\n",
      "Epoch 191/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6919\n",
      "Epoch 192/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6897\n",
      "Epoch 193/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6880\n",
      "Epoch 194/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6874\n",
      "Epoch 195/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6874\n",
      "Epoch 196/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6869\n",
      "Epoch 197/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6880\n",
      "Epoch 198/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6875\n",
      "Epoch 199/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6863\n",
      "Epoch 200/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6864\n",
      "Epoch 201/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6856\n",
      "Epoch 202/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6849\n",
      "Epoch 203/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6851\n",
      "Epoch 204/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6850\n",
      "Epoch 205/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6872\n",
      "Epoch 206/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6871\n",
      "Epoch 207/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6857\n",
      "Epoch 208/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6833\n",
      "Epoch 209/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6836\n",
      "Epoch 210/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6831\n",
      "Epoch 211/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6840\n",
      "Epoch 212/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6854\n",
      "Epoch 213/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6830\n",
      "Epoch 214/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6828\n",
      "Epoch 215/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6819\n",
      "Epoch 216/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6814\n",
      "Epoch 217/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6821\n",
      "Epoch 218/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6806\n",
      "Epoch 219/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6813\n",
      "Epoch 220/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6807\n",
      "Epoch 221/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6809\n",
      "Epoch 222/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6819\n",
      "Epoch 223/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6811\n",
      "Epoch 224/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6794\n",
      "Epoch 225/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6801\n",
      "Epoch 226/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6811\n",
      "Epoch 227/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6810\n",
      "Epoch 228/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6784\n",
      "Epoch 229/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6777\n",
      "Epoch 230/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6776\n",
      "Epoch 231/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6769\n",
      "Epoch 232/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6772\n",
      "Epoch 233/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6768\n",
      "Epoch 234/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6771\n",
      "Epoch 235/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6769\n",
      "Epoch 236/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6764\n",
      "Epoch 237/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6765\n",
      "Epoch 238/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6762\n",
      "Epoch 239/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6760\n",
      "Epoch 240/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6766\n",
      "Epoch 241/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6779\n",
      "Epoch 242/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6794\n",
      "Epoch 243/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6775\n",
      "Epoch 244/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6745\n",
      "Epoch 245/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6742\n",
      "Epoch 246/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6765\n",
      "Epoch 247/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6752\n",
      "Epoch 248/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6738\n",
      "Epoch 249/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6734\n",
      "Epoch 250/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6744\n",
      "Epoch 251/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6730\n",
      "Epoch 252/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6725\n",
      "Epoch 253/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6734\n",
      "Epoch 254/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6747\n",
      "Epoch 255/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6742\n",
      "Epoch 256/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6739\n",
      "Epoch 257/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6743\n",
      "Epoch 258/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6721\n",
      "Epoch 259/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6718\n",
      "Epoch 260/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6724\n",
      "Epoch 261/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6714\n",
      "Epoch 262/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6725\n",
      "Epoch 263/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6713\n",
      "Epoch 264/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6746\n",
      "Epoch 265/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6784\n",
      "Epoch 266/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6717\n",
      "Epoch 267/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6703\n",
      "Epoch 268/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6700\n",
      "Epoch 269/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6698\n",
      "Epoch 270/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6706\n",
      "Epoch 271/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6701\n",
      "Epoch 272/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6692\n",
      "Epoch 273/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6691\n",
      "Epoch 274/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6697\n",
      "Epoch 275/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6703\n",
      "Epoch 276/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6691\n",
      "Epoch 277/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6705\n",
      "Epoch 278/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6737\n",
      "Epoch 279/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6690\n",
      "Epoch 280/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6685\n",
      "Epoch 281/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6679\n",
      "Epoch 282/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6680\n",
      "Epoch 283/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6680\n",
      "Epoch 284/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6699\n",
      "Epoch 285/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6693\n",
      "Epoch 286/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6674\n",
      "Epoch 287/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6673\n",
      "Epoch 288/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6668\n",
      "Epoch 289/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6674\n",
      "Epoch 290/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6676\n",
      "Epoch 291/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6670\n",
      "Epoch 292/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6707\n",
      "Epoch 293/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6693\n",
      "Epoch 294/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6661\n",
      "Epoch 295/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6661\n",
      "Epoch 296/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6659\n",
      "Epoch 297/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6669\n",
      "Epoch 298/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6665\n",
      "Epoch 299/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6658\n",
      "Epoch 300/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6658\n",
      "102/102 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1/300\n",
      "102/102 [==============================] - 1s 4ms/step - loss: 31.4769\n",
      "Epoch 2/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 4.0722\n",
      "Epoch 3/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.8238\n",
      "Epoch 4/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.5141\n",
      "Epoch 5/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.4427\n",
      "Epoch 6/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.4130\n",
      "Epoch 7/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.3960\n",
      "Epoch 8/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.3848\n",
      "Epoch 9/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.3768\n",
      "Epoch 10/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 1.3710\n",
      "Epoch 11/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.3666\n",
      "Epoch 12/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.3632\n",
      "Epoch 13/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.3606\n",
      "Epoch 14/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.3584\n",
      "Epoch 15/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.3565\n",
      "Epoch 16/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.3548\n",
      "Epoch 17/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.3533\n",
      "Epoch 18/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.3519\n",
      "Epoch 19/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.3504\n",
      "Epoch 20/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.3491\n",
      "Epoch 21/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.3476\n",
      "Epoch 22/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.3461\n",
      "Epoch 23/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.3447\n",
      "Epoch 24/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.3429\n",
      "Epoch 25/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.3413\n",
      "Epoch 26/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.3400\n",
      "Epoch 27/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.3379\n",
      "Epoch 28/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.3358\n",
      "Epoch 29/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.3335\n",
      "Epoch 30/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.3312\n",
      "Epoch 31/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.3287\n",
      "Epoch 32/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.3262\n",
      "Epoch 33/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.3239\n",
      "Epoch 34/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.3214\n",
      "Epoch 35/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.3185\n",
      "Epoch 36/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.3162\n",
      "Epoch 37/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.3129\n",
      "Epoch 38/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.3099\n",
      "Epoch 39/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.3069\n",
      "Epoch 40/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.3030\n",
      "Epoch 41/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.2998\n",
      "Epoch 42/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.2963\n",
      "Epoch 43/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.2920\n",
      "Epoch 44/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.2882\n",
      "Epoch 45/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.2847\n",
      "Epoch 46/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.2798\n",
      "Epoch 47/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.2761\n",
      "Epoch 48/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.2724\n",
      "Epoch 49/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.2679\n",
      "Epoch 50/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.2645\n",
      "Epoch 51/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.2604\n",
      "Epoch 52/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.2555\n",
      "Epoch 53/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.2520\n",
      "Epoch 54/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.2486\n",
      "Epoch 55/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.2447\n",
      "Epoch 56/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 4ms/step - loss: 1.2410\n",
      "Epoch 57/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.2373\n",
      "Epoch 58/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.2342\n",
      "Epoch 59/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.2294\n",
      "Epoch 60/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.2260\n",
      "Epoch 61/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.2231\n",
      "Epoch 62/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.2198\n",
      "Epoch 63/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.2153\n",
      "Epoch 64/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.2134\n",
      "Epoch 65/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.2098\n",
      "Epoch 66/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.2068\n",
      "Epoch 67/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.2028\n",
      "Epoch 68/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1996\n",
      "Epoch 69/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1969\n",
      "Epoch 70/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1933\n",
      "Epoch 71/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1904\n",
      "Epoch 72/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1884\n",
      "Epoch 73/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1849\n",
      "Epoch 74/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1822\n",
      "Epoch 75/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1797\n",
      "Epoch 76/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1765\n",
      "Epoch 77/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1733\n",
      "Epoch 78/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1703\n",
      "Epoch 79/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1675\n",
      "Epoch 80/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1643\n",
      "Epoch 81/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1617\n",
      "Epoch 82/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1601\n",
      "Epoch 83/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1570\n",
      "Epoch 84/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1545\n",
      "Epoch 85/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1517\n",
      "Epoch 86/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1499\n",
      "Epoch 87/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1475\n",
      "Epoch 88/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1448\n",
      "Epoch 89/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1439\n",
      "Epoch 90/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1406\n",
      "Epoch 91/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1384\n",
      "Epoch 92/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1370\n",
      "Epoch 93/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1346\n",
      "Epoch 94/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1330\n",
      "Epoch 95/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1308\n",
      "Epoch 96/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1289\n",
      "Epoch 97/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1291\n",
      "Epoch 98/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1255\n",
      "Epoch 99/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1227\n",
      "Epoch 100/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1219\n",
      "Epoch 101/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1202\n",
      "Epoch 102/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1184\n",
      "Epoch 103/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1164\n",
      "Epoch 104/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1154\n",
      "Epoch 105/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1135\n",
      "Epoch 106/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1114\n",
      "Epoch 107/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1100\n",
      "Epoch 108/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1081\n",
      "Epoch 109/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1075\n",
      "Epoch 110/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1055\n",
      "Epoch 111/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.1048\n",
      "Epoch 112/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1038\n",
      "Epoch 113/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1015\n",
      "Epoch 114/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1009\n",
      "Epoch 115/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0994\n",
      "Epoch 116/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0979\n",
      "Epoch 117/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0971\n",
      "Epoch 118/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0966\n",
      "Epoch 119/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0940\n",
      "Epoch 120/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0936\n",
      "Epoch 121/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0918\n",
      "Epoch 122/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0907\n",
      "Epoch 123/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0899\n",
      "Epoch 124/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0897\n",
      "Epoch 125/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0874\n",
      "Epoch 126/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0861\n",
      "Epoch 127/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0852\n",
      "Epoch 128/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0843\n",
      "Epoch 129/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0829\n",
      "Epoch 130/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0824\n",
      "Epoch 131/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0813\n",
      "Epoch 132/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0805\n",
      "Epoch 133/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0789\n",
      "Epoch 134/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0781\n",
      "Epoch 135/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0776\n",
      "Epoch 136/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0767\n",
      "Epoch 137/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0753\n",
      "Epoch 138/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0744\n",
      "Epoch 139/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0730\n",
      "Epoch 140/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0725\n",
      "Epoch 141/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0721\n",
      "Epoch 142/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0706\n",
      "Epoch 143/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0698\n",
      "Epoch 144/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0699\n",
      "Epoch 145/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0680\n",
      "Epoch 146/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0674\n",
      "Epoch 147/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0653\n",
      "Epoch 148/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0653\n",
      "Epoch 149/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0646\n",
      "Epoch 150/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0638\n",
      "Epoch 151/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0632\n",
      "Epoch 152/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0625\n",
      "Epoch 153/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0614\n",
      "Epoch 154/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0612\n",
      "Epoch 155/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0602\n",
      "Epoch 156/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0599\n",
      "Epoch 157/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0591\n",
      "Epoch 158/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0576\n",
      "Epoch 159/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0575\n",
      "Epoch 160/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0570\n",
      "Epoch 161/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0575\n",
      "Epoch 162/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0557\n",
      "Epoch 163/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0545\n",
      "Epoch 164/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0536\n",
      "Epoch 165/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0530\n",
      "Epoch 166/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0525\n",
      "Epoch 167/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0523\n",
      "Epoch 168/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0510\n",
      "Epoch 169/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0504\n",
      "Epoch 170/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0503\n",
      "Epoch 171/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0494\n",
      "Epoch 172/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0493\n",
      "Epoch 173/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0476\n",
      "Epoch 174/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0477\n",
      "Epoch 175/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0468\n",
      "Epoch 176/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0483\n",
      "Epoch 177/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0477\n",
      "Epoch 178/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0454\n",
      "Epoch 179/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0452\n",
      "Epoch 180/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0443\n",
      "Epoch 181/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.0442\n",
      "Epoch 182/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 1.0435\n",
      "Epoch 183/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.0427\n",
      "Epoch 184/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.0416\n",
      "Epoch 185/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.0424\n",
      "Epoch 186/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0408\n",
      "Epoch 187/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0402\n",
      "Epoch 188/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0409\n",
      "Epoch 189/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0399\n",
      "Epoch 190/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0389\n",
      "Epoch 191/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0385\n",
      "Epoch 192/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0384\n",
      "Epoch 193/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0378\n",
      "Epoch 194/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0383\n",
      "Epoch 195/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0375\n",
      "Epoch 196/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0367\n",
      "Epoch 197/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0359\n",
      "Epoch 198/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0357\n",
      "Epoch 199/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0350\n",
      "Epoch 200/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0350\n",
      "Epoch 201/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0341\n",
      "Epoch 202/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0342\n",
      "Epoch 203/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0350\n",
      "Epoch 204/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 1.0352\n",
      "Epoch 205/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0326\n",
      "Epoch 206/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0320\n",
      "Epoch 207/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0319\n",
      "Epoch 208/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0315\n",
      "Epoch 209/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 1.0304\n",
      "Epoch 210/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.0317\n",
      "Epoch 211/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.0311\n",
      "Epoch 212/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 1.0302\n",
      "Epoch 213/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0293\n",
      "Epoch 214/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 1.0297\n",
      "Epoch 215/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0290\n",
      "Epoch 216/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0283\n",
      "Epoch 217/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0289\n",
      "Epoch 218/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 1.0273\n",
      "Epoch 219/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0275\n",
      "Epoch 220/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0270\n",
      "Epoch 221/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0266\n",
      "Epoch 222/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0280\n",
      "Epoch 223/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0304\n",
      "Epoch 224/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0268\n",
      "Epoch 225/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0266\n",
      "Epoch 226/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0258\n",
      "Epoch 227/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0244\n",
      "Epoch 228/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0243\n",
      "Epoch 229/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0248\n",
      "Epoch 230/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0233\n",
      "Epoch 231/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0237\n",
      "Epoch 232/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0232\n",
      "Epoch 233/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0232\n",
      "Epoch 234/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0235\n",
      "Epoch 235/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0257\n",
      "Epoch 236/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0212\n",
      "Epoch 237/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0272\n",
      "Epoch 238/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0242\n",
      "Epoch 239/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0219\n",
      "Epoch 240/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0217\n",
      "Epoch 241/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0211\n",
      "Epoch 242/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0202\n",
      "Epoch 243/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0204\n",
      "Epoch 244/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0203\n",
      "Epoch 245/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0200\n",
      "Epoch 246/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0206\n",
      "Epoch 247/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0196\n",
      "Epoch 248/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0210\n",
      "Epoch 249/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0216\n",
      "Epoch 250/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0179\n",
      "Epoch 251/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0176\n",
      "Epoch 252/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0177\n",
      "Epoch 253/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0179\n",
      "Epoch 254/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0172\n",
      "Epoch 255/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0176\n",
      "Epoch 256/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0179\n",
      "Epoch 257/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0171\n",
      "Epoch 258/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0164\n",
      "Epoch 259/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0181\n",
      "Epoch 260/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0183\n",
      "Epoch 261/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0159\n",
      "Epoch 262/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0162\n",
      "Epoch 263/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0168\n",
      "Epoch 264/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0149\n",
      "Epoch 265/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0154\n",
      "Epoch 266/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0153\n",
      "Epoch 267/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0163\n",
      "Epoch 268/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0158\n",
      "Epoch 269/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0145\n",
      "Epoch 270/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0148\n",
      "Epoch 271/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0149\n",
      "Epoch 272/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0167\n",
      "Epoch 273/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0144\n",
      "Epoch 274/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0147\n",
      "Epoch 275/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0138\n",
      "Epoch 276/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0157\n",
      "Epoch 277/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0178\n",
      "Epoch 278/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0124\n",
      "Epoch 279/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0136\n",
      "Epoch 280/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0119\n",
      "Epoch 281/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0121\n",
      "Epoch 282/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0115\n",
      "Epoch 283/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0111\n",
      "Epoch 284/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0137\n",
      "Epoch 285/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0108\n",
      "Epoch 286/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0146\n",
      "Epoch 287/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0126\n",
      "Epoch 288/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0110\n",
      "Epoch 289/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0123\n",
      "Epoch 290/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0116\n",
      "Epoch 291/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0169\n",
      "Epoch 292/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0156\n",
      "Epoch 293/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0131\n",
      "Epoch 294/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0151\n",
      "Epoch 295/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0140\n",
      "Epoch 296/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0123\n",
      "Epoch 297/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0115\n",
      "Epoch 298/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0110\n",
      "Epoch 299/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0123\n",
      "Epoch 300/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0112\n",
      "102/102 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "l2_reg_val_list = 10**np.arange(-3,0,0.5)\n",
    "num_iters = len(l2_reg_val_list)\n",
    "num_epochs = 300\n",
    "J_list = np.zeros((num_epochs,num_iters))\n",
    "train_precision = []\n",
    "valid_precision = []\n",
    "counter = 0\n",
    "for l2_reg_val in l2_reg_val_list:    \n",
    "    np.random.seed(42 + k)\n",
    "    \n",
    "    \n",
    "    tf.random.set_seed(1234) # for consistent results\n",
    "    model = Sequential(\n",
    "        [               \n",
    "            ### START CODE HERE ### \n",
    "            Dense(units=442, activation='relu',activity_regularizer=tf.keras.regularizers.L2(l2_reg_val)),\n",
    "            Dense(units=131, activation='relu',activity_regularizer=tf.keras.regularizers.L2(l2_reg_val)),\n",
    "            Dense(units=25, activation='relu',activity_regularizer=tf.keras.regularizers.L2(l2_reg_val)),\n",
    "            Dense(units=4, activation='linear',activity_regularizer=tf.keras.regularizers.L2(l2_reg_val))\n",
    "            ### END CODE HERE ### \n",
    "        ], name = \"my_model\" \n",
    "    )\n",
    "    model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                 optimizer=tf.keras.optimizers.Adam(learning_rate=3*(10**(-5))),)\n",
    "    history = model.fit(X, y, epochs=num_epochs)\n",
    "    J_list[:,counter] = history.history['loss']\n",
    "    counter +=1\n",
    "    prediction_train = model.predict(X)\n",
    "    prediction_train_p = tf.nn.softmax(prediction_train)\n",
    "    y_hat_train = np.zeros((len(prediction_train_p),1))\n",
    "    for i in range(len(y_hat_train)):\n",
    "        y_hat_train[i] = np.argmax(prediction_train_p[i])\n",
    "    train_precision.append(np.sum(y_hat_train==y)/len(y_hat_train))\n",
    "    \n",
    "    prediction_valid = model.predict(X_valid)\n",
    "    prediction_valid_p = tf.nn.softmax(prediction_valid)\n",
    "    y_hat_valid = np.zeros((len(prediction_valid_p),1))\n",
    "    for i in range(len(y_hat_valid)):\n",
    "        y_hat_valid[i] = np.argmax(prediction_valid_p[i])\n",
    "    valid_precision.append(np.sum(y_hat_valid==y_valid)/len(y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db075476",
   "metadata": {},
   "source": [
    "We see a small increase in the validation dataset for L2 regularisation with srength 0.01, lets explore values around this number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b7187cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1844a2cb580>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.log10(l2_reg_val_list),train_precision,'ko',label=\"train precision\")\n",
    "plt.plot(np.log10(l2_reg_val_list),valid_precision,'bx',label=\"validate precision\")\n",
    "plt.ylabel(\"Cost function\"), plt.xlabel(\"log(L2)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c260c6",
   "metadata": {},
   "source": [
    "Now we vary the L2 parameter strength as $10^d$ where for $d$ between $-2.375$ and $-1.5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "38280727",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "102/102 [==============================] - 1s 4ms/step - loss: 1.7417\n",
      "Epoch 2/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 1.1660\n",
      "Epoch 3/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.0307\n",
      "Epoch 4/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.9454\n",
      "Epoch 5/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.8793\n",
      "Epoch 6/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.8196\n",
      "Epoch 7/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.7654\n",
      "Epoch 8/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7187\n",
      "Epoch 9/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6748\n",
      "Epoch 10/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6401\n",
      "Epoch 11/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6066\n",
      "Epoch 12/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5761\n",
      "Epoch 13/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5505\n",
      "Epoch 14/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.5279\n",
      "Epoch 15/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.5049\n",
      "Epoch 16/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4894\n",
      "Epoch 17/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4678\n",
      "Epoch 18/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.4532\n",
      "Epoch 19/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.4341\n",
      "Epoch 20/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4220\n",
      "Epoch 21/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4059\n",
      "Epoch 22/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3948\n",
      "Epoch 23/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3821\n",
      "Epoch 24/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3710\n",
      "Epoch 25/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3590\n",
      "Epoch 26/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3482\n",
      "Epoch 27/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3385\n",
      "Epoch 28/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3269\n",
      "Epoch 29/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3183\n",
      "Epoch 30/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3105\n",
      "Epoch 31/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3020\n",
      "Epoch 32/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2948\n",
      "Epoch 33/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2865\n",
      "Epoch 34/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.2821\n",
      "Epoch 35/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.2722\n",
      "Epoch 36/300\n",
      "102/102 [==============================] - 1s 9ms/step - loss: 0.2658\n",
      "Epoch 37/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.2601\n",
      "Epoch 38/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.2558\n",
      "Epoch 39/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.2498\n",
      "Epoch 40/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.2454\n",
      "Epoch 41/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.2395\n",
      "Epoch 42/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.2344\n",
      "Epoch 43/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2287\n",
      "Epoch 44/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2239\n",
      "Epoch 45/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.2203\n",
      "Epoch 46/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.2157\n",
      "Epoch 47/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2131\n",
      "Epoch 48/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2103\n",
      "Epoch 49/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.2074\n",
      "Epoch 50/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.2039\n",
      "Epoch 51/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2004\n",
      "Epoch 52/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1988\n",
      "Epoch 53/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1955\n",
      "Epoch 54/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1933\n",
      "Epoch 55/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1909\n",
      "Epoch 56/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.1892\n",
      "Epoch 57/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1869\n",
      "Epoch 58/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1847\n",
      "Epoch 59/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.1832\n",
      "Epoch 60/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1819\n",
      "Epoch 61/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.1796\n",
      "Epoch 62/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.1779\n",
      "Epoch 63/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.1765\n",
      "Epoch 64/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1755\n",
      "Epoch 65/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.1737\n",
      "Epoch 66/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.1726\n",
      "Epoch 67/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.1709\n",
      "Epoch 68/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.1686\n",
      "Epoch 69/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.1680\n",
      "Epoch 70/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.1664\n",
      "Epoch 71/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.1652\n",
      "Epoch 72/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1639\n",
      "Epoch 73/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1630\n",
      "Epoch 74/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1615\n",
      "Epoch 75/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1605\n",
      "Epoch 76/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1592\n",
      "Epoch 77/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1583\n",
      "Epoch 78/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1568\n",
      "Epoch 79/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1561\n",
      "Epoch 80/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1551\n",
      "Epoch 81/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1543\n",
      "Epoch 82/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.1531\n",
      "Epoch 83/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.1521\n",
      "Epoch 84/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1518\n",
      "Epoch 85/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1507\n",
      "Epoch 86/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1493\n",
      "Epoch 87/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1488\n",
      "Epoch 88/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1477\n",
      "Epoch 89/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.1473\n",
      "Epoch 90/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.1469\n",
      "Epoch 91/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1458\n",
      "Epoch 92/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1450\n",
      "Epoch 93/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1441\n",
      "Epoch 94/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1432\n",
      "Epoch 95/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1426\n",
      "Epoch 96/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1416\n",
      "Epoch 97/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1412\n",
      "Epoch 98/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1405\n",
      "Epoch 99/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1398\n",
      "Epoch 100/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1393\n",
      "Epoch 101/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1388\n",
      "Epoch 102/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1381\n",
      "Epoch 103/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.1375\n",
      "Epoch 104/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1366\n",
      "Epoch 105/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1361\n",
      "Epoch 106/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.1356\n",
      "Epoch 107/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.1349\n",
      "Epoch 108/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.1346\n",
      "Epoch 109/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1340\n",
      "Epoch 110/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1338\n",
      "Epoch 111/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1333\n",
      "Epoch 112/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.1328\n",
      "Epoch 113/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.1322\n",
      "Epoch 114/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1315\n",
      "Epoch 115/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.1310\n",
      "Epoch 116/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.1309\n",
      "Epoch 117/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.1300\n",
      "Epoch 118/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.1296\n",
      "Epoch 119/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.1293\n",
      "Epoch 120/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.1314\n",
      "Epoch 121/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.1285\n",
      "Epoch 122/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.1282\n",
      "Epoch 123/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.1275\n",
      "Epoch 124/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.1273\n",
      "Epoch 125/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.1268\n",
      "Epoch 126/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.1264\n",
      "Epoch 127/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.1262\n",
      "Epoch 128/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.1258\n",
      "Epoch 129/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.1252\n",
      "Epoch 130/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.1253\n",
      "Epoch 131/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.1248\n",
      "Epoch 132/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.1244\n",
      "Epoch 133/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.1240\n",
      "Epoch 134/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.1240\n",
      "Epoch 135/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.1235\n",
      "Epoch 136/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.1230\n",
      "Epoch 137/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.1229\n",
      "Epoch 138/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1226\n",
      "Epoch 139/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1224\n",
      "Epoch 140/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1223\n",
      "Epoch 141/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1217\n",
      "Epoch 142/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1215\n",
      "Epoch 143/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1211\n",
      "Epoch 144/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1218\n",
      "Epoch 145/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1208\n",
      "Epoch 146/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1204\n",
      "Epoch 147/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1201\n",
      "Epoch 148/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1198\n",
      "Epoch 149/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1202\n",
      "Epoch 150/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1195\n",
      "Epoch 151/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1194\n",
      "Epoch 152/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1194\n",
      "Epoch 153/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1185\n",
      "Epoch 154/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1185\n",
      "Epoch 155/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1182\n",
      "Epoch 156/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1185\n",
      "Epoch 157/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1178\n",
      "Epoch 158/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1175\n",
      "Epoch 159/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1173\n",
      "Epoch 160/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1174\n",
      "Epoch 161/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1169\n",
      "Epoch 162/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1169\n",
      "Epoch 163/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1170\n",
      "Epoch 164/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1164\n",
      "Epoch 165/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1161\n",
      "Epoch 166/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1161\n",
      "Epoch 167/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1161\n",
      "Epoch 168/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1157\n",
      "Epoch 169/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1158\n",
      "Epoch 170/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1156\n",
      "Epoch 171/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1153\n",
      "Epoch 172/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1149\n",
      "Epoch 173/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1150\n",
      "Epoch 174/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1147\n",
      "Epoch 175/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1145\n",
      "Epoch 176/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1144\n",
      "Epoch 177/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1142\n",
      "Epoch 178/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1144\n",
      "Epoch 179/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1142\n",
      "Epoch 180/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1142\n",
      "Epoch 181/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1136\n",
      "Epoch 182/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1137\n",
      "Epoch 183/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1133\n",
      "Epoch 184/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1131\n",
      "Epoch 185/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1130\n",
      "Epoch 186/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1128\n",
      "Epoch 187/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1129\n",
      "Epoch 188/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1130\n",
      "Epoch 189/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1126\n",
      "Epoch 190/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1123\n",
      "Epoch 191/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1123\n",
      "Epoch 192/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1122\n",
      "Epoch 193/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1120\n",
      "Epoch 194/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1121\n",
      "Epoch 195/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1118\n",
      "Epoch 196/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1116\n",
      "Epoch 197/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1116\n",
      "Epoch 198/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1118\n",
      "Epoch 199/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1115\n",
      "Epoch 200/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1112\n",
      "Epoch 201/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1112\n",
      "Epoch 202/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1112\n",
      "Epoch 203/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1110\n",
      "Epoch 204/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1107\n",
      "Epoch 205/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1112\n",
      "Epoch 206/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1113\n",
      "Epoch 207/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1105\n",
      "Epoch 208/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1104\n",
      "Epoch 209/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1101\n",
      "Epoch 210/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1102\n",
      "Epoch 211/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1102\n",
      "Epoch 212/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1101\n",
      "Epoch 213/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1098\n",
      "Epoch 214/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1098\n",
      "Epoch 215/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1096\n",
      "Epoch 216/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1097\n",
      "Epoch 217/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1108\n",
      "Epoch 218/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1121\n",
      "Epoch 219/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1101\n",
      "Epoch 220/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1092\n",
      "Epoch 221/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1090\n",
      "Epoch 222/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1089\n",
      "Epoch 223/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1087\n",
      "Epoch 224/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1087\n",
      "Epoch 225/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1087\n",
      "Epoch 226/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1086\n",
      "Epoch 227/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1086\n",
      "Epoch 228/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1084\n",
      "Epoch 229/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1083\n",
      "Epoch 230/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1083\n",
      "Epoch 231/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1083\n",
      "Epoch 232/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1081\n",
      "Epoch 233/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1082\n",
      "Epoch 234/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1080\n",
      "Epoch 235/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1079\n",
      "Epoch 236/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1079\n",
      "Epoch 237/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1077\n",
      "Epoch 238/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1077\n",
      "Epoch 239/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1077\n",
      "Epoch 240/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1279\n",
      "Epoch 241/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1200\n",
      "Epoch 242/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1097\n",
      "Epoch 243/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1086\n",
      "Epoch 244/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1082\n",
      "Epoch 245/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1080\n",
      "Epoch 246/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1079\n",
      "Epoch 247/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1077\n",
      "Epoch 248/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1076\n",
      "Epoch 249/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1075\n",
      "Epoch 250/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1074\n",
      "Epoch 251/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1073\n",
      "Epoch 252/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1072\n",
      "Epoch 253/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1072\n",
      "Epoch 254/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1070\n",
      "Epoch 255/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1070\n",
      "Epoch 256/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1069\n",
      "Epoch 257/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1068\n",
      "Epoch 258/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1068\n",
      "Epoch 259/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1067\n",
      "Epoch 260/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1066\n",
      "Epoch 261/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1066\n",
      "Epoch 262/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1065\n",
      "Epoch 263/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1065\n",
      "Epoch 264/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1064\n",
      "Epoch 265/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1064\n",
      "Epoch 266/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1063\n",
      "Epoch 267/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1062\n",
      "Epoch 268/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1062\n",
      "Epoch 269/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1062\n",
      "Epoch 270/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1060\n",
      "Epoch 271/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1060\n",
      "Epoch 272/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1060\n",
      "Epoch 273/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1060\n",
      "Epoch 274/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1059\n",
      "Epoch 275/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1058\n",
      "Epoch 276/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1058\n",
      "Epoch 277/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1057\n",
      "Epoch 278/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1057\n",
      "Epoch 279/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1056\n",
      "Epoch 280/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1057\n",
      "Epoch 281/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1055\n",
      "Epoch 282/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1055\n",
      "Epoch 283/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1055\n",
      "Epoch 284/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1053\n",
      "Epoch 285/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1054\n",
      "Epoch 286/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1057\n",
      "Epoch 287/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1054\n",
      "Epoch 288/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1052\n",
      "Epoch 289/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1052\n",
      "Epoch 290/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1051\n",
      "Epoch 291/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1050\n",
      "Epoch 292/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1056\n",
      "Epoch 293/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1327\n",
      "Epoch 294/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1129\n",
      "Epoch 295/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1060\n",
      "Epoch 296/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1056\n",
      "Epoch 297/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1055\n",
      "Epoch 298/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1053\n",
      "Epoch 299/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1051\n",
      "Epoch 300/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1050\n",
      "102/102 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1/300\n",
      "102/102 [==============================] - 1s 4ms/step - loss: 1.8908\n",
      "Epoch 2/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.2040\n",
      "Epoch 3/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0698\n",
      "Epoch 4/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.9842\n",
      "Epoch 5/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.9153\n",
      "Epoch 6/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.8561\n",
      "Epoch 7/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.8041\n",
      "Epoch 8/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.7586\n",
      "Epoch 9/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.7143\n",
      "Epoch 10/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6799\n",
      "Epoch 11/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6452\n",
      "Epoch 12/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6141\n",
      "Epoch 13/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5875\n",
      "Epoch 14/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5651\n",
      "Epoch 15/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5413\n",
      "Epoch 16/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5249\n",
      "Epoch 17/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5012\n",
      "Epoch 18/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4858\n",
      "Epoch 19/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4668\n",
      "Epoch 20/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4549\n",
      "Epoch 21/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4377\n",
      "Epoch 22/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4259\n",
      "Epoch 23/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4129\n",
      "Epoch 24/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4013\n",
      "Epoch 25/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3900\n",
      "Epoch 26/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3791\n",
      "Epoch 27/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3701\n",
      "Epoch 28/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3588\n",
      "Epoch 29/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3505\n",
      "Epoch 30/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3427\n",
      "Epoch 31/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3339\n",
      "Epoch 32/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3270\n",
      "Epoch 33/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3190\n",
      "Epoch 34/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3143\n",
      "Epoch 35/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3045\n",
      "Epoch 36/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2983\n",
      "Epoch 37/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2922\n",
      "Epoch 38/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2877\n",
      "Epoch 39/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2816\n",
      "Epoch 40/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2772\n",
      "Epoch 41/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2722\n",
      "Epoch 42/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2678\n",
      "Epoch 43/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2631\n",
      "Epoch 44/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2569\n",
      "Epoch 45/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2533\n",
      "Epoch 46/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2481\n",
      "Epoch 47/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2449\n",
      "Epoch 48/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2422\n",
      "Epoch 49/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2395\n",
      "Epoch 50/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2351\n",
      "Epoch 51/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2320\n",
      "Epoch 52/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2301\n",
      "Epoch 53/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2266\n",
      "Epoch 54/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2246\n",
      "Epoch 55/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2216\n",
      "Epoch 56/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2198\n",
      "Epoch 57/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2171\n",
      "Epoch 58/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2148\n",
      "Epoch 59/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2129\n",
      "Epoch 60/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2115\n",
      "Epoch 61/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2092\n",
      "Epoch 62/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2074\n",
      "Epoch 63/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2055\n",
      "Epoch 64/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2042\n",
      "Epoch 65/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2024\n",
      "Epoch 66/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2014\n",
      "Epoch 67/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1992\n",
      "Epoch 68/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1972\n",
      "Epoch 69/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1961\n",
      "Epoch 70/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1944\n",
      "Epoch 71/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1934\n",
      "Epoch 72/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1918\n",
      "Epoch 73/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1908\n",
      "Epoch 74/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1893\n",
      "Epoch 75/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1882\n",
      "Epoch 76/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1866\n",
      "Epoch 77/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1856\n",
      "Epoch 78/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1842\n",
      "Epoch 79/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1834\n",
      "Epoch 80/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1823\n",
      "Epoch 81/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1814\n",
      "Epoch 82/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1803\n",
      "Epoch 83/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1789\n",
      "Epoch 84/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1785\n",
      "Epoch 85/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1770\n",
      "Epoch 86/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1761\n",
      "Epoch 87/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1754\n",
      "Epoch 88/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1740\n",
      "Epoch 89/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1736\n",
      "Epoch 90/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1736\n",
      "Epoch 91/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1721\n",
      "Epoch 92/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1712\n",
      "Epoch 93/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1703\n",
      "Epoch 94/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1695\n",
      "Epoch 95/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1688\n",
      "Epoch 96/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1676\n",
      "Epoch 97/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1670\n",
      "Epoch 98/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1663\n",
      "Epoch 99/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1655\n",
      "Epoch 100/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1650\n",
      "Epoch 101/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1642\n",
      "Epoch 102/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1635\n",
      "Epoch 103/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1632\n",
      "Epoch 104/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1621\n",
      "Epoch 105/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1616\n",
      "Epoch 106/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1608\n",
      "Epoch 107/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1602\n",
      "Epoch 108/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1604\n",
      "Epoch 109/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1592\n",
      "Epoch 110/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1588\n",
      "Epoch 111/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1584\n",
      "Epoch 112/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1578\n",
      "Epoch 113/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1570\n",
      "Epoch 114/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1564\n",
      "Epoch 115/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1558\n",
      "Epoch 116/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1553\n",
      "Epoch 117/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1549\n",
      "Epoch 118/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1547\n",
      "Epoch 119/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1539\n",
      "Epoch 120/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1542\n",
      "Epoch 121/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1533\n",
      "Epoch 122/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1527\n",
      "Epoch 123/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1522\n",
      "Epoch 124/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1520\n",
      "Epoch 125/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1513\n",
      "Epoch 126/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1511\n",
      "Epoch 127/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1508\n",
      "Epoch 128/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1503\n",
      "Epoch 129/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1498\n",
      "Epoch 130/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1493\n",
      "Epoch 131/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1489\n",
      "Epoch 132/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1487\n",
      "Epoch 133/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1483\n",
      "Epoch 134/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1480\n",
      "Epoch 135/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1477\n",
      "Epoch 136/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1477\n",
      "Epoch 137/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1471\n",
      "Epoch 138/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1467\n",
      "Epoch 139/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1467\n",
      "Epoch 140/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1461\n",
      "Epoch 141/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1459\n",
      "Epoch 142/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1456\n",
      "Epoch 143/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1453\n",
      "Epoch 144/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1448\n",
      "Epoch 145/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1446\n",
      "Epoch 146/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1442\n",
      "Epoch 147/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1440\n",
      "Epoch 148/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1441\n",
      "Epoch 149/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1436\n",
      "Epoch 150/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1433\n",
      "Epoch 151/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1430\n",
      "Epoch 152/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1432\n",
      "Epoch 153/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1426\n",
      "Epoch 154/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1423\n",
      "Epoch 155/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1424\n",
      "Epoch 156/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1419\n",
      "Epoch 157/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1418\n",
      "Epoch 158/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1414\n",
      "Epoch 159/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1412\n",
      "Epoch 160/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1409\n",
      "Epoch 161/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1405\n",
      "Epoch 162/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1404\n",
      "Epoch 163/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1405\n",
      "Epoch 164/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1402\n",
      "Epoch 165/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1400\n",
      "Epoch 166/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1398\n",
      "Epoch 167/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1395\n",
      "Epoch 168/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1394\n",
      "Epoch 169/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1395\n",
      "Epoch 170/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1389\n",
      "Epoch 171/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.1387\n",
      "Epoch 172/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1388\n",
      "Epoch 173/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.1384\n",
      "Epoch 174/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1382\n",
      "Epoch 175/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1383\n",
      "Epoch 176/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1378\n",
      "Epoch 177/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.1376\n",
      "Epoch 178/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1376\n",
      "Epoch 179/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1373\n",
      "Epoch 180/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.1372\n",
      "Epoch 181/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.1371\n",
      "Epoch 182/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1368\n",
      "Epoch 183/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.1367\n",
      "Epoch 184/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.1365\n",
      "Epoch 185/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.1364\n",
      "Epoch 186/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.1364\n",
      "Epoch 187/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.1360\n",
      "Epoch 188/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1360\n",
      "Epoch 189/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1359\n",
      "Epoch 190/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1356\n",
      "Epoch 191/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1354\n",
      "Epoch 192/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.1352\n",
      "Epoch 193/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.1352\n",
      "Epoch 194/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1351\n",
      "Epoch 195/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1349\n",
      "Epoch 196/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1353\n",
      "Epoch 197/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1350\n",
      "Epoch 198/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1348\n",
      "Epoch 199/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1345\n",
      "Epoch 200/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1343\n",
      "Epoch 201/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1348\n",
      "Epoch 202/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1346\n",
      "Epoch 203/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1347\n",
      "Epoch 204/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1349\n",
      "Epoch 205/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1337\n",
      "Epoch 206/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1335\n",
      "Epoch 207/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.1333\n",
      "Epoch 208/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.1333\n",
      "Epoch 209/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.1331\n",
      "Epoch 210/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.1329\n",
      "Epoch 211/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.1328\n",
      "Epoch 212/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1331\n",
      "Epoch 213/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1334\n",
      "Epoch 214/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1326\n",
      "Epoch 215/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1326\n",
      "Epoch 216/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1326\n",
      "Epoch 217/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1326\n",
      "Epoch 218/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1323\n",
      "Epoch 219/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1324\n",
      "Epoch 220/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1327\n",
      "Epoch 221/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1530\n",
      "Epoch 222/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1414\n",
      "Epoch 223/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1326\n",
      "Epoch 224/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1321\n",
      "Epoch 225/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1319\n",
      "Epoch 226/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1317\n",
      "Epoch 227/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1315\n",
      "Epoch 228/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1314\n",
      "Epoch 229/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1313\n",
      "Epoch 230/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1313\n",
      "Epoch 231/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1311\n",
      "Epoch 232/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1310\n",
      "Epoch 233/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1310\n",
      "Epoch 234/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1309\n",
      "Epoch 235/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1308\n",
      "Epoch 236/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1307\n",
      "Epoch 237/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1306\n",
      "Epoch 238/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1306\n",
      "Epoch 239/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.1305\n",
      "Epoch 240/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1304\n",
      "Epoch 241/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.1303\n",
      "Epoch 242/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1303\n",
      "Epoch 243/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1302\n",
      "Epoch 244/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1301\n",
      "Epoch 245/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1300\n",
      "Epoch 246/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1300\n",
      "Epoch 247/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1299\n",
      "Epoch 248/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1299\n",
      "Epoch 249/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1298\n",
      "Epoch 250/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1298\n",
      "Epoch 251/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1305\n",
      "Epoch 252/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1296\n",
      "Epoch 253/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1296\n",
      "Epoch 254/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1294\n",
      "Epoch 255/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1294\n",
      "Epoch 256/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1293\n",
      "Epoch 257/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1293\n",
      "Epoch 258/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1291\n",
      "Epoch 259/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1291\n",
      "Epoch 260/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1289\n",
      "Epoch 261/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1291\n",
      "Epoch 262/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1367\n",
      "Epoch 263/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1570\n",
      "Epoch 264/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1310\n",
      "Epoch 265/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1299\n",
      "Epoch 266/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1296\n",
      "Epoch 267/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1293\n",
      "Epoch 268/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1292\n",
      "Epoch 269/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1291\n",
      "Epoch 270/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1289\n",
      "Epoch 271/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1289\n",
      "Epoch 272/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1288\n",
      "Epoch 273/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1286\n",
      "Epoch 274/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1286\n",
      "Epoch 275/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1285\n",
      "Epoch 276/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1284\n",
      "Epoch 277/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1284\n",
      "Epoch 278/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1284\n",
      "Epoch 279/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1283\n",
      "Epoch 280/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1282\n",
      "Epoch 281/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1282\n",
      "Epoch 282/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1281\n",
      "Epoch 283/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1281\n",
      "Epoch 284/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1280\n",
      "Epoch 285/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1280\n",
      "Epoch 286/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1279\n",
      "Epoch 287/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1279\n",
      "Epoch 288/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1278\n",
      "Epoch 289/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1277\n",
      "Epoch 290/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1277\n",
      "Epoch 291/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1276\n",
      "Epoch 292/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1276\n",
      "Epoch 293/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1275\n",
      "Epoch 294/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1275\n",
      "Epoch 295/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1274\n",
      "Epoch 296/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1281\n",
      "Epoch 297/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1278\n",
      "Epoch 298/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1273\n",
      "Epoch 299/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1272\n",
      "Epoch 300/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1271\n",
      "102/102 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1/300\n",
      "102/102 [==============================] - 1s 4ms/step - loss: 2.0883\n",
      "Epoch 2/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.2493\n",
      "Epoch 3/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1033\n",
      "Epoch 4/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0215\n",
      "Epoch 5/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.9577\n",
      "Epoch 6/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.9020\n",
      "Epoch 7/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.8515\n",
      "Epoch 8/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.8077\n",
      "Epoch 9/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7645\n",
      "Epoch 10/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7300\n",
      "Epoch 11/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6940\n",
      "Epoch 12/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6610\n",
      "Epoch 13/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6332\n",
      "Epoch 14/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6088\n",
      "Epoch 15/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5848\n",
      "Epoch 16/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5668\n",
      "Epoch 17/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5449\n",
      "Epoch 18/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5296\n",
      "Epoch 19/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5099\n",
      "Epoch 20/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4967\n",
      "Epoch 21/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4790\n",
      "Epoch 22/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4668\n",
      "Epoch 23/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4522\n",
      "Epoch 24/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4400\n",
      "Epoch 25/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4274\n",
      "Epoch 26/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4159\n",
      "Epoch 27/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4069\n",
      "Epoch 28/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3949\n",
      "Epoch 29/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3864\n",
      "Epoch 30/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3780\n",
      "Epoch 31/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3685\n",
      "Epoch 32/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3613\n",
      "Epoch 33/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3537\n",
      "Epoch 34/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3491\n",
      "Epoch 35/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3397\n",
      "Epoch 36/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3337\n",
      "Epoch 37/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3265\n",
      "Epoch 38/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3206\n",
      "Epoch 39/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3139\n",
      "Epoch 40/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3083\n",
      "Epoch 41/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3021\n",
      "Epoch 42/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2988\n",
      "Epoch 43/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2939\n",
      "Epoch 44/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2892\n",
      "Epoch 45/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2856\n",
      "Epoch 46/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2808\n",
      "Epoch 47/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2778\n",
      "Epoch 48/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2749\n",
      "Epoch 49/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2724\n",
      "Epoch 50/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2682\n",
      "Epoch 51/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2646\n",
      "Epoch 52/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2628\n",
      "Epoch 53/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2595\n",
      "Epoch 54/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2570\n",
      "Epoch 55/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2541\n",
      "Epoch 56/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2523\n",
      "Epoch 57/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2497\n",
      "Epoch 58/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2474\n",
      "Epoch 59/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2454\n",
      "Epoch 60/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2439\n",
      "Epoch 61/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2416\n",
      "Epoch 62/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2396\n",
      "Epoch 63/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2378\n",
      "Epoch 64/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2367\n",
      "Epoch 65/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2345\n",
      "Epoch 66/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2330\n",
      "Epoch 67/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2313\n",
      "Epoch 68/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2294\n",
      "Epoch 69/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2284\n",
      "Epoch 70/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2262\n",
      "Epoch 71/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2250\n",
      "Epoch 72/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2237\n",
      "Epoch 73/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2223\n",
      "Epoch 74/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2208\n",
      "Epoch 75/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2194\n",
      "Epoch 76/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2184\n",
      "Epoch 77/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2173\n",
      "Epoch 78/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2159\n",
      "Epoch 79/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2148\n",
      "Epoch 80/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2138\n",
      "Epoch 81/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2127\n",
      "Epoch 82/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2116\n",
      "Epoch 83/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2104\n",
      "Epoch 84/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2097\n",
      "Epoch 85/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2087\n",
      "Epoch 86/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2070\n",
      "Epoch 87/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2062\n",
      "Epoch 88/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2050\n",
      "Epoch 89/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2044\n",
      "Epoch 90/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2039\n",
      "Epoch 91/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2028\n",
      "Epoch 92/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2020\n",
      "Epoch 93/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2012\n",
      "Epoch 94/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2000\n",
      "Epoch 95/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1992\n",
      "Epoch 96/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1980\n",
      "Epoch 97/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1978\n",
      "Epoch 98/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1969\n",
      "Epoch 99/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1957\n",
      "Epoch 100/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1954\n",
      "Epoch 101/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1944\n",
      "Epoch 102/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1940\n",
      "Epoch 103/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1933\n",
      "Epoch 104/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1922\n",
      "Epoch 105/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1915\n",
      "Epoch 106/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1909\n",
      "Epoch 107/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1901\n",
      "Epoch 108/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1904\n",
      "Epoch 109/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1891\n",
      "Epoch 110/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1889\n",
      "Epoch 111/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1883\n",
      "Epoch 112/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1871\n",
      "Epoch 113/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1868\n",
      "Epoch 114/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1864\n",
      "Epoch 115/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1858\n",
      "Epoch 116/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1850\n",
      "Epoch 117/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1846\n",
      "Epoch 118/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1844\n",
      "Epoch 119/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1834\n",
      "Epoch 120/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1834\n",
      "Epoch 121/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1832\n",
      "Epoch 122/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1820\n",
      "Epoch 123/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1817\n",
      "Epoch 124/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1814\n",
      "Epoch 125/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1811\n",
      "Epoch 126/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1805\n",
      "Epoch 127/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1803\n",
      "Epoch 128/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1796\n",
      "Epoch 129/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1790\n",
      "Epoch 130/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1785\n",
      "Epoch 131/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1783\n",
      "Epoch 132/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1778\n",
      "Epoch 133/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1776\n",
      "Epoch 134/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1775\n",
      "Epoch 135/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1769\n",
      "Epoch 136/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1766\n",
      "Epoch 137/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1761\n",
      "Epoch 138/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1759\n",
      "Epoch 139/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1756\n",
      "Epoch 140/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1753\n",
      "Epoch 141/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1751\n",
      "Epoch 142/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1750\n",
      "Epoch 143/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1743\n",
      "Epoch 144/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1743\n",
      "Epoch 145/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1737\n",
      "Epoch 146/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1730\n",
      "Epoch 147/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1728\n",
      "Epoch 148/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1728\n",
      "Epoch 149/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1730\n",
      "Epoch 150/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1723\n",
      "Epoch 151/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1719\n",
      "Epoch 152/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1717\n",
      "Epoch 153/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1712\n",
      "Epoch 154/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1710\n",
      "Epoch 155/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1711\n",
      "Epoch 156/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1716\n",
      "Epoch 157/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1703\n",
      "Epoch 158/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1698\n",
      "Epoch 159/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1697\n",
      "Epoch 160/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1696\n",
      "Epoch 161/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1692\n",
      "Epoch 162/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1692\n",
      "Epoch 163/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1688\n",
      "Epoch 164/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1685\n",
      "Epoch 165/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1683\n",
      "Epoch 166/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1689\n",
      "Epoch 167/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1680\n",
      "Epoch 168/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1676\n",
      "Epoch 169/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1682\n",
      "Epoch 170/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1675\n",
      "Epoch 171/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1669\n",
      "Epoch 172/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1666\n",
      "Epoch 173/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1666\n",
      "Epoch 174/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1667\n",
      "Epoch 175/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1661\n",
      "Epoch 176/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1658\n",
      "Epoch 177/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1655\n",
      "Epoch 178/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1657\n",
      "Epoch 179/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1665\n",
      "Epoch 180/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1672\n",
      "Epoch 181/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1682\n",
      "Epoch 182/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1673\n",
      "Epoch 183/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1648\n",
      "Epoch 184/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1643\n",
      "Epoch 185/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1642\n",
      "Epoch 186/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1640\n",
      "Epoch 187/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1638\n",
      "Epoch 188/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1637\n",
      "Epoch 189/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1635\n",
      "Epoch 190/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1632\n",
      "Epoch 191/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1633\n",
      "Epoch 192/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1633\n",
      "Epoch 193/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1629\n",
      "Epoch 194/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1634\n",
      "Epoch 195/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1628\n",
      "Epoch 196/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1626\n",
      "Epoch 197/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1626\n",
      "Epoch 198/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1627\n",
      "Epoch 199/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1623\n",
      "Epoch 200/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1618\n",
      "Epoch 201/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1619\n",
      "Epoch 202/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1616\n",
      "Epoch 203/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1617\n",
      "Epoch 204/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1615\n",
      "Epoch 205/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1614\n",
      "Epoch 206/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1611\n",
      "Epoch 207/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1612\n",
      "Epoch 208/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1610\n",
      "Epoch 209/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1612\n",
      "Epoch 210/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1608\n",
      "Epoch 211/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1605\n",
      "Epoch 212/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1603\n",
      "Epoch 213/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1605\n",
      "Epoch 214/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1606\n",
      "Epoch 215/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1603\n",
      "Epoch 216/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1602\n",
      "Epoch 217/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1603\n",
      "Epoch 218/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1597\n",
      "Epoch 219/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1595\n",
      "Epoch 220/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1592\n",
      "Epoch 221/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1597\n",
      "Epoch 222/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1596\n",
      "Epoch 223/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1589\n",
      "Epoch 224/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1591\n",
      "Epoch 225/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1592\n",
      "Epoch 226/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1591\n",
      "Epoch 227/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1587\n",
      "Epoch 228/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1584\n",
      "Epoch 229/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1583\n",
      "Epoch 230/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1581\n",
      "Epoch 231/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1583\n",
      "Epoch 232/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1586\n",
      "Epoch 233/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1586\n",
      "Epoch 234/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1583\n",
      "Epoch 235/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1584\n",
      "Epoch 236/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1577\n",
      "Epoch 237/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1575\n",
      "Epoch 238/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1575\n",
      "Epoch 239/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1583\n",
      "Epoch 240/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1580\n",
      "Epoch 241/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1573\n",
      "Epoch 242/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1571\n",
      "Epoch 243/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1569\n",
      "Epoch 244/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1568\n",
      "Epoch 245/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1567\n",
      "Epoch 246/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1566\n",
      "Epoch 247/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1567\n",
      "Epoch 248/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1572\n",
      "Epoch 249/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1832\n",
      "Epoch 250/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1741\n",
      "Epoch 251/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1589\n",
      "Epoch 252/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1577\n",
      "Epoch 253/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.1574\n",
      "Epoch 254/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1570\n",
      "Epoch 255/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1569\n",
      "Epoch 256/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1567\n",
      "Epoch 257/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1565\n",
      "Epoch 258/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1565\n",
      "Epoch 259/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1564\n",
      "Epoch 260/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1562\n",
      "Epoch 261/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1561\n",
      "Epoch 262/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1561\n",
      "Epoch 263/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1560\n",
      "Epoch 264/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1559\n",
      "Epoch 265/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1558\n",
      "Epoch 266/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1557\n",
      "Epoch 267/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1556\n",
      "Epoch 268/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1556\n",
      "Epoch 269/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1554\n",
      "Epoch 270/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1554\n",
      "Epoch 271/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1554\n",
      "Epoch 272/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1552\n",
      "Epoch 273/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1552\n",
      "Epoch 274/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1552\n",
      "Epoch 275/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1551\n",
      "Epoch 276/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1550\n",
      "Epoch 277/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1549\n",
      "Epoch 278/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1549\n",
      "Epoch 279/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1548\n",
      "Epoch 280/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1547\n",
      "Epoch 281/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1546\n",
      "Epoch 282/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1549\n",
      "Epoch 283/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1546\n",
      "Epoch 284/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1546\n",
      "Epoch 285/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1547\n",
      "Epoch 286/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1544\n",
      "Epoch 287/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1543\n",
      "Epoch 288/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1543\n",
      "Epoch 289/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1541\n",
      "Epoch 290/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1540\n",
      "Epoch 291/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1541\n",
      "Epoch 292/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1541\n",
      "Epoch 293/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1550\n",
      "Epoch 294/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1546\n",
      "Epoch 295/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1570\n",
      "Epoch 296/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1762\n",
      "Epoch 297/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1622\n",
      "Epoch 298/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1562\n",
      "Epoch 299/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1547\n",
      "Epoch 300/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1545\n",
      "102/102 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1/300\n",
      "102/102 [==============================] - 1s 4ms/step - loss: 2.3424\n",
      "Epoch 2/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.2997\n",
      "Epoch 3/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1521\n",
      "Epoch 4/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0736\n",
      "Epoch 5/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0121\n",
      "Epoch 6/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.9574\n",
      "Epoch 7/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.9073\n",
      "Epoch 8/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.8637\n",
      "Epoch 9/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.8195\n",
      "Epoch 10/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7848\n",
      "Epoch 11/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7508\n",
      "Epoch 12/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7183\n",
      "Epoch 13/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6911\n",
      "Epoch 14/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6662\n",
      "Epoch 15/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6417\n",
      "Epoch 16/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6213\n",
      "Epoch 17/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5981\n",
      "Epoch 18/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5807\n",
      "Epoch 19/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5607\n",
      "Epoch 20/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5458\n",
      "Epoch 21/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5276\n",
      "Epoch 22/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5141\n",
      "Epoch 23/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5006\n",
      "Epoch 24/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4878\n",
      "Epoch 25/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4752\n",
      "Epoch 26/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4640\n",
      "Epoch 27/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4537\n",
      "Epoch 28/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4411\n",
      "Epoch 29/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4304\n",
      "Epoch 30/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4187\n",
      "Epoch 31/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4085\n",
      "Epoch 32/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3998\n",
      "Epoch 33/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.3911\n",
      "Epoch 34/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.3855\n",
      "Epoch 35/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.3763\n",
      "Epoch 36/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.3699\n",
      "Epoch 37/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.3629\n",
      "Epoch 38/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3577\n",
      "Epoch 39/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3522\n",
      "Epoch 40/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.3468\n",
      "Epoch 41/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3414\n",
      "Epoch 42/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3372\n",
      "Epoch 43/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3321\n",
      "Epoch 44/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3278\n",
      "Epoch 45/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.3242\n",
      "Epoch 46/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3200\n",
      "Epoch 47/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3168\n",
      "Epoch 48/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3140\n",
      "Epoch 49/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3114\n",
      "Epoch 50/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3073\n",
      "Epoch 51/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3037\n",
      "Epoch 52/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3020\n",
      "Epoch 53/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2981\n",
      "Epoch 54/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2959\n",
      "Epoch 55/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2930\n",
      "Epoch 56/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2907\n",
      "Epoch 57/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2879\n",
      "Epoch 58/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2855\n",
      "Epoch 59/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2838\n",
      "Epoch 60/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2820\n",
      "Epoch 61/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2798\n",
      "Epoch 62/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2779\n",
      "Epoch 63/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2756\n",
      "Epoch 64/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2740\n",
      "Epoch 65/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2719\n",
      "Epoch 66/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2707\n",
      "Epoch 67/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2686\n",
      "Epoch 68/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2666\n",
      "Epoch 69/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2655\n",
      "Epoch 70/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2634\n",
      "Epoch 71/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2620\n",
      "Epoch 72/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2607\n",
      "Epoch 73/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2592\n",
      "Epoch 74/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2577\n",
      "Epoch 75/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2560\n",
      "Epoch 76/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2548\n",
      "Epoch 77/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2538\n",
      "Epoch 78/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2519\n",
      "Epoch 79/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2510\n",
      "Epoch 80/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.2497\n",
      "Epoch 81/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.2488\n",
      "Epoch 82/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.2476\n",
      "Epoch 83/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2462\n",
      "Epoch 84/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2451\n",
      "Epoch 85/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2442\n",
      "Epoch 86/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2429\n",
      "Epoch 87/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2417\n",
      "Epoch 88/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2406\n",
      "Epoch 89/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2402\n",
      "Epoch 90/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2391\n",
      "Epoch 91/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2379\n",
      "Epoch 92/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2374\n",
      "Epoch 93/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2364\n",
      "Epoch 94/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2357\n",
      "Epoch 95/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2345\n",
      "Epoch 96/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2333\n",
      "Epoch 97/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2327\n",
      "Epoch 98/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2317\n",
      "Epoch 99/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2311\n",
      "Epoch 100/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2302\n",
      "Epoch 101/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2295\n",
      "Epoch 102/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.2288\n",
      "Epoch 103/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2278\n",
      "Epoch 104/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2272\n",
      "Epoch 105/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.2266\n",
      "Epoch 106/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.2258\n",
      "Epoch 107/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2249\n",
      "Epoch 108/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.2247\n",
      "Epoch 109/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.2237\n",
      "Epoch 110/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2233\n",
      "Epoch 111/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2231\n",
      "Epoch 112/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2221\n",
      "Epoch 113/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2218\n",
      "Epoch 114/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2208\n",
      "Epoch 115/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2204\n",
      "Epoch 116/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2197\n",
      "Epoch 117/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2195\n",
      "Epoch 118/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2190\n",
      "Epoch 119/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.2183\n",
      "Epoch 120/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2178\n",
      "Epoch 121/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2170\n",
      "Epoch 122/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2164\n",
      "Epoch 123/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2158\n",
      "Epoch 124/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2156\n",
      "Epoch 125/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2155\n",
      "Epoch 126/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.2148\n",
      "Epoch 127/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2142\n",
      "Epoch 128/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2137\n",
      "Epoch 129/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2141\n",
      "Epoch 130/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2132\n",
      "Epoch 131/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2125\n",
      "Epoch 132/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2119\n",
      "Epoch 133/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2118\n",
      "Epoch 134/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2112\n",
      "Epoch 135/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.2112\n",
      "Epoch 136/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.2109\n",
      "Epoch 137/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.2102\n",
      "Epoch 138/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.2098\n",
      "Epoch 139/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.2094\n",
      "Epoch 140/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.2091\n",
      "Epoch 141/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.2093\n",
      "Epoch 142/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.2098\n",
      "Epoch 143/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.2080\n",
      "Epoch 144/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.2075\n",
      "Epoch 145/300\n",
      "102/102 [==============================] - 1s 9ms/step - loss: 0.2071\n",
      "Epoch 146/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.2073\n",
      "Epoch 147/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.2067\n",
      "Epoch 148/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.2063\n",
      "Epoch 149/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.2070\n",
      "Epoch 150/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.2057\n",
      "Epoch 151/300\n",
      "102/102 [==============================] - 1s 9ms/step - loss: 0.2054\n",
      "Epoch 152/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.2049\n",
      "Epoch 153/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.2048\n",
      "Epoch 154/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.2046\n",
      "Epoch 155/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.2043\n",
      "Epoch 156/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.2043\n",
      "Epoch 157/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.2037\n",
      "Epoch 158/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2033\n",
      "Epoch 159/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.2033\n",
      "Epoch 160/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.2029\n",
      "Epoch 161/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.2025\n",
      "Epoch 162/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.2021\n",
      "Epoch 163/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.2019\n",
      "Epoch 164/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.2018\n",
      "Epoch 165/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2016\n",
      "Epoch 166/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2016\n",
      "Epoch 167/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2016\n",
      "Epoch 168/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2018\n",
      "Epoch 169/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2011\n",
      "Epoch 170/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2001\n",
      "Epoch 171/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2000\n",
      "Epoch 172/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1998\n",
      "Epoch 173/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1997\n",
      "Epoch 174/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1994\n",
      "Epoch 175/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1991\n",
      "Epoch 176/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1989\n",
      "Epoch 177/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1988\n",
      "Epoch 178/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1984\n",
      "Epoch 179/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1982\n",
      "Epoch 180/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1984\n",
      "Epoch 181/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1979\n",
      "Epoch 182/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1977\n",
      "Epoch 183/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1977\n",
      "Epoch 184/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1975\n",
      "Epoch 185/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1971\n",
      "Epoch 186/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1968\n",
      "Epoch 187/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1973\n",
      "Epoch 188/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1964\n",
      "Epoch 189/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1964\n",
      "Epoch 190/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1964\n",
      "Epoch 191/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1959\n",
      "Epoch 192/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1957\n",
      "Epoch 193/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1957\n",
      "Epoch 194/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1954\n",
      "Epoch 195/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1952\n",
      "Epoch 196/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1957\n",
      "Epoch 197/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1953\n",
      "Epoch 198/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1955\n",
      "Epoch 199/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1943\n",
      "Epoch 200/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1941\n",
      "Epoch 201/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1950\n",
      "Epoch 202/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1943\n",
      "Epoch 203/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1938\n",
      "Epoch 204/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1939\n",
      "Epoch 205/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1936\n",
      "Epoch 206/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1933\n",
      "Epoch 207/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1932\n",
      "Epoch 208/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1932\n",
      "Epoch 209/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1933\n",
      "Epoch 210/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1931\n",
      "Epoch 211/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1961\n",
      "Epoch 212/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2056\n",
      "Epoch 213/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1939\n",
      "Epoch 214/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1926\n",
      "Epoch 215/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1924\n",
      "Epoch 216/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1922\n",
      "Epoch 217/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1920\n",
      "Epoch 218/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1917\n",
      "Epoch 219/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1916\n",
      "Epoch 220/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1915\n",
      "Epoch 221/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1914\n",
      "Epoch 222/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1912\n",
      "Epoch 223/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1911\n",
      "Epoch 224/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1909\n",
      "Epoch 225/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1908\n",
      "Epoch 226/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1909\n",
      "Epoch 227/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1907\n",
      "Epoch 228/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1905\n",
      "Epoch 229/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1902\n",
      "Epoch 230/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1902\n",
      "Epoch 231/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1901\n",
      "Epoch 232/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1899\n",
      "Epoch 233/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1900\n",
      "Epoch 234/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1901\n",
      "Epoch 235/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1898\n",
      "Epoch 236/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1901\n",
      "Epoch 237/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1903\n",
      "Epoch 238/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1898\n",
      "Epoch 239/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1894\n",
      "Epoch 240/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1896\n",
      "Epoch 241/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1913\n",
      "Epoch 242/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2075\n",
      "Epoch 243/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1993\n",
      "Epoch 244/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1905\n",
      "Epoch 245/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1894\n",
      "Epoch 246/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1891\n",
      "Epoch 247/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1889\n",
      "Epoch 248/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1888\n",
      "Epoch 249/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1886\n",
      "Epoch 250/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1885\n",
      "Epoch 251/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1884\n",
      "Epoch 252/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1883\n",
      "Epoch 253/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1882\n",
      "Epoch 254/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1881\n",
      "Epoch 255/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1880\n",
      "Epoch 256/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1879\n",
      "Epoch 257/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1878\n",
      "Epoch 258/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1877\n",
      "Epoch 259/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1876\n",
      "Epoch 260/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1875\n",
      "Epoch 261/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1874\n",
      "Epoch 262/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1874\n",
      "Epoch 263/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1872\n",
      "Epoch 264/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1872\n",
      "Epoch 265/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1872\n",
      "Epoch 266/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1872\n",
      "Epoch 267/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1872\n",
      "Epoch 268/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1869\n",
      "Epoch 269/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1868\n",
      "Epoch 270/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1867\n",
      "Epoch 271/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1866\n",
      "Epoch 272/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1867\n",
      "Epoch 273/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1867\n",
      "Epoch 274/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1866\n",
      "Epoch 275/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1865\n",
      "Epoch 276/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1866\n",
      "Epoch 277/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1862\n",
      "Epoch 278/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1861\n",
      "Epoch 279/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1860\n",
      "Epoch 280/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1867\n",
      "Epoch 281/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1865\n",
      "Epoch 282/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2028\n",
      "Epoch 283/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2034\n",
      "Epoch 284/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1888\n",
      "Epoch 285/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1868\n",
      "Epoch 286/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1865\n",
      "Epoch 287/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1862\n",
      "Epoch 288/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1861\n",
      "Epoch 289/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1859\n",
      "Epoch 290/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1859\n",
      "Epoch 291/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1857\n",
      "Epoch 292/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1856\n",
      "Epoch 293/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1855\n",
      "Epoch 294/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1854\n",
      "Epoch 295/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1854\n",
      "Epoch 296/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1853\n",
      "Epoch 297/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1852\n",
      "Epoch 298/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1851\n",
      "Epoch 299/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1851\n",
      "Epoch 300/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1850\n",
      "102/102 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1/300\n",
      "102/102 [==============================] - 1s 3ms/step - loss: 2.6714\n",
      "Epoch 2/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.3578\n",
      "Epoch 3/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.2035\n",
      "Epoch 4/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1335\n",
      "Epoch 5/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0748\n",
      "Epoch 6/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0219\n",
      "Epoch 7/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.9730\n",
      "Epoch 8/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.9292\n",
      "Epoch 9/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.8845\n",
      "Epoch 10/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.8479\n",
      "Epoch 11/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.8128\n",
      "Epoch 12/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.7785\n",
      "Epoch 13/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.7496\n",
      "Epoch 14/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7230\n",
      "Epoch 15/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6955\n",
      "Epoch 16/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6724\n",
      "Epoch 17/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6485\n",
      "Epoch 18/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6295\n",
      "Epoch 19/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6096\n",
      "Epoch 20/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5934\n",
      "Epoch 21/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5758\n",
      "Epoch 22/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5618\n",
      "Epoch 23/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5478\n",
      "Epoch 24/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5342\n",
      "Epoch 25/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5210\n",
      "Epoch 26/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5088\n",
      "Epoch 27/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4948\n",
      "Epoch 28/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4806\n",
      "Epoch 29/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4708\n",
      "Epoch 30/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4604\n",
      "Epoch 31/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4514\n",
      "Epoch 32/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4433\n",
      "Epoch 33/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4347\n",
      "Epoch 34/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4290\n",
      "Epoch 35/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4200\n",
      "Epoch 36/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4139\n",
      "Epoch 37/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4068\n",
      "Epoch 38/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4019\n",
      "Epoch 39/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3966\n",
      "Epoch 40/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3911\n",
      "Epoch 41/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3863\n",
      "Epoch 42/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3819\n",
      "Epoch 43/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3764\n",
      "Epoch 44/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3726\n",
      "Epoch 45/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3685\n",
      "Epoch 46/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3640\n",
      "Epoch 47/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3608\n",
      "Epoch 48/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3584\n",
      "Epoch 49/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3550\n",
      "Epoch 50/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3513\n",
      "Epoch 51/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3475\n",
      "Epoch 52/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3453\n",
      "Epoch 53/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3422\n",
      "Epoch 54/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3393\n",
      "Epoch 55/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3369\n",
      "Epoch 56/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3339\n",
      "Epoch 57/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3314\n",
      "Epoch 58/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3290\n",
      "Epoch 59/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3267\n",
      "Epoch 60/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3248\n",
      "Epoch 61/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3231\n",
      "Epoch 62/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3211\n",
      "Epoch 63/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3185\n",
      "Epoch 64/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3169\n",
      "Epoch 65/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3147\n",
      "Epoch 66/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3137\n",
      "Epoch 67/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3111\n",
      "Epoch 68/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3090\n",
      "Epoch 69/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3079\n",
      "Epoch 70/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3060\n",
      "Epoch 71/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3045\n",
      "Epoch 72/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3036\n",
      "Epoch 73/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3016\n",
      "Epoch 74/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2998\n",
      "Epoch 75/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2981\n",
      "Epoch 76/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2968\n",
      "Epoch 77/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2962\n",
      "Epoch 78/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2942\n",
      "Epoch 79/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2929\n",
      "Epoch 80/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2915\n",
      "Epoch 81/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2908\n",
      "Epoch 82/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2898\n",
      "Epoch 83/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2882\n",
      "Epoch 84/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2874\n",
      "Epoch 85/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2854\n",
      "Epoch 86/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2845\n",
      "Epoch 87/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2832\n",
      "Epoch 88/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2820\n",
      "Epoch 89/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2815\n",
      "Epoch 90/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2801\n",
      "Epoch 91/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2795\n",
      "Epoch 92/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2786\n",
      "Epoch 93/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2776\n",
      "Epoch 94/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2762\n",
      "Epoch 95/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2753\n",
      "Epoch 96/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2740\n",
      "Epoch 97/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2736\n",
      "Epoch 98/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2729\n",
      "Epoch 99/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2719\n",
      "Epoch 100/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2717\n",
      "Epoch 101/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2701\n",
      "Epoch 102/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2691\n",
      "Epoch 103/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2684\n",
      "Epoch 104/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2679\n",
      "Epoch 105/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2672\n",
      "Epoch 106/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2660\n",
      "Epoch 107/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2653\n",
      "Epoch 108/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2655\n",
      "Epoch 109/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2641\n",
      "Epoch 110/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2634\n",
      "Epoch 111/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2632\n",
      "Epoch 112/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2624\n",
      "Epoch 113/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2616\n",
      "Epoch 114/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2609\n",
      "Epoch 115/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2605\n",
      "Epoch 116/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2596\n",
      "Epoch 117/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2592\n",
      "Epoch 118/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2588\n",
      "Epoch 119/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2584\n",
      "Epoch 120/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2577\n",
      "Epoch 121/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2568\n",
      "Epoch 122/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2565\n",
      "Epoch 123/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2557\n",
      "Epoch 124/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2550\n",
      "Epoch 125/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2549\n",
      "Epoch 126/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2549\n",
      "Epoch 127/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2537\n",
      "Epoch 128/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2537\n",
      "Epoch 129/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2528\n",
      "Epoch 130/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2521\n",
      "Epoch 131/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2515\n",
      "Epoch 132/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2515\n",
      "Epoch 133/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2512\n",
      "Epoch 134/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2514\n",
      "Epoch 135/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2505\n",
      "Epoch 136/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2499\n",
      "Epoch 137/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2490\n",
      "Epoch 138/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2490\n",
      "Epoch 139/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2495\n",
      "Epoch 140/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2490\n",
      "Epoch 141/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2478\n",
      "Epoch 142/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2472\n",
      "Epoch 143/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2466\n",
      "Epoch 144/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2469\n",
      "Epoch 145/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2465\n",
      "Epoch 146/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2458\n",
      "Epoch 147/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2451\n",
      "Epoch 148/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2449\n",
      "Epoch 149/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2449\n",
      "Epoch 150/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2442\n",
      "Epoch 151/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2449\n",
      "Epoch 152/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2464\n",
      "Epoch 153/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2464\n",
      "Epoch 154/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2436\n",
      "Epoch 155/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2430\n",
      "Epoch 156/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2424\n",
      "Epoch 157/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2419\n",
      "Epoch 158/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2418\n",
      "Epoch 159/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2416\n",
      "Epoch 160/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2413\n",
      "Epoch 161/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2410\n",
      "Epoch 162/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2406\n",
      "Epoch 163/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2403\n",
      "Epoch 164/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2403\n",
      "Epoch 165/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2397\n",
      "Epoch 166/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2399\n",
      "Epoch 167/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2398\n",
      "Epoch 168/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2389\n",
      "Epoch 169/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2387\n",
      "Epoch 170/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2390\n",
      "Epoch 171/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2384\n",
      "Epoch 172/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2383\n",
      "Epoch 173/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2384\n",
      "Epoch 174/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2376\n",
      "Epoch 175/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2378\n",
      "Epoch 176/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2370\n",
      "Epoch 177/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2366\n",
      "Epoch 178/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2366\n",
      "Epoch 179/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2363\n",
      "Epoch 180/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2369\n",
      "Epoch 181/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2367\n",
      "Epoch 182/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2355\n",
      "Epoch 183/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2352\n",
      "Epoch 184/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2351\n",
      "Epoch 185/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2365\n",
      "Epoch 186/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2354\n",
      "Epoch 187/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2348\n",
      "Epoch 188/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2342\n",
      "Epoch 189/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2340\n",
      "Epoch 190/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2338\n",
      "Epoch 191/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2338\n",
      "Epoch 192/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2338\n",
      "Epoch 193/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2333\n",
      "Epoch 194/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2337\n",
      "Epoch 195/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2332\n",
      "Epoch 196/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2332\n",
      "Epoch 197/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2333\n",
      "Epoch 198/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2331\n",
      "Epoch 199/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2322\n",
      "Epoch 200/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2318\n",
      "Epoch 201/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2317\n",
      "Epoch 202/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2317\n",
      "Epoch 203/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2319\n",
      "Epoch 204/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2326\n",
      "Epoch 205/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2326\n",
      "Epoch 206/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2312\n",
      "Epoch 207/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2307\n",
      "Epoch 208/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2305\n",
      "Epoch 209/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2304\n",
      "Epoch 210/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2303\n",
      "Epoch 211/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2301\n",
      "Epoch 212/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2301\n",
      "Epoch 213/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2298\n",
      "Epoch 214/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2296\n",
      "Epoch 215/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2299\n",
      "Epoch 216/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2312\n",
      "Epoch 217/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2308\n",
      "Epoch 218/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2293\n",
      "Epoch 219/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2292\n",
      "Epoch 220/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2288\n",
      "Epoch 221/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2293\n",
      "Epoch 222/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2287\n",
      "Epoch 223/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2285\n",
      "Epoch 224/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2291\n",
      "Epoch 225/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2287\n",
      "Epoch 226/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2323\n",
      "Epoch 227/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2371\n",
      "Epoch 228/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2300\n",
      "Epoch 229/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2281\n",
      "Epoch 230/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2277\n",
      "Epoch 231/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2276\n",
      "Epoch 232/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2275\n",
      "Epoch 233/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2272\n",
      "Epoch 234/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2270\n",
      "Epoch 235/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2269\n",
      "Epoch 236/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2267\n",
      "Epoch 237/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2267\n",
      "Epoch 238/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2265\n",
      "Epoch 239/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2264\n",
      "Epoch 240/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2262\n",
      "Epoch 241/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2262\n",
      "Epoch 242/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2262\n",
      "Epoch 243/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2262\n",
      "Epoch 244/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2259\n",
      "Epoch 245/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2260\n",
      "Epoch 246/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2258\n",
      "Epoch 247/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2256\n",
      "Epoch 248/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2260\n",
      "Epoch 249/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2257\n",
      "Epoch 250/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2252\n",
      "Epoch 251/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2253\n",
      "Epoch 252/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2252\n",
      "Epoch 253/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2251\n",
      "Epoch 254/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2257\n",
      "Epoch 255/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2267\n",
      "Epoch 256/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2253\n",
      "Epoch 257/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2246\n",
      "Epoch 258/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2244\n",
      "Epoch 259/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2246\n",
      "Epoch 260/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2243\n",
      "Epoch 261/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2241\n",
      "Epoch 262/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2242\n",
      "Epoch 263/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2266\n",
      "Epoch 264/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2273\n",
      "Epoch 265/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2296\n",
      "Epoch 266/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2370\n",
      "Epoch 267/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2323\n",
      "Epoch 268/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2258\n",
      "Epoch 269/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2241\n",
      "Epoch 270/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2237\n",
      "Epoch 271/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2235\n",
      "Epoch 272/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2234\n",
      "Epoch 273/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2233\n",
      "Epoch 274/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2232\n",
      "Epoch 275/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2230\n",
      "Epoch 276/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2230\n",
      "Epoch 277/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2229\n",
      "Epoch 278/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2228\n",
      "Epoch 279/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2227\n",
      "Epoch 280/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2226\n",
      "Epoch 281/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2225\n",
      "Epoch 282/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2225\n",
      "Epoch 283/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2224\n",
      "Epoch 284/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2223\n",
      "Epoch 285/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2223\n",
      "Epoch 286/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2222\n",
      "Epoch 287/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2221\n",
      "Epoch 288/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2221\n",
      "Epoch 289/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2220\n",
      "Epoch 290/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2219\n",
      "Epoch 291/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2219\n",
      "Epoch 292/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2221\n",
      "Epoch 293/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2219\n",
      "Epoch 294/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2219\n",
      "Epoch 295/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2221\n",
      "Epoch 296/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2216\n",
      "Epoch 297/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2222\n",
      "Epoch 298/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2350\n",
      "Epoch 299/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2380\n",
      "Epoch 300/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2236\n",
      "102/102 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1/300\n",
      "102/102 [==============================] - 1s 3ms/step - loss: 3.1072\n",
      "Epoch 2/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.4289\n",
      "Epoch 3/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.2547\n",
      "Epoch 4/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1944\n",
      "Epoch 5/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1427\n",
      "Epoch 6/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0914\n",
      "Epoch 7/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0421\n",
      "Epoch 8/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.9978\n",
      "Epoch 9/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.9525\n",
      "Epoch 10/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.9146\n",
      "Epoch 11/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.8781\n",
      "Epoch 12/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.8431\n",
      "Epoch 13/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.8131\n",
      "Epoch 14/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.7865\n",
      "Epoch 15/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.7608\n",
      "Epoch 16/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.7371\n",
      "Epoch 17/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.7135\n",
      "Epoch 18/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6938\n",
      "Epoch 19/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6734\n",
      "Epoch 20/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6565\n",
      "Epoch 21/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6387\n",
      "Epoch 22/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6234\n",
      "Epoch 23/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6083\n",
      "Epoch 24/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5919\n",
      "Epoch 25/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5756\n",
      "Epoch 26/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5630\n",
      "Epoch 27/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5505\n",
      "Epoch 28/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5370\n",
      "Epoch 29/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5275\n",
      "Epoch 30/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5174\n",
      "Epoch 31/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5080\n",
      "Epoch 32/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4996\n",
      "Epoch 33/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4914\n",
      "Epoch 34/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4852\n",
      "Epoch 35/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4764\n",
      "Epoch 36/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4703\n",
      "Epoch 37/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4628\n",
      "Epoch 38/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4576\n",
      "Epoch 39/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4523\n",
      "Epoch 40/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4465\n",
      "Epoch 41/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4412\n",
      "Epoch 42/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4367\n",
      "Epoch 43/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4316\n",
      "Epoch 44/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4270\n",
      "Epoch 45/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4226\n",
      "Epoch 46/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4181\n",
      "Epoch 47/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4148\n",
      "Epoch 48/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4125\n",
      "Epoch 49/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4083\n",
      "Epoch 50/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4047\n",
      "Epoch 51/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4008\n",
      "Epoch 52/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3985\n",
      "Epoch 53/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.3947\n",
      "Epoch 54/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3918\n",
      "Epoch 55/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3893\n",
      "Epoch 56/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3864\n",
      "Epoch 57/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3836\n",
      "Epoch 58/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3810\n",
      "Epoch 59/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3783\n",
      "Epoch 60/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3763\n",
      "Epoch 61/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3744\n",
      "Epoch 62/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3718\n",
      "Epoch 63/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3699\n",
      "Epoch 64/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3682\n",
      "Epoch 65/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3654\n",
      "Epoch 66/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3640\n",
      "Epoch 67/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3614\n",
      "Epoch 68/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3595\n",
      "Epoch 69/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3576\n",
      "Epoch 70/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3559\n",
      "Epoch 71/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3543\n",
      "Epoch 72/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3528\n",
      "Epoch 73/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3512\n",
      "Epoch 74/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3497\n",
      "Epoch 75/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3477\n",
      "Epoch 76/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3462\n",
      "Epoch 77/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3448\n",
      "Epoch 78/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3432\n",
      "Epoch 79/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3422\n",
      "Epoch 80/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3406\n",
      "Epoch 81/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3396\n",
      "Epoch 82/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3381\n",
      "Epoch 83/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3368\n",
      "Epoch 84/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3362\n",
      "Epoch 85/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3341\n",
      "Epoch 86/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3329\n",
      "Epoch 87/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3318\n",
      "Epoch 88/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3303\n",
      "Epoch 89/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3300\n",
      "Epoch 90/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3287\n",
      "Epoch 91/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3274\n",
      "Epoch 92/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3262\n",
      "Epoch 93/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3255\n",
      "Epoch 94/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3243\n",
      "Epoch 95/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3234\n",
      "Epoch 96/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3219\n",
      "Epoch 97/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3215\n",
      "Epoch 98/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3206\n",
      "Epoch 99/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3196\n",
      "Epoch 100/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3187\n",
      "Epoch 101/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3176\n",
      "Epoch 102/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3172\n",
      "Epoch 103/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3166\n",
      "Epoch 104/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3155\n",
      "Epoch 105/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3146\n",
      "Epoch 106/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3136\n",
      "Epoch 107/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3128\n",
      "Epoch 108/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3126\n",
      "Epoch 109/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3113\n",
      "Epoch 110/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3107\n",
      "Epoch 111/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3109\n",
      "Epoch 112/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3098\n",
      "Epoch 113/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3087\n",
      "Epoch 114/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3077\n",
      "Epoch 115/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3073\n",
      "Epoch 116/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3066\n",
      "Epoch 117/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3064\n",
      "Epoch 118/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3055\n",
      "Epoch 119/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3052\n",
      "Epoch 120/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3052\n",
      "Epoch 121/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3038\n",
      "Epoch 122/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.3029\n",
      "Epoch 123/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3024\n",
      "Epoch 124/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3016\n",
      "Epoch 125/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3016\n",
      "Epoch 126/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3012\n",
      "Epoch 127/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3005\n",
      "Epoch 128/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3002\n",
      "Epoch 129/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2992\n",
      "Epoch 130/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2988\n",
      "Epoch 131/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2989\n",
      "Epoch 132/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2985\n",
      "Epoch 133/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2978\n",
      "Epoch 134/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2968\n",
      "Epoch 135/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2965\n",
      "Epoch 136/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2963\n",
      "Epoch 137/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2952\n",
      "Epoch 138/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2948\n",
      "Epoch 139/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2946\n",
      "Epoch 140/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2943\n",
      "Epoch 141/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2941\n",
      "Epoch 142/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2936\n",
      "Epoch 143/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2927\n",
      "Epoch 144/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2927\n",
      "Epoch 145/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2920\n",
      "Epoch 146/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2927\n",
      "Epoch 147/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2912\n",
      "Epoch 148/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2909\n",
      "Epoch 149/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2904\n",
      "Epoch 150/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2898\n",
      "Epoch 151/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2905\n",
      "Epoch 152/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2901\n",
      "Epoch 153/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2896\n",
      "Epoch 154/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2887\n",
      "Epoch 155/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2883\n",
      "Epoch 156/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2883\n",
      "Epoch 157/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2878\n",
      "Epoch 158/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2874\n",
      "Epoch 159/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2867\n",
      "Epoch 160/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2865\n",
      "Epoch 161/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2865\n",
      "Epoch 162/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2863\n",
      "Epoch 163/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2858\n",
      "Epoch 164/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2857\n",
      "Epoch 165/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2854\n",
      "Epoch 166/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2849\n",
      "Epoch 167/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2842\n",
      "Epoch 168/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2846\n",
      "Epoch 169/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2840\n",
      "Epoch 170/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2837\n",
      "Epoch 171/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2837\n",
      "Epoch 172/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2828\n",
      "Epoch 173/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2829\n",
      "Epoch 174/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2825\n",
      "Epoch 175/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2826\n",
      "Epoch 176/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2822\n",
      "Epoch 177/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2816\n",
      "Epoch 178/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2816\n",
      "Epoch 179/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2820\n",
      "Epoch 180/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2815\n",
      "Epoch 181/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2806\n",
      "Epoch 182/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2803\n",
      "Epoch 183/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2802\n",
      "Epoch 184/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2802\n",
      "Epoch 185/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2805\n",
      "Epoch 186/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2805\n",
      "Epoch 187/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2791\n",
      "Epoch 188/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2788\n",
      "Epoch 189/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2785\n",
      "Epoch 190/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.2782\n",
      "Epoch 191/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.2782\n",
      "Epoch 192/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2780\n",
      "Epoch 193/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.2786\n",
      "Epoch 194/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.2783\n",
      "Epoch 195/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.2773\n",
      "Epoch 196/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2772\n",
      "Epoch 197/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.2772\n",
      "Epoch 198/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.2770\n",
      "Epoch 199/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.2805\n",
      "Epoch 200/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.2783\n",
      "Epoch 201/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.2767\n",
      "Epoch 202/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.2759\n",
      "Epoch 203/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2757\n",
      "Epoch 204/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.2755\n",
      "Epoch 205/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.2751\n",
      "Epoch 206/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.2750\n",
      "Epoch 207/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.2749\n",
      "Epoch 208/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.2746\n",
      "Epoch 209/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.2744\n",
      "Epoch 210/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2761\n",
      "Epoch 211/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.2769\n",
      "Epoch 212/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.2924\n",
      "Epoch 213/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2827\n",
      "Epoch 214/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2757\n",
      "Epoch 215/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2748\n",
      "Epoch 216/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2744\n",
      "Epoch 217/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2741\n",
      "Epoch 218/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2737\n",
      "Epoch 219/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2735\n",
      "Epoch 220/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2733\n",
      "Epoch 221/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2731\n",
      "Epoch 222/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2729\n",
      "Epoch 223/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2727\n",
      "Epoch 224/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2727\n",
      "Epoch 225/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2723\n",
      "Epoch 226/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2723\n",
      "Epoch 227/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2721\n",
      "Epoch 228/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2719\n",
      "Epoch 229/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2717\n",
      "Epoch 230/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2715\n",
      "Epoch 231/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2716\n",
      "Epoch 232/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2714\n",
      "Epoch 233/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2717\n",
      "Epoch 234/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2711\n",
      "Epoch 235/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2713\n",
      "Epoch 236/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2707\n",
      "Epoch 237/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2705\n",
      "Epoch 238/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2705\n",
      "Epoch 239/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2706\n",
      "Epoch 240/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2704\n",
      "Epoch 241/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2704\n",
      "Epoch 242/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2706\n",
      "Epoch 243/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2699\n",
      "Epoch 244/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2699\n",
      "Epoch 245/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2704\n",
      "Epoch 246/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2694\n",
      "Epoch 247/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2692\n",
      "Epoch 248/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2701\n",
      "Epoch 249/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2695\n",
      "Epoch 250/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2712\n",
      "Epoch 251/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2944\n",
      "Epoch 252/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2756\n",
      "Epoch 253/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2717\n",
      "Epoch 254/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2703\n",
      "Epoch 255/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2696\n",
      "Epoch 256/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2696\n",
      "Epoch 257/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2691\n",
      "Epoch 258/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2688\n",
      "Epoch 259/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2687\n",
      "Epoch 260/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2684\n",
      "Epoch 261/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2683\n",
      "Epoch 262/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2681\n",
      "Epoch 263/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2680\n",
      "Epoch 264/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2679\n",
      "Epoch 265/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2677\n",
      "Epoch 266/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2677\n",
      "Epoch 267/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2678\n",
      "Epoch 268/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2674\n",
      "Epoch 269/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2673\n",
      "Epoch 270/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2672\n",
      "Epoch 271/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2670\n",
      "Epoch 272/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2670\n",
      "Epoch 273/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2669\n",
      "Epoch 274/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2669\n",
      "Epoch 275/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2666\n",
      "Epoch 276/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2665\n",
      "Epoch 277/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2668\n",
      "Epoch 278/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2669\n",
      "Epoch 279/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2664\n",
      "Epoch 280/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2662\n",
      "Epoch 281/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2661\n",
      "Epoch 282/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2659\n",
      "Epoch 283/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2667\n",
      "Epoch 284/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2674\n",
      "Epoch 285/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2666\n",
      "Epoch 286/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2658\n",
      "Epoch 287/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2658\n",
      "Epoch 288/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2671\n",
      "Epoch 289/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2663\n",
      "Epoch 290/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2652\n",
      "Epoch 291/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2651\n",
      "Epoch 292/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2651\n",
      "Epoch 293/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2650\n",
      "Epoch 294/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2650\n",
      "Epoch 295/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2654\n",
      "Epoch 296/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2687\n",
      "Epoch 297/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2844\n",
      "Epoch 298/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2790\n",
      "Epoch 299/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2671\n",
      "Epoch 300/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2662\n",
      "102/102 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1/300\n",
      "102/102 [==============================] - 1s 3ms/step - loss: 3.6840\n",
      "Epoch 2/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.5078\n",
      "Epoch 3/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.3025\n",
      "Epoch 4/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.2433\n",
      "Epoch 5/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.1970\n",
      "Epoch 6/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.1486\n",
      "Epoch 7/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1002\n",
      "Epoch 8/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0561\n",
      "Epoch 9/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0120\n",
      "Epoch 10/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.9760\n",
      "Epoch 11/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.9403\n",
      "Epoch 12/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.9063\n",
      "Epoch 13/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.8766\n",
      "Epoch 14/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.8492\n",
      "Epoch 15/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.8220\n",
      "Epoch 16/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.7985\n",
      "Epoch 17/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.7752\n",
      "Epoch 18/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.7555\n",
      "Epoch 19/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.7358\n",
      "Epoch 20/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.7190\n",
      "Epoch 21/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.7015\n",
      "Epoch 22/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6857\n",
      "Epoch 23/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6717\n",
      "Epoch 24/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6573\n",
      "Epoch 25/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6434\n",
      "Epoch 26/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6293\n",
      "Epoch 27/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6154\n",
      "Epoch 28/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6012\n",
      "Epoch 29/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5913\n",
      "Epoch 30/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5805\n",
      "Epoch 31/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5710\n",
      "Epoch 32/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5618\n",
      "Epoch 33/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5530\n",
      "Epoch 34/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5466\n",
      "Epoch 35/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5378\n",
      "Epoch 36/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5312\n",
      "Epoch 37/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5237\n",
      "Epoch 38/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5177\n",
      "Epoch 39/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5127\n",
      "Epoch 40/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5063\n",
      "Epoch 41/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5010\n",
      "Epoch 42/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4966\n",
      "Epoch 43/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4909\n",
      "Epoch 44/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4864\n",
      "Epoch 45/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4823\n",
      "Epoch 46/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4774\n",
      "Epoch 47/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4743\n",
      "Epoch 48/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4708\n",
      "Epoch 49/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4668\n",
      "Epoch 50/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4631\n",
      "Epoch 51/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4599\n",
      "Epoch 52/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4569\n",
      "Epoch 53/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4534\n",
      "Epoch 54/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4503\n",
      "Epoch 55/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4477\n",
      "Epoch 56/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4445\n",
      "Epoch 57/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4417\n",
      "Epoch 58/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4390\n",
      "Epoch 59/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4363\n",
      "Epoch 60/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4343\n",
      "Epoch 61/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4321\n",
      "Epoch 62/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4298\n",
      "Epoch 63/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4276\n",
      "Epoch 64/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4254\n",
      "Epoch 65/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4228\n",
      "Epoch 66/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4215\n",
      "Epoch 67/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4188\n",
      "Epoch 68/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4165\n",
      "Epoch 69/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4149\n",
      "Epoch 70/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4135\n",
      "Epoch 71/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4110\n",
      "Epoch 72/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4097\n",
      "Epoch 73/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4076\n",
      "Epoch 74/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4061\n",
      "Epoch 75/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4040\n",
      "Epoch 76/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4027\n",
      "Epoch 77/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4011\n",
      "Epoch 78/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3995\n",
      "Epoch 79/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3981\n",
      "Epoch 80/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3967\n",
      "Epoch 81/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3955\n",
      "Epoch 82/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3950\n",
      "Epoch 83/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3928\n",
      "Epoch 84/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3915\n",
      "Epoch 85/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3902\n",
      "Epoch 86/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3884\n",
      "Epoch 87/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3875\n",
      "Epoch 88/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3857\n",
      "Epoch 89/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3849\n",
      "Epoch 90/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3839\n",
      "Epoch 91/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3823\n",
      "Epoch 92/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3812\n",
      "Epoch 93/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3806\n",
      "Epoch 94/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3791\n",
      "Epoch 95/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3781\n",
      "Epoch 96/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3768\n",
      "Epoch 97/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3761\n",
      "Epoch 98/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3750\n",
      "Epoch 99/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3739\n",
      "Epoch 100/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3738\n",
      "Epoch 101/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3724\n",
      "Epoch 102/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3715\n",
      "Epoch 103/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3702\n",
      "Epoch 104/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3694\n",
      "Epoch 105/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3687\n",
      "Epoch 106/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3678\n",
      "Epoch 107/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3669\n",
      "Epoch 108/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3664\n",
      "Epoch 109/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3653\n",
      "Epoch 110/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3646\n",
      "Epoch 111/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3651\n",
      "Epoch 112/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3635\n",
      "Epoch 113/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3621\n",
      "Epoch 114/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3619\n",
      "Epoch 115/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3613\n",
      "Epoch 116/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3603\n",
      "Epoch 117/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3594\n",
      "Epoch 118/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3586\n",
      "Epoch 119/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3580\n",
      "Epoch 120/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3579\n",
      "Epoch 121/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3574\n",
      "Epoch 122/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3575\n",
      "Epoch 123/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3568\n",
      "Epoch 124/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3547\n",
      "Epoch 125/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3544\n",
      "Epoch 126/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3538\n",
      "Epoch 127/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3535\n",
      "Epoch 128/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3525\n",
      "Epoch 129/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3517\n",
      "Epoch 130/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3514\n",
      "Epoch 131/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3509\n",
      "Epoch 132/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3508\n",
      "Epoch 133/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3503\n",
      "Epoch 134/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3497\n",
      "Epoch 135/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3487\n",
      "Epoch 136/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3482\n",
      "Epoch 137/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3476\n",
      "Epoch 138/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3476\n",
      "Epoch 139/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3474\n",
      "Epoch 140/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3465\n",
      "Epoch 141/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3458\n",
      "Epoch 142/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3459\n",
      "Epoch 143/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3446\n",
      "Epoch 144/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3455\n",
      "Epoch 145/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3446\n",
      "Epoch 146/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3436\n",
      "Epoch 147/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3433\n",
      "Epoch 148/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3429\n",
      "Epoch 149/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3421\n",
      "Epoch 150/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3415\n",
      "Epoch 151/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3419\n",
      "Epoch 152/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3412\n",
      "Epoch 153/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3410\n",
      "Epoch 154/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3403\n",
      "Epoch 155/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3406\n",
      "Epoch 156/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3398\n",
      "Epoch 157/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3392\n",
      "Epoch 158/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3389\n",
      "Epoch 159/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3390\n",
      "Epoch 160/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3383\n",
      "Epoch 161/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3380\n",
      "Epoch 162/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3379\n",
      "Epoch 163/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3377\n",
      "Epoch 164/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3370\n",
      "Epoch 165/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3363\n",
      "Epoch 166/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3367\n",
      "Epoch 167/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3360\n",
      "Epoch 168/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3358\n",
      "Epoch 169/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3350\n",
      "Epoch 170/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3353\n",
      "Epoch 171/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3343\n",
      "Epoch 172/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3339\n",
      "Epoch 173/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3336\n",
      "Epoch 174/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3336\n",
      "Epoch 175/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3330\n",
      "Epoch 176/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3328\n",
      "Epoch 177/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3324\n",
      "Epoch 178/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3323\n",
      "Epoch 179/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3325\n",
      "Epoch 180/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3321\n",
      "Epoch 181/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3322\n",
      "Epoch 182/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3324\n",
      "Epoch 183/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3312\n",
      "Epoch 184/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3307\n",
      "Epoch 185/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3303\n",
      "Epoch 186/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3308\n",
      "Epoch 187/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3301\n",
      "Epoch 188/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3303\n",
      "Epoch 189/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3295\n",
      "Epoch 190/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3293\n",
      "Epoch 191/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3288\n",
      "Epoch 192/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3285\n",
      "Epoch 193/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3281\n",
      "Epoch 194/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3282\n",
      "Epoch 195/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3290\n",
      "Epoch 196/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3297\n",
      "Epoch 197/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3315\n",
      "Epoch 198/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3300\n",
      "Epoch 199/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3280\n",
      "Epoch 200/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3269\n",
      "Epoch 201/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3266\n",
      "Epoch 202/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3262\n",
      "Epoch 203/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3275\n",
      "Epoch 204/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3272\n",
      "Epoch 205/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3259\n",
      "Epoch 206/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3255\n",
      "Epoch 207/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3254\n",
      "Epoch 208/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3248\n",
      "Epoch 209/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3248\n",
      "Epoch 210/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3255\n",
      "Epoch 211/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3269\n",
      "Epoch 212/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3296\n",
      "Epoch 213/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3284\n",
      "Epoch 214/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3256\n",
      "Epoch 215/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3248\n",
      "Epoch 216/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3236\n",
      "Epoch 217/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3234\n",
      "Epoch 218/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3232\n",
      "Epoch 219/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3230\n",
      "Epoch 220/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3229\n",
      "Epoch 221/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3227\n",
      "Epoch 222/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3224\n",
      "Epoch 223/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3224\n",
      "Epoch 224/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3223\n",
      "Epoch 225/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3221\n",
      "Epoch 226/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3218\n",
      "Epoch 227/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3219\n",
      "Epoch 228/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3216\n",
      "Epoch 229/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3214\n",
      "Epoch 230/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3217\n",
      "Epoch 231/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3220\n",
      "Epoch 232/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3248\n",
      "Epoch 233/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3266\n",
      "Epoch 234/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3238\n",
      "Epoch 235/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3211\n",
      "Epoch 236/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3205\n",
      "Epoch 237/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3201\n",
      "Epoch 238/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3200\n",
      "Epoch 239/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3199\n",
      "Epoch 240/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3196\n",
      "Epoch 241/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3195\n",
      "Epoch 242/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3195\n",
      "Epoch 243/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3193\n",
      "Epoch 244/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3191\n",
      "Epoch 245/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3192\n",
      "Epoch 246/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3188\n",
      "Epoch 247/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3187\n",
      "Epoch 248/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3189\n",
      "Epoch 249/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3193\n",
      "Epoch 250/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3246\n",
      "Epoch 251/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3355\n",
      "Epoch 252/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3317\n",
      "Epoch 253/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3208\n",
      "Epoch 254/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3196\n",
      "Epoch 255/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3190\n",
      "Epoch 256/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3186\n",
      "Epoch 257/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3185\n",
      "Epoch 258/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3179\n",
      "Epoch 259/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3181\n",
      "Epoch 260/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3176\n",
      "Epoch 261/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3174\n",
      "Epoch 262/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3173\n",
      "Epoch 263/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3171\n",
      "Epoch 264/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3171\n",
      "Epoch 265/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3168\n",
      "Epoch 266/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3169\n",
      "Epoch 267/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3167\n",
      "Epoch 268/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3165\n",
      "Epoch 269/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3166\n",
      "Epoch 270/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3165\n",
      "Epoch 271/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3162\n",
      "Epoch 272/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3164\n",
      "Epoch 273/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3166\n",
      "Epoch 274/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3160\n",
      "Epoch 275/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3157\n",
      "Epoch 276/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3158\n",
      "Epoch 277/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3160\n",
      "Epoch 278/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3159\n",
      "Epoch 279/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3163\n",
      "Epoch 280/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3192\n",
      "Epoch 281/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3288\n",
      "Epoch 282/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3279\n",
      "Epoch 283/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3185\n",
      "Epoch 284/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3168\n",
      "Epoch 285/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3162\n",
      "Epoch 286/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3171\n",
      "Epoch 287/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3156\n",
      "Epoch 288/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3153\n",
      "Epoch 289/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3153\n",
      "Epoch 290/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3151\n",
      "Epoch 291/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3158\n",
      "Epoch 292/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3149\n",
      "Epoch 293/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3147\n",
      "Epoch 294/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3145\n",
      "Epoch 295/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3144\n",
      "Epoch 296/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3144\n",
      "Epoch 297/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3143\n",
      "Epoch 298/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3144\n",
      "Epoch 299/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3141\n",
      "Epoch 300/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3139\n",
      "102/102 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "l2_reg_val_list = 10**np.arange(-2.375,-1.5,0.125)\n",
    "num_iters = len(l2_reg_val_list)\n",
    "num_epochs = 300\n",
    "J_list = np.zeros((num_epochs,num_iters))\n",
    "train_precision = []\n",
    "valid_precision = []\n",
    "counter = 0\n",
    "for l2_reg_val in l2_reg_val_list:    \n",
    "    np.random.seed(42 + k)\n",
    "    \n",
    "    \n",
    "    tf.random.set_seed(1234) # for consistent results\n",
    "    model = Sequential(\n",
    "        [               \n",
    "            ### START CODE HERE ### \n",
    "            Dense(units=442, activation='relu',activity_regularizer=tf.keras.regularizers.L2(l2_reg_val)),\n",
    "            Dense(units=131, activation='relu',activity_regularizer=tf.keras.regularizers.L2(l2_reg_val)),\n",
    "            Dense(units=25, activation='relu',activity_regularizer=tf.keras.regularizers.L2(l2_reg_val)),\n",
    "            Dense(units=4, activation='linear',activity_regularizer=tf.keras.regularizers.L2(l2_reg_val))\n",
    "            ### END CODE HERE ### \n",
    "        ], name = \"my_model\" \n",
    "    )\n",
    "    model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                 optimizer=tf.keras.optimizers.Adam(learning_rate=3*(10**(-5))),)\n",
    "    history = model.fit(X, y, epochs=num_epochs)\n",
    "    J_list[:,counter] = history.history['loss']\n",
    "    counter +=1\n",
    "    prediction_train = model.predict(X)\n",
    "    prediction_train_p = tf.nn.softmax(prediction_train)\n",
    "    y_hat_train = np.zeros((len(prediction_train_p),1))\n",
    "    for i in range(len(y_hat_train)):\n",
    "        y_hat_train[i] = np.argmax(prediction_train_p[i])\n",
    "    train_precision.append(np.sum(y_hat_train==y)/len(y_hat_train))\n",
    "    \n",
    "    prediction_valid = model.predict(X_valid)\n",
    "    prediction_valid_p = tf.nn.softmax(prediction_valid)\n",
    "    y_hat_valid = np.zeros((len(prediction_valid_p),1))\n",
    "    for i in range(len(y_hat_valid)):\n",
    "        y_hat_valid[i] = np.argmax(prediction_valid_p[i])\n",
    "    valid_precision.append(np.sum(y_hat_valid==y_valid)/len(y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f769f9",
   "metadata": {},
   "source": [
    "We see quite large variation in the validation dataset accuracy for small changes in the L2 regularisation strength. This variation is likely demonstrating that our dataset is on the small side. For example, when $d$ is $-1.875$ we obtain 42/45 correct solutions whilst when $d$ is $-1.75$ we get 45/45 correct. If we had more data this variation would smooth out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6b53df28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x18444846f10>]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD4CAYAAAAKA1qZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAT60lEQVR4nO3dcYyc9Z3f8fcnNpQ4aYpV3PQOEy+RUIqLaELWiNxVESuiipAo6JCKQJempSAU60KTa6UrGDlVQFTBPZ1C1cgUEU5NcUEuF1oUcSUktymt1INdB0MNhsoBHfhIwl6rnO8aqZzJt3/M42O8WXtn7fHOeH7vlzSafX7P75nn+5uZnc88v2dmN1WFJKlN7xp1AZKk0TEEJKlhhoAkNcwQkKSGGQKS1LC1oy5gKeecc05NTU2NugxJOm3s2bPnT6pqw0q3G8sQmJqaYn5+ftRlSNJpI8kfnch2TgdJUsMMAUlqmCEgSQ0zBCSpYYaAJDVs2RBI8kCSN5PsO8b6JPnXSQ4keT7JJX3rrkzycrfu1mEWvtiuXbuYmpriXe96F1NTU+zatetU7u6UmpSxTMo4wLGMmx074Pbbv3vUOG6//bvs2DHqyk7MSB+TqjruBfg4cAmw7xjrrwJ+HwhwGfB0174G+CHwQeBM4Dlg83L7qyo++tGP1ko8+OCDtW7dugL+8rJu3bp68MEHV3Q742BSxjIp46hyLONo27YnC94suLwbx+UFb9a2bU+OurQVG9ZjAszXAK+viy+DdYKp44TAvwWu71t+Gfgl4GPAE33ttwG3DbK/lYbApk2bjroDj1w2bdq0otsZB5MylkkZR5VjGUe9cVzeBcFX/jIQTrdxVA3vMTnREBjGOYFzgdf7lg92bcdqX1KSm5PMJ5lfWFhYUQGvvfbaitrH2aSMZVLGAY5lHPXq/T6wE/hyd/39024cMPrHZBghkCXa6jjtS6qq+6pquqqmN2xY2TefP/CBD6yofZxNylgmZRzgWMZRr97Lga3AHd315afdOGD0j8kwQuAgcF7f8kbgjeO0D91dd93FunXrjmpbt24dd91116nY3Sk1KWOZlHGAYxlHv/7r9wO7gWuBf9Fd7+7aTy8jf0wGmTPi+OcEPsXRJ4af6drXAq8A5/POieG/Pcj+VnpOoKp3cmXTpk2VpDZt2nTanejqNyljmZRxVDmWcXP33b2Tw/3j2Lbtybr77lFXdmKG8ZhwgucEUsv8j+EkD9E77joH+Am92D2jC5B7kwT4N8CVwM+AG6pqvtv2KuBr9D4p9EBVDRRt09PT5R+Qk6TBJdlTVdMr3W7ZvyJaVdcvs76A3zjGuseBx1dalCRpdfiNYUlqmCEgSQ0zBCSpYYaAJDXMEJCkhhkCktQwQ0CSGmYISFLDDAFJapghIEkNMwQkqWGGgCQ1zBCQpIYZApLUMENAkhpmCEhSwwwBSWqYISBJDTMEJKlhhoAkNcwQkKSGGQKS1DBDQJIaZghIUsMMAUlqmCEgSQ0zBCSpYYaAJDXMEJCkhhkCktQwQ0CSGmYISFLDDAFJapghIEkNMwQkqWGGgCQ1bKAQSHJlkpeTHEhy6xLr1yd5NMnzSZ5JclHfut9M8kKSfUkeSnLWMAcgSTpxy4ZAkjXA14FPApuB65NsXtRtG7C3qi4GPgfc0217LvBPgOmqughYA1w3vPIlSSdjkCOBS4EDVfVKVb0FPAxcvajPZuB7AFX1EjCV5P3durXAu5OsBdYBbwylcknSSRskBM4FXu9bPti19XsOuAYgyaXAJmBjVf0x8NvAa8CPgD+tqu8stZMkNyeZTzK/sLCwslFIkk7IICGQJdpq0fJXgfVJ9gK3AM8Ch5Osp3fUcD7wy8B7knx2qZ1U1X1VNV1V0xs2bBi0fknSSRgkBA4C5/Utb2TRlE5VHaqqG6rqw/TOCWwAXgU+AbxaVQtV9RfAt4BfGUbhkjQJduyA2dmj22Zne+2rYZAQmAMuSHJ+kjPpndh9rL9DkrO7dQA3AU9V1SF600CXJVmXJMAVwP7hlS9Jp7ctW+Daa98JgtnZ3vKWLauz/7XLdaiqw0m+ADxB79M9D1TVC0k+362/F7gQ+GaSt4EXgRu7dU8neQT4AXCY3jTRfadkJJJ0GpqZgd27ey/8W7fCzp295ZmZ1dl/qhZP74/e9PR0zc/Pj7oMSVo1X/4y3HknbN8Od9yx8u2T7Kmq6ZVu5zeGJWnEZmd7RwDbt/euF58jOJUMAUkaoSPnAHbv7h0BHJkaWq0gMAQkaYTm5o4+B3DkHMHc3Ors33MCkjQBPCcgSVoxQ0CSGmYISFLDDAFJapghIEkNMwQkqWGGgCQ1zBCQpIYZApLUMENAkhpmCEhSwwwBSWqYISBJDTMEJKlhhoAkNcwQkKSGGQKS1DBDQJIaZghIUsMMAUlqmCEgSQ0zBCSpYYaAJDXMEJCkhhkCktQwQ0CSGmYISFLDDAFJapghIEkNMwQkqWGGgCQ1bKAQSHJlkpeTHEhy6xLr1yd5NMnzSZ5JclHfurOTPJLkpST7k3xsmAOQJJ24ZUMgyRrg68Angc3A9Uk2L+q2DdhbVRcDnwPu6Vt3D/BfqupvAX8H2D+MwiVJJ2+QI4FLgQNV9UpVvQU8DFy9qM9m4HsAVfUSMJXk/UneB3wc+Ea37q2q+umwipcknZxBQuBc4PW+5YNdW7/ngGsAklwKbAI2Ah8EFoDfTfJskvuTvGepnSS5Ocl8kvmFhYUVDkOSdCIGCYEs0VaLlr8KrE+yF7gFeBY4DKwFLgF2VtVHgP8L/MI5BYCquq+qpqtqesOGDQOWL0k6GWsH6HMQOK9veSPwRn+HqjoE3ACQJMCr3WUdcLCqnu66PsIxQkCStPoGORKYAy5Icn6SM4HrgMf6O3SfADqzW7wJeKqqDlXVj4HXk3yoW3cF8OKQapcknaRljwSq6nCSLwBPAGuAB6rqhSSf79bfC1wIfDPJ2/Re5G/su4lbgF1dSLxCd8QgSRq9VC2e3h+96enpmp+fH3UZknTaSLKnqqZXup3fGJakhk1ECOzYAbOzR7fNzvbapZPl80uTbCJCYMsWuPbad35RZ2d7y1u2jLYuTQafX5pkg3xEdOzNzMDu3b1fzK1bYefO3vLMzKgr0yTw+aVJNhFHAtD7hdy6Fe68s3ftL6iGyeeXJtXEhMDsbO8d2vbtvevFc7jSyfD5pUk1ESFwZI5292644453Dt39RdUw+PzSJJuIEJibO3qO9sgc7tzcaOvSZPD5pUnml8UkaQL4ZTFJ0ooZApLUMENAkhpmCEhSwwwBSWqYISBJDTMEJKlhhoAkNcwQkKSGGQKS1DBDQJIaZghIUsMMAUlqmCEgSQ0zBCSpYYaAJDXMEJCkhhkCktQwQ0CSGmYISFLDDAFJapghIEkNMwQkqWGGgCQ1zBCQpIYZApLUMENAkho2UAgkuTLJy0kOJLl1ifXrkzya5PkkzyS5aNH6NUmeTfLtYRUuSTp5y4ZAkjXA14FPApuB65NsXtRtG7C3qi4GPgfcs2j9F4H9J1+uJGmYBjkSuBQ4UFWvVNVbwMPA1Yv6bAa+B1BVLwFTSd4PkGQj8Cng/qFVLUkaikFC4Fzg9b7lg11bv+eAawCSXApsAjZ2674G/Bbw8+PtJMnNSeaTzC8sLAxQliTpZA0SAlmirRYtfxVYn2QvcAvwLHA4yaeBN6tqz3I7qar7qmq6qqY3bNgwQFmSpJO1doA+B4Hz+pY3Am/0d6iqQ8ANAEkCvNpdrgM+k+Qq4CzgfUkerKrPDqF2SdJJGuRIYA64IMn5Sc6k98L+WH+HJGd36wBuAp6qqkNVdVtVbayqqW67PzAAJGl8LHskUFWHk3wBeAJYAzxQVS8k+Xy3/l7gQuCbSd4GXgRuPIU1S5KGJFWLp/dHb3p6uubn50ddhiSdNpLsqarplW7nN4YlqWGGgCQ1zBCQpIYZApLUMENAkhpmCIyZHTtgdvbottnZXvvpZFLGIU06Q2DMbNkC1177zgvo7GxvecuW0da1UpMyDmnSDfJnI7SKZmZg9+7eC+bWrbBzZ295ZmbUla3MpIxDmnQeCYyhmZneC+edd/auT9cXzkkZhzTJDIExNDvbe+e8fXvvevHc+uliUsYhTTJDYMwcmTvfvRvuuOOdKZXT7QV0UsYhTTpDYMzMzR09d35kbn1ubrR1rdSkjEOadP4BOUmaAP4BOUnSihkCktQwQ0CSGmYISFLDDAFJapghIEkNMwQkqWGGgCQ1zBCQpIYZApLUMENAkhpmCEhSwwwBSWqYISBJDTMEJKlhhoAkNcwQkKSGGQKS1DBDQJIaZghIUsMMAUlqmCEgSQ0bKASSXJnk5SQHkty6xPr1SR5N8nySZ5Jc1LWfl2Q2yf4kLyT54rAHIEk6ccuGQJI1wNeBTwKbgeuTbF7UbRuwt6ouBj4H3NO1Hwb+WVVdCFwG/MYS20qSRmSQI4FLgQNV9UpVvQU8DFy9qM9m4HsAVfUSMJXk/VX1o6r6Qdf+Z8B+4NyhVS9JOimDhMC5wOt9ywf5xRfy54BrAJJcCmwCNvZ3SDIFfAR4eqmdJLk5yXyS+YWFhYGKlySdnEFCIEu01aLlrwLrk+wFbgGepTcV1LuB5L3A7wFfqqpDS+2kqu6rqumqmt6wYcMgtUuSTtLaAfocBM7rW94IvNHfoXthvwEgSYBXuwtJzqAXALuq6ltDqFmSNCSDHAnMARckOT/JmcB1wGP9HZKc3a0DuAl4qqoOdYHwDWB/Vf3OMAuXJJ28ZY8Equpwki8ATwBrgAeq6oUkn+/W3wtcCHwzydvAi8CN3ea/CvwD4H92U0UA26rq8eEOQ5J0IgaZDqJ70X58Udu9fT//D+CCJbb77yx9TkGSNAb8xrAkNcwQkKSGGQKS1DBDQJIaZghIUsMMAUlqmCEgSQ0zBCSpYYaAJDXMEJCkhhkCktQwQ0BqyI4dMDt7dNvsbK9dbTIEpIZs2QLXXvtOEMzO9pa3bBltXRqdgf6KqKTJMDMDu3f3Xvi3boWdO3vLMzOjrkyj4pGA1JiZmV4A3Hln79oAaJshIDVmdrZ3BLB9e+968TkCtcUQkBpy5BzA7t1wxx3vTA0ZBO0yBKSGzM0dfQ7gyDmCubnR1qXRSVWNuoZfMD09XfPz86MuQ5JOG0n2VNX0SrfzSECSGmYISFLDDAFJapghIEkNMwQkqWFj+emgJAvAHy1qPgf4kxGUM6hxrw/Gv8Zxrw+scRjGvT4Y/xqXqm9TVW1Y6Q2NZQgsJcn8iXz8abWMe30w/jWOe31gjcMw7vXB+Nc4zPqcDpKkhhkCktSw0ykE7ht1AcsY9/pg/Gsc9/rAGodh3OuD8a9xaPWdNucEJEnDdzodCUiShswQkKSGjW0IJPlXSV5K8nySR5OcfZy+a5I8m+Tb41RfkrOSPJPkuSQvJPnKatW3ghrPSzKbZH9X4xfHqb6u3wNJ3kyyb7Vq69v3oDVemeTlJAeS3LqK9f397nH7eZJjfmQwyReT7Ov6fmm16uv2PWiNv9n125fkoSRnjVONST6UZG/f5dBq3ZcruA/PTvJI95zdn+Rjy954VY3lBfh7wNru57uBu4/T958C/wH49jjVBwR4b/fzGcDTwGVjVuMvAZd0P/9V4H8Bm8elvm7dx4FLgH2rdd+t8D5cA/wQ+CBwJvDcKt6HFwIfAr4PTB+jz0XAPmAdvf8r/l3gglW8Dwep8VzgVeDd3fJu4B+NU41LPOY/pvcFrbGpD/h3wE3dz2cCZy9322N7JFBV36mqw93iHwIbl+qXZCPwKeD+1aoNBquvev68Wzyju6zamfgBa/xRVf2g+/nPgP30fiHHor6u31PA/1mNmpbY9yA1XgocqKpXquot4GHg6lWqb39VvbxMtwuBP6yqn3Vj+a/Ar5366noGrBF6AfXuJGvpBdYbp7ayd6ygxiOuAH5YVYv/ssEpMUh9Sd5H7w3TN7pt3qqqny5322MbAov8Y+D3j7Hua8BvAT9ftWp+0THr66aq9gJvAk9W1dOrWVif492HACSZAj5C74hltS1b3xg4Vo3nAq/3LR9klYJ0QPuAjyf560nWAVcB5424pqNU1R8Dvw28BvwI+NOq+s5oqzqu64CHRl3EIh8EFoDf7abH70/ynuU2Wnvq6zq2JN8F/uYSq26vqv/c9bkdOAzsWmL7TwNvVtWeJJePW30AVfU28OFuLvnRJBdV1dDmtodRY9fnvcDvAV+qqkPjVt+pNIQas0Tb0I74BqnveKpqf5K7gSeBP6c3XXX4+Futbo1J1tM7ejof+CnwH5N8tqoeHJca+27nTOAzwG3Dqq273ZOtby29adNbqurpJPcAtwLbl9toZKrqE8dbn+QfAp8GrqhukmuRXwU+k+Qq4CzgfUkerKrPjkl9/bf10yTfB66k985sKIZRY5Iz6AXArqr61rBqG1Z9p9oQajzI0e+sNzLEqYzl6hvwNr5BN02Q5F/Sq3lohlDjJ4BXq2oBIMm3gF8BhhYCw7gfO58EflBVPxnS7QFDqe8gcLBvtuEReiFwXGM7HZTkSuCfA5+pqp8t1aeqbquqjVU1Re/w7A+GFQDDqC/JhiOfJknybnpP9JdWo74V1Bh6Lw77q+p3Vqu2QesbtQFrnAMuSHJ+9y7xOuCx1apxEEn+Rnf9AeAaxm8q4zXgsiTruufkFfTOT42j6xm/+4+q+jHwepIPdU1XAC8OsuFYXoAD9OZZ93aXe7v2XwYeX6L/5azup4OWrQ+4GHgWeJ7eu/8vj9t9CPxdelMXz/f1u2pc6uuWH6I3T/wX9N7t3DhO92G3fBW9T1b9kN7h+2rV92vdffL/gJ8ATxyjvv/WvSA8R++IZjWfh4PW+BV6b5L2Af8e+CtjWOM64H8Df21M78MPA/Pd7/N/AtYvd9v+2QhJatjYTgdJkk49Q0CSGmYISFLDDAFJapghIEkNMwQkqWGGgCQ17P8D+0EJqODpIeEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.log10(l2_reg_val_list),train_precision,'ko',label=\"train precision\")\n",
    "plt.plot(np.log10(l2_reg_val_list),valid_precision,'bx',label=\"validate precision\")\n",
    "plt.ylabel(\"Cost function\"), plt.xlabel(\"log(L2)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be30b62",
   "metadata": {},
   "source": [
    "Nevertheless, we will proceed with the best value of $d =  -1.75$. A note will be made that more data is needed for a validation test set. This project was meant to emulate an situation where data gathering is expensive - perhaps more of the original data should be used for validation and testing and a smaller mount of data augmented for training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18ab96a",
   "metadata": {},
   "source": [
    "# Testing neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393ea9a4",
   "metadata": {},
   "source": [
    "Lets import our test dataset, normalise it and test our neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6b56cb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported files: circles\\test\\circle_\n",
      "Imported files: lines\\test\\line_\n",
      "Imported files: squares\\test\\square_\n"
     ]
    }
   ],
   "source": [
    "num_images = 15*3\n",
    "resolu_images = 25**2\n",
    "file_list = [r\"circles\\test\\circle_\",r\"lines\\test\\line_\",r\"squares\\test\\square_\"]\n",
    "X_test = np.zeros([num_images, resolu_images])\n",
    "counter = 0\n",
    "for i in range(3):\n",
    "    for j in range(15):\n",
    "        file_name = file_list[i] + str(j+1) + \".jpg\"\n",
    "        X_test[counter] = np.matrix.flatten(np.array(Image.open(file_name).convert('L')))\n",
    "        counter += 1\n",
    "    print(\"Imported files: {}\".format(file_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "00f27233",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "81877e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.genfromtxt(\"test_target_class.csv\", delimiter=',')\n",
    "y_test = y_test.reshape((num_images,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "94411a3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "102/102 [==============================] - 1s 4ms/step - loss: 4.1088\n",
      "Epoch 2/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 2.0848\n",
      "Epoch 3/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.4548\n",
      "Epoch 4/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.2198\n",
      "Epoch 5/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.1252\n",
      "Epoch 6/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 1.0823\n",
      "Epoch 7/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 1.0570\n",
      "Epoch 8/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0371\n",
      "Epoch 9/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0181\n",
      "Epoch 10/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 1.0001\n",
      "Epoch 11/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.9830\n",
      "Epoch 12/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.9652\n",
      "Epoch 13/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.9475\n",
      "Epoch 14/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.9300\n",
      "Epoch 15/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.9119\n",
      "Epoch 16/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.8940\n",
      "Epoch 17/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.8757\n",
      "Epoch 18/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.8587\n",
      "Epoch 19/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.8413\n",
      "Epoch 20/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.8245\n",
      "Epoch 21/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.8075\n",
      "Epoch 22/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7919\n",
      "Epoch 23/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7762\n",
      "Epoch 24/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7619\n",
      "Epoch 25/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.7466\n",
      "Epoch 26/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.7331\n",
      "Epoch 27/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.7198\n",
      "Epoch 28/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.7062\n",
      "Epoch 29/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6940\n",
      "Epoch 30/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6814\n",
      "Epoch 31/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6710\n",
      "Epoch 32/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6594\n",
      "Epoch 33/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6485\n",
      "Epoch 34/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6384\n",
      "Epoch 35/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6279\n",
      "Epoch 36/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6190\n",
      "Epoch 37/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6099\n",
      "Epoch 38/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6007\n",
      "Epoch 39/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5932\n",
      "Epoch 40/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5845\n",
      "Epoch 41/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5762\n",
      "Epoch 42/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5689\n",
      "Epoch 43/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5614\n",
      "Epoch 44/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5539\n",
      "Epoch 45/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5472\n",
      "Epoch 46/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5394\n",
      "Epoch 47/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5333\n",
      "Epoch 48/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5274\n",
      "Epoch 49/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5213\n",
      "Epoch 50/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5158\n",
      "Epoch 51/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5097\n",
      "Epoch 52/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5031\n",
      "Epoch 53/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4974\n",
      "Epoch 54/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4920\n",
      "Epoch 55/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4871\n",
      "Epoch 56/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4818\n",
      "Epoch 57/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4773\n",
      "Epoch 58/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4720\n",
      "Epoch 59/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4673\n",
      "Epoch 60/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4625\n",
      "Epoch 61/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4579\n",
      "Epoch 62/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4541\n",
      "Epoch 63/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4494\n",
      "Epoch 64/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4473\n",
      "Epoch 65/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4413\n",
      "Epoch 66/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4384\n",
      "Epoch 67/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4335\n",
      "Epoch 68/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4300\n",
      "Epoch 69/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4264\n",
      "Epoch 70/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4229\n",
      "Epoch 71/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4193\n",
      "Epoch 72/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4162\n",
      "Epoch 73/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4128\n",
      "Epoch 74/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4097\n",
      "Epoch 75/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.4066\n",
      "Epoch 76/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4039\n",
      "Epoch 77/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4006\n",
      "Epoch 78/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3981\n",
      "Epoch 79/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3951\n",
      "Epoch 80/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3922\n",
      "Epoch 81/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.3897\n",
      "Epoch 82/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.3870\n",
      "Epoch 83/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.3845\n",
      "Epoch 84/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.3819\n",
      "Epoch 85/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.3796\n",
      "Epoch 86/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3771\n",
      "Epoch 87/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3749\n",
      "Epoch 88/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3725\n",
      "Epoch 89/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3703\n",
      "Epoch 90/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3686\n",
      "Epoch 91/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3664\n",
      "Epoch 92/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.3642\n",
      "Epoch 93/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.3621\n",
      "Epoch 94/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3605\n",
      "Epoch 95/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3584\n",
      "Epoch 96/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3564\n",
      "Epoch 97/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3552\n",
      "Epoch 98/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3530\n",
      "Epoch 99/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3511\n",
      "Epoch 100/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3493\n",
      "Epoch 101/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3476\n",
      "Epoch 102/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3461\n",
      "Epoch 103/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3445\n",
      "Epoch 104/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3428\n",
      "Epoch 105/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.3414\n",
      "Epoch 106/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3396\n",
      "Epoch 107/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3381\n",
      "Epoch 108/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3371\n",
      "Epoch 109/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3353\n",
      "Epoch 110/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3338\n",
      "Epoch 111/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3323\n",
      "Epoch 112/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3310\n",
      "Epoch 113/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3295\n",
      "Epoch 114/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3284\n",
      "Epoch 115/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3270\n",
      "Epoch 116/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3256\n",
      "Epoch 117/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3244\n",
      "Epoch 118/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3235\n",
      "Epoch 119/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3218\n",
      "Epoch 120/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3208\n",
      "Epoch 121/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3195\n",
      "Epoch 122/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3185\n",
      "Epoch 123/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3172\n",
      "Epoch 124/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3161\n",
      "Epoch 125/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3152\n",
      "Epoch 126/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3139\n",
      "Epoch 127/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3128\n",
      "Epoch 128/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3115\n",
      "Epoch 129/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3107\n",
      "Epoch 130/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3097\n",
      "Epoch 131/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3085\n",
      "Epoch 132/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3077\n",
      "Epoch 133/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3066\n",
      "Epoch 134/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3058\n",
      "Epoch 135/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3047\n",
      "Epoch 136/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3037\n",
      "Epoch 137/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3029\n",
      "Epoch 138/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3022\n",
      "Epoch 139/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3010\n",
      "Epoch 140/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3001\n",
      "Epoch 141/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2993\n",
      "Epoch 142/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2983\n",
      "Epoch 143/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2974\n",
      "Epoch 144/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2968\n",
      "Epoch 145/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2958\n",
      "Epoch 146/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2950\n",
      "Epoch 147/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2942\n",
      "Epoch 148/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2934\n",
      "Epoch 149/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2928\n",
      "Epoch 150/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2919\n",
      "Epoch 151/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2910\n",
      "Epoch 152/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2906\n",
      "Epoch 153/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2896\n",
      "Epoch 154/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2890\n",
      "Epoch 155/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2884\n",
      "Epoch 156/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2875\n",
      "Epoch 157/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2867\n",
      "Epoch 158/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2861\n",
      "Epoch 159/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2854\n",
      "Epoch 160/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2848\n",
      "Epoch 161/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2843\n",
      "Epoch 162/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2837\n",
      "Epoch 163/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2829\n",
      "Epoch 164/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2823\n",
      "Epoch 165/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2815\n",
      "Epoch 166/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2812\n",
      "Epoch 167/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2804\n",
      "Epoch 168/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2798\n",
      "Epoch 169/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2792\n",
      "Epoch 170/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2786\n",
      "Epoch 171/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2780\n",
      "Epoch 172/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2775\n",
      "Epoch 173/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2770\n",
      "Epoch 174/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2765\n",
      "Epoch 175/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2758\n",
      "Epoch 176/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2752\n",
      "Epoch 177/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2746\n",
      "Epoch 178/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2743\n",
      "Epoch 179/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2737\n",
      "Epoch 180/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2731\n",
      "Epoch 181/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2727\n",
      "Epoch 182/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2720\n",
      "Epoch 183/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2717\n",
      "Epoch 184/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2712\n",
      "Epoch 185/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2706\n",
      "Epoch 186/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2701\n",
      "Epoch 187/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2697\n",
      "Epoch 188/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2692\n",
      "Epoch 189/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.2687\n",
      "Epoch 190/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.2683\n",
      "Epoch 191/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.2679\n",
      "Epoch 192/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.2675\n",
      "Epoch 193/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.2670\n",
      "Epoch 194/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.2666\n",
      "Epoch 195/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.2661\n",
      "Epoch 196/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 1s 5ms/step - loss: 0.2656\n",
      "Epoch 197/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.2652\n",
      "Epoch 198/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.2648\n",
      "Epoch 199/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.2644\n",
      "Epoch 200/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.2640\n",
      "Epoch 201/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.2636\n",
      "Epoch 202/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.2632\n",
      "Epoch 203/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.2628\n",
      "Epoch 204/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.2623\n",
      "Epoch 205/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.2620\n",
      "Epoch 206/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2616\n",
      "Epoch 207/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2612\n",
      "Epoch 208/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.2608\n",
      "Epoch 209/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2605\n",
      "Epoch 210/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2601\n",
      "Epoch 211/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2598\n",
      "Epoch 212/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2593\n",
      "Epoch 213/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2591\n",
      "Epoch 214/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2587\n",
      "Epoch 215/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2583\n",
      "Epoch 216/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2580\n",
      "Epoch 217/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2576\n",
      "Epoch 218/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2572\n",
      "Epoch 219/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2569\n",
      "Epoch 220/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2565\n",
      "Epoch 221/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2563\n",
      "Epoch 222/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2561\n",
      "Epoch 223/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2555\n",
      "Epoch 224/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2552\n",
      "Epoch 225/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2549\n",
      "Epoch 226/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2549\n",
      "Epoch 227/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2547\n",
      "Epoch 228/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2539\n",
      "Epoch 229/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2538\n",
      "Epoch 230/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2532\n",
      "Epoch 231/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2530\n",
      "Epoch 232/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2527\n",
      "Epoch 233/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2523\n",
      "Epoch 234/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2521\n",
      "Epoch 235/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2518\n",
      "Epoch 236/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2516\n",
      "Epoch 237/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2513\n",
      "Epoch 238/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2510\n",
      "Epoch 239/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2506\n",
      "Epoch 240/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2503\n",
      "Epoch 241/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2501\n",
      "Epoch 242/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2498\n",
      "Epoch 243/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2495\n",
      "Epoch 244/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2492\n",
      "Epoch 245/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2490\n",
      "Epoch 246/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2488\n",
      "Epoch 247/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2484\n",
      "Epoch 248/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2482\n",
      "Epoch 249/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2480\n",
      "Epoch 250/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2476\n",
      "Epoch 251/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2476\n",
      "Epoch 252/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2472\n",
      "Epoch 253/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2468\n",
      "Epoch 254/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2467\n",
      "Epoch 255/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2464\n",
      "Epoch 256/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2462\n",
      "Epoch 257/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2460\n",
      "Epoch 258/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2458\n",
      "Epoch 259/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2455\n",
      "Epoch 260/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2453\n",
      "Epoch 261/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2449\n",
      "Epoch 262/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2448\n",
      "Epoch 263/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2445\n",
      "Epoch 264/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2444\n",
      "Epoch 265/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2441\n",
      "Epoch 266/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2438\n",
      "Epoch 267/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2437\n",
      "Epoch 268/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2434\n",
      "Epoch 269/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2432\n",
      "Epoch 270/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2429\n",
      "Epoch 271/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2427\n",
      "Epoch 272/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2425\n",
      "Epoch 273/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2423\n",
      "Epoch 274/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2420\n",
      "Epoch 275/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2418\n",
      "Epoch 276/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2417\n",
      "Epoch 277/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2414\n",
      "Epoch 278/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2412\n",
      "Epoch 279/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2410\n",
      "Epoch 280/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2409\n",
      "Epoch 281/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2407\n",
      "Epoch 282/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2403\n",
      "Epoch 283/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2401\n",
      "Epoch 284/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2400\n",
      "Epoch 285/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2398\n",
      "Epoch 286/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2397\n",
      "Epoch 287/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2395\n",
      "Epoch 288/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2392\n",
      "Epoch 289/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2390\n",
      "Epoch 290/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2388\n",
      "Epoch 291/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2386\n",
      "Epoch 292/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2385\n",
      "Epoch 293/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2382\n",
      "Epoch 294/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2382\n",
      "Epoch 295/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2380\n",
      "Epoch 296/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2377\n",
      "Epoch 297/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2376\n",
      "Epoch 298/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2374\n",
      "Epoch 299/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2372\n",
      "Epoch 300/300\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2370\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 300    \n",
    "tf.random.set_seed(1234) # for consistent results\n",
    "model = Sequential(\n",
    "    [               \n",
    "        ### START CODE HERE ### \n",
    "        Dense(units=442, activation='relu',activity_regularizer=tf.keras.regularizers.L2(10**(-1.75))),\n",
    "        Dense(units=131, activation='relu',activity_regularizer=tf.keras.regularizers.L2(10**(-1.75))),\n",
    "        Dense(units=25, activation='relu',activity_regularizer=tf.keras.regularizers.L2(10**(-1.75))),\n",
    "        Dense(units=3, activation='linear',activity_regularizer=tf.keras.regularizers.L2(10**(-1.75)))\n",
    "        ### END CODE HERE ### \n",
    "    ], name = \"my_model\" \n",
    ")\n",
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "             optimizer=tf.keras.optimizers.Adam(learning_rate=1.29e-05),)\n",
    "history = model.fit(X, y, epochs=num_epochs)\n",
    "J = history.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dca31ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction_test = model.predict(X_test)\n",
    "prediction_test_p = tf.nn.softmax(prediction_test)\n",
    "y_hat_test = np.zeros((len(prediction_test_p),1))\n",
    "for i in range(len(y_hat_test)):\n",
    "    y_hat_test[i] = np.argmax(prediction_test_p[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94925ff5",
   "metadata": {},
   "source": [
    "We obtain an accuracy of 93% - this is better than we obtained on our validation dataset. Due to the small amoutn of validation and test examples we can't say with certainty how effective regularisation was."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9c950e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_hat_test == y_test)/len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcf2329",
   "metadata": {},
   "source": [
    "We got 3/45 examples wrong. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "03b40109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_hat_test != y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c82fa5",
   "metadata": {},
   "source": [
    "Plotting the three incorrectly classified images we see that three squares (2) were incorrectly catagorised as circles (0). The first and third incorrect images are slightly rounded, which may have confused the newtork. Perhaps higher resolution images would have aided this classification. Nevertheless, I do believe a human would be able to correctly label these results as squares meaning in this case the network is performing under baseline performance. The second result is less concerning. I believe the protruding line from the square means this image is an outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8323f50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_index = np.where(y_hat_test != y_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c1aefa33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1,3)\n",
    "for i in range(3):\n",
    "    axs[i].imshow(X_test[incorrect_index[i]].reshape((25,25)))\n",
    "    axs[i].text(0,-5,\"Correct was: {}\".format(y_test[incorrect_index[i],0]))\n",
    "    axs[i].text(0,-2,\"Guessed was: {}\".format(y_hat_test[incorrect_index[i],0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45592bb0",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b00cb5",
   "metadata": {},
   "source": [
    "To summarise, from only 180 original images we have successfully trained a neural network that can successfully distinguish lines and shapes and is over 90% successful at distinguishing low-resolution circles and squares. \n",
    "\n",
    "To train a more effective model several improvements could be made. More data should we including in the validation dataset, this would allow more effective tuning of the regularisation parameter which would prevent overfitting to the heavily augmented trainign dataset. \n",
    "\n",
    "Perhaps two validation datasets could be made - the first from the augmented dataset and the second from the non-augmented dataset. The augmeted validation set could be used to tune regularisaition that can prevent overfitting within the augmented dataset. The second, non-augmented validation dataset could instead be used to prevent overfitting to the augmented dataset. To explain this example in simple terms, imagine we trained a neural network to distinguish cats and dogs. Lets imagine we took a small selection of 15 cats from a dataset of 45 cats - to train the neural model we then augmented the training dataset by flipping, rotating and further modifying images. If in the original dataset, 14 of the 15 cats had black fur, then in the augmented training set 90% of thousands of cat examples might have black fur leading the neural network to strongly associate black fur with cats -  when in truth maybe only 50% of cats have black fur. This would be overfitting to the dataset.     \n",
    "\n",
    "To further improve this work it may also be recommended to use a convolution neural network that could more quickly process high resolution images."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
